{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:53.217351Z",
     "start_time": "2020-02-19T01:21:53.214162Z"
    }
   },
   "outputs": [],
   "source": [
    "#Prints **all** console output, not just last item in cell \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eric Meinhardt / emeinhardt@ucsd.edu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:53.451473Z",
     "start_time": "2020-02-19T01:21:53.221711Z"
    }
   },
   "outputs": [],
   "source": [
    "from funcy import *\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Motivation\" data-toc-modified-id=\"Motivation-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Motivation</a></span></li><li><span><a href=\"#Load-data\" data-toc-modified-id=\"Load-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load data</a></span></li><li><span><a href=\"#Check-well-formedness\" data-toc-modified-id=\"Check-well-formedness-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Check well-formedness</a></span></li><li><span><a href=\"#Preprocess-and-transform-into-ndarray\" data-toc-modified-id=\"Preprocess-and-transform-into-ndarray-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Preprocess and transform into <code>ndarray</code></a></span></li><li><span><a href=\"#Export\" data-toc-modified-id=\"Export-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Export</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrates usage of the package, focusing exclusively on loading and preparing data. We will:\n",
    " - look at some example input data (specifying a phonological feature system)\n",
    " - turn that data into a ternary matrix (NumPy ndarray)\n",
    " - export our transformed data and metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:53.469628Z",
     "start_time": "2020-02-19T01:21:53.453362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/cube/home/AD/emeinhar/prague\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:53.637253Z",
     "start_time": "2020-02-19T01:21:53.471439Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:53.850664Z",
     "start_time": "2020-02-19T01:21:53.638775Z"
    }
   },
   "outputs": [],
   "source": [
    "import prague"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:53.986996Z",
     "start_time": "2020-02-19T01:21:53.852517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bakovic_chart_riggle_hayes_remapped.tsv  brh.npy             hayes_remapped.tsv\r\n",
      "bakovic_chart_riggle_hayes.tsv           hayes_features.txt  hayes.tsv\r\n",
      "brh_features.txt                         hayes.npy\r\n"
     ]
    }
   ],
   "source": [
    "%ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:53.992645Z",
     "start_time": "2020-02-19T01:21:53.989086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Module to take\n",
      " - a tab-separated value file specifying a binary or ternary feature matrix.\n",
      "   - the file is assumed to have a header row indicating feature labels\n",
      "   - each non-header row represents an object's feature vector\n",
      "   - features are assumed to be {`+`,`-`,`0`} (following phonological\n",
      "     convention) by default\n",
      " - a (potentially -- comma-separated -- list of) column name(s) indicating any\n",
      "   columns not containing feature-value information (e.g. an object's label =\n",
      "  IPA symbol in the case of phonological feature matrices).\n",
      "\n",
      "and write\n",
      " - the ordered list of feature names (reflecting the ordering in the input\n",
      "   `.tsv`) to a `.txt` file\n",
      " - a serialized numpy ndarray `.npy` file representing the unique feature\n",
      "   vectors of the `.tsv` file as a matrix, with each row corresponding to\n",
      "   an object and feature values represented as `1`, `-1`, or `0`\n",
      " - a tab-separated-value file with `+` replaced with `1` and `-` replaced with\n",
      "   `-1`.\n",
      "\n",
      "Note that if your feature matrix contains multiple objects that have the same\n",
      "featural description, this notebook will detect and record as much, but the\n",
      "final matrix it produces will only have one row for each unique feature vector.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prague.convert.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:54.108041Z",
     "start_time": "2020-02-19T01:21:53.994748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿symbol\tanterior\tapproximant\tback\tconsonantal\tconstricted glottis\tcontinuant\tcoronal\tdelayed_release\tdiphthong\tdistributed\tdorsal\tfront\tfront-diphthong\thigh\tlabial\tlabiodental\tlateral\tlong\tlow\tnasal\tround\tsegment\tsonorant\tspread glottis\tstress\tstrident\tsyllabic\ttap\ttense\ttrill\tvoice\r",
      "\r\n",
      "n̩\t+\t-\t0\t+\t-\t-\t+\t0\t0\t-\t-\t0\t0\t0\t-\t-\t-\t-\t0\t+\t-\t+\t+\t-\t-\t-\t+\t-\t0\t-\t+\r",
      "\r\n",
      "k͡p\t0\t-\t0\t+\t-\t-\t-\t-\t0\t0\t+\t0\t0\t+\t+\t-\t-\t-\t-\t-\t-\t+\t-\t-\t-\t0\t-\t-\t0\t-\t-\r",
      "\r\n",
      "i\t0\t+\t-\t-\t-\t+\t-\t0\t-\t0\t+\t+\t0\t+\t-\t-\t-\t-\t-\t-\t-\t+\t+\t-\t-\t0\t+\t-\t+\t-\t+\r",
      "\r\n",
      "ɡ͡b\t0\t-\t0\t+\t-\t-\t-\t-\t0\t0\t+\t0\t0\t+\t+\t-\t-\t-\t-\t-\t-\t+\t-\t-\t-\t0\t-\t-\t0\t-\t+\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "%cat data/hayes.tsv | head -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:54.114479Z",
     "start_time": "2020-02-19T01:21:54.111260Z"
    }
   },
   "outputs": [],
   "source": [
    "my_input_filepath = 'data/hayes.tsv'\n",
    "my_columns_to_remove = ('symbol',)\n",
    "my_output_filepath = 'data/hayes.npy'\n",
    "my_features_list_output_filepath = 'data/hayes_features.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:54.138354Z",
     "start_time": "2020-02-19T01:21:54.116594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('symbol', 'n̩'),\n",
       "              ('anterior', '+'),\n",
       "              ('approximant', '-'),\n",
       "              ('back', '0'),\n",
       "              ('consonantal', '+'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '-'),\n",
       "              ('coronal', '+'),\n",
       "              ('delayed_release', '0'),\n",
       "              ('diphthong', '0'),\n",
       "              ('distributed', '-'),\n",
       "              ('dorsal', '-'),\n",
       "              ('front', '0'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '0'),\n",
       "              ('labial', '-'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '-'),\n",
       "              ('low', '0'),\n",
       "              ('nasal', '+'),\n",
       "              ('round', '-'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '+'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '-'),\n",
       "              ('syllabic', '+'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '0'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '+')]),\n",
       " OrderedDict([('symbol', 'k͡p'),\n",
       "              ('anterior', '0'),\n",
       "              ('approximant', '-'),\n",
       "              ('back', '0'),\n",
       "              ('consonantal', '+'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '-'),\n",
       "              ('coronal', '-'),\n",
       "              ('delayed_release', '-'),\n",
       "              ('diphthong', '0'),\n",
       "              ('distributed', '0'),\n",
       "              ('dorsal', '+'),\n",
       "              ('front', '0'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '+'),\n",
       "              ('labial', '+'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '-'),\n",
       "              ('low', '-'),\n",
       "              ('nasal', '-'),\n",
       "              ('round', '-'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '-'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '0'),\n",
       "              ('syllabic', '-'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '0'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '-')]),\n",
       " OrderedDict([('symbol', 'i'),\n",
       "              ('anterior', '0'),\n",
       "              ('approximant', '+'),\n",
       "              ('back', '-'),\n",
       "              ('consonantal', '-'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '+'),\n",
       "              ('coronal', '-'),\n",
       "              ('delayed_release', '0'),\n",
       "              ('diphthong', '-'),\n",
       "              ('distributed', '0'),\n",
       "              ('dorsal', '+'),\n",
       "              ('front', '+'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '+'),\n",
       "              ('labial', '-'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '-'),\n",
       "              ('low', '-'),\n",
       "              ('nasal', '-'),\n",
       "              ('round', '-'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '+'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '0'),\n",
       "              ('syllabic', '+'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '+'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '+')]),\n",
       " OrderedDict([('symbol', 'ɡ͡b'),\n",
       "              ('anterior', '0'),\n",
       "              ('approximant', '-'),\n",
       "              ('back', '0'),\n",
       "              ('consonantal', '+'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '-'),\n",
       "              ('coronal', '-'),\n",
       "              ('delayed_release', '-'),\n",
       "              ('diphthong', '0'),\n",
       "              ('distributed', '0'),\n",
       "              ('dorsal', '+'),\n",
       "              ('front', '0'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '+'),\n",
       "              ('labial', '+'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '-'),\n",
       "              ('low', '-'),\n",
       "              ('nasal', '-'),\n",
       "              ('round', '-'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '-'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '0'),\n",
       "              ('syllabic', '-'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '0'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '+')]),\n",
       " OrderedDict([('symbol', 'ʑ'),\n",
       "              ('anterior', '+'),\n",
       "              ('approximant', '-'),\n",
       "              ('back', '-'),\n",
       "              ('consonantal', '+'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '+'),\n",
       "              ('coronal', '+'),\n",
       "              ('delayed_release', '+'),\n",
       "              ('diphthong', '0'),\n",
       "              ('distributed', '+'),\n",
       "              ('dorsal', '+'),\n",
       "              ('front', '+'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '+'),\n",
       "              ('labial', '-'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '-'),\n",
       "              ('low', '-'),\n",
       "              ('nasal', '-'),\n",
       "              ('round', '-'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '-'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '+'),\n",
       "              ('syllabic', '-'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '0'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '+')]),\n",
       " OrderedDict([('symbol', 'ʕ'),\n",
       "              ('anterior', '0'),\n",
       "              ('approximant', '-'),\n",
       "              ('back', '+'),\n",
       "              ('consonantal', '+'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '+'),\n",
       "              ('coronal', '-'),\n",
       "              ('delayed_release', '-'),\n",
       "              ('diphthong', '0'),\n",
       "              ('distributed', '0'),\n",
       "              ('dorsal', '+'),\n",
       "              ('front', '-'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '-'),\n",
       "              ('labial', '-'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '-'),\n",
       "              ('low', '+'),\n",
       "              ('nasal', '-'),\n",
       "              ('round', '-'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '-'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '0'),\n",
       "              ('syllabic', '-'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '0'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '+')]),\n",
       " OrderedDict([('symbol', 'ã'),\n",
       "              ('anterior', '0'),\n",
       "              ('approximant', '+'),\n",
       "              ('back', '-'),\n",
       "              ('consonantal', '-'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '+'),\n",
       "              ('coronal', '-'),\n",
       "              ('delayed_release', '0'),\n",
       "              ('diphthong', '-'),\n",
       "              ('distributed', '0'),\n",
       "              ('dorsal', '+'),\n",
       "              ('front', '-'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '-'),\n",
       "              ('labial', '-'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '-'),\n",
       "              ('low', '+'),\n",
       "              ('nasal', '+'),\n",
       "              ('round', '-'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '+'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '0'),\n",
       "              ('syllabic', '+'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '0'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '+')]),\n",
       " OrderedDict([('symbol', 'ɣ'),\n",
       "              ('anterior', '0'),\n",
       "              ('approximant', '-'),\n",
       "              ('back', '0'),\n",
       "              ('consonantal', '+'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '+'),\n",
       "              ('coronal', '-'),\n",
       "              ('delayed_release', '+'),\n",
       "              ('diphthong', '0'),\n",
       "              ('distributed', '0'),\n",
       "              ('dorsal', '+'),\n",
       "              ('front', '0'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '+'),\n",
       "              ('labial', '-'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '-'),\n",
       "              ('low', '-'),\n",
       "              ('nasal', '-'),\n",
       "              ('round', '-'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '-'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '0'),\n",
       "              ('syllabic', '-'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '0'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '+')]),\n",
       " OrderedDict([('symbol', 'ɶ̃'),\n",
       "              ('anterior', '0'),\n",
       "              ('approximant', '+'),\n",
       "              ('back', '-'),\n",
       "              ('consonantal', '-'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '+'),\n",
       "              ('coronal', '-'),\n",
       "              ('delayed_release', '0'),\n",
       "              ('diphthong', '-'),\n",
       "              ('distributed', '0'),\n",
       "              ('dorsal', '+'),\n",
       "              ('front', '+'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '-'),\n",
       "              ('labial', '+'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '-'),\n",
       "              ('low', '+'),\n",
       "              ('nasal', '+'),\n",
       "              ('round', '+'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '+'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '0'),\n",
       "              ('syllabic', '+'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '0'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '+')]),\n",
       " OrderedDict([('symbol', 'ɵː'),\n",
       "              ('anterior', '0'),\n",
       "              ('approximant', '+'),\n",
       "              ('back', '-'),\n",
       "              ('consonantal', '-'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '+'),\n",
       "              ('coronal', '-'),\n",
       "              ('delayed_release', '0'),\n",
       "              ('diphthong', '-'),\n",
       "              ('distributed', '0'),\n",
       "              ('dorsal', '+'),\n",
       "              ('front', '-'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '-'),\n",
       "              ('labial', '+'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '+'),\n",
       "              ('low', '-'),\n",
       "              ('nasal', '-'),\n",
       "              ('round', '+'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '+'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '0'),\n",
       "              ('syllabic', '+'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '+'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '+')])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_objects = prague.convert.load_objects(my_input_filepath)\n",
    "my_objects[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:54.142242Z",
     "start_time": "2020-02-19T01:21:54.139539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check well-formedness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - We want to make sure every object is defined on the same set of features.\n",
    " - We at least want a heads-up about duplicate objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:54.146871Z",
     "start_time": "2020-02-19T01:21:54.143478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Returns True iff all objects are defined for the same set of features.\n",
      "\n",
      "    If behavior is 'Exception', then this function will raise an exception\n",
      "    if this property does not hold of the set of objects.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(prague.convert.have_universal_feature_definitions.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:54.152209Z",
     "start_time": "2020-02-19T01:21:54.148002Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prague.convert.have_universal_feature_definitions(my_objects, \n",
    "                                                  behavior='Exception')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:54.156252Z",
     "start_time": "2020-02-19T01:21:54.153552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Returns True iff all objects are unique (excluding features in\n",
      "    `features_to_ignore`).\n",
      "\n",
      "    If behavior is 'Exception', then this function will raise an exception if\n",
      "    this property does not hold of the set of objects.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(prague.convert.objects_are_unique.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:54.215350Z",
     "start_time": "2020-02-19T01:21:54.157662Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prague.convert.objects_are_unique(my_objects,\n",
    "                                  features_to_ignore=None,\n",
    "                                  behavior='Exception')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:54.272348Z",
     "start_time": "2020-02-19T01:21:54.216710Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_objects)\n",
    "\n",
    "objects_with_duplicates = lfilter(lambda o: prague.convert.has_duplicates(o, \n",
    "                                                                          my_objects),\n",
    "                                  my_objects)\n",
    "len(objects_with_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `symbol` key or feature is currently responsible for maintaining uniqueness in our demo data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:54.349701Z",
     "start_time": "2020-02-19T01:21:54.274022Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('symbol',)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_columns_to_remove\n",
    "\n",
    "len(my_objects)\n",
    "\n",
    "objects_with_duplicates = lfilter(lambda o: prague.convert.has_duplicates(o,\n",
    "                                                                          my_objects,\n",
    "                                                                          my_columns_to_remove,),\n",
    "                                  my_objects)\n",
    "len(objects_with_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A subsequent processing step will (optionally) remove all of these duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can shorten both of these checks (for uniqueness at a certain level and universality of feature definition) with one call to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:54.353440Z",
     "start_time": "2020-02-19T01:21:54.350904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Given a collection of objects (dicts),\n",
      "     - checks that all objects are defined for the same set of features. If\n",
      "       they're not, this function will raise an exception.\n",
      "\n",
      "    If duplicate_behavior is `Exception`, this will also check if there are\n",
      "    any duplicate objects (with equality up to `features_to_ignore`) and raises\n",
      "    an exception if so.\n",
      "\n",
      "    Returns True if no exceptions are raised.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(prague.convert.sanitized_objects.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:54.410083Z",
     "start_time": "2020-02-19T01:21:54.354692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prague.convert.sanitized_objects(my_objects, duplicate_behavior='Exception',\n",
    "                                 features_to_ignore=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess and transform into `ndarray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:54.413642Z",
     "start_time": "2020-02-19T01:21:54.411236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Given a sanitized collection of objects (dicts) and keys to be removed\n",
      "    (e.g. symbol columns), this function creates a copy of objects, and then\n",
      "     - remaps values to integers\n",
      "     - removes the keys in keys_to_remove\n",
      "\n",
      "    and returns the resulting collection of feature vectors.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(prague.convert.preprocess_objects.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:54.447690Z",
     "start_time": "2020-02-19T01:21:54.414722Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('symbol',)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('anterior', 1),\n",
       "              ('approximant', -1),\n",
       "              ('back', 0),\n",
       "              ('consonantal', 1),\n",
       "              ('constricted glottis', -1),\n",
       "              ('continuant', -1),\n",
       "              ('coronal', 1),\n",
       "              ('delayed_release', 0),\n",
       "              ('diphthong', 0),\n",
       "              ('distributed', -1),\n",
       "              ('dorsal', -1),\n",
       "              ('front', 0),\n",
       "              ('front-diphthong', 0),\n",
       "              ('high', 0),\n",
       "              ('labial', -1),\n",
       "              ('labiodental', -1),\n",
       "              ('lateral', -1),\n",
       "              ('long', -1),\n",
       "              ('low', 0),\n",
       "              ('nasal', 1),\n",
       "              ('round', -1),\n",
       "              ('segment', 1),\n",
       "              ('sonorant', 1),\n",
       "              ('spread glottis', -1),\n",
       "              ('stress', -1),\n",
       "              ('strident', -1),\n",
       "              ('syllabic', 1),\n",
       "              ('tap', -1),\n",
       "              ('tense', 0),\n",
       "              ('trill', -1),\n",
       "              ('voice', 1)]),\n",
       " OrderedDict([('anterior', 0),\n",
       "              ('approximant', -1),\n",
       "              ('back', 0),\n",
       "              ('consonantal', 1),\n",
       "              ('constricted glottis', -1),\n",
       "              ('continuant', -1),\n",
       "              ('coronal', -1),\n",
       "              ('delayed_release', -1),\n",
       "              ('diphthong', 0),\n",
       "              ('distributed', 0),\n",
       "              ('dorsal', 1),\n",
       "              ('front', 0),\n",
       "              ('front-diphthong', 0),\n",
       "              ('high', 1),\n",
       "              ('labial', 1),\n",
       "              ('labiodental', -1),\n",
       "              ('lateral', -1),\n",
       "              ('long', -1),\n",
       "              ('low', -1),\n",
       "              ('nasal', -1),\n",
       "              ('round', -1),\n",
       "              ('segment', 1),\n",
       "              ('sonorant', -1),\n",
       "              ('spread glottis', -1),\n",
       "              ('stress', -1),\n",
       "              ('strident', 0),\n",
       "              ('syllabic', -1),\n",
       "              ('tap', -1),\n",
       "              ('tense', 0),\n",
       "              ('trill', -1),\n",
       "              ('voice', -1)]),\n",
       " OrderedDict([('anterior', 0),\n",
       "              ('approximant', 1),\n",
       "              ('back', -1),\n",
       "              ('consonantal', -1),\n",
       "              ('constricted glottis', -1),\n",
       "              ('continuant', 1),\n",
       "              ('coronal', -1),\n",
       "              ('delayed_release', 0),\n",
       "              ('diphthong', -1),\n",
       "              ('distributed', 0),\n",
       "              ('dorsal', 1),\n",
       "              ('front', 1),\n",
       "              ('front-diphthong', 0),\n",
       "              ('high', 1),\n",
       "              ('labial', -1),\n",
       "              ('labiodental', -1),\n",
       "              ('lateral', -1),\n",
       "              ('long', -1),\n",
       "              ('low', -1),\n",
       "              ('nasal', -1),\n",
       "              ('round', -1),\n",
       "              ('segment', 1),\n",
       "              ('sonorant', 1),\n",
       "              ('spread glottis', -1),\n",
       "              ('stress', -1),\n",
       "              ('strident', 0),\n",
       "              ('syllabic', 1),\n",
       "              ('tap', -1),\n",
       "              ('tense', 1),\n",
       "              ('trill', -1),\n",
       "              ('voice', 1)]),\n",
       " OrderedDict([('anterior', 0),\n",
       "              ('approximant', -1),\n",
       "              ('back', 0),\n",
       "              ('consonantal', 1),\n",
       "              ('constricted glottis', -1),\n",
       "              ('continuant', -1),\n",
       "              ('coronal', -1),\n",
       "              ('delayed_release', -1),\n",
       "              ('diphthong', 0),\n",
       "              ('distributed', 0),\n",
       "              ('dorsal', 1),\n",
       "              ('front', 0),\n",
       "              ('front-diphthong', 0),\n",
       "              ('high', 1),\n",
       "              ('labial', 1),\n",
       "              ('labiodental', -1),\n",
       "              ('lateral', -1),\n",
       "              ('long', -1),\n",
       "              ('low', -1),\n",
       "              ('nasal', -1),\n",
       "              ('round', -1),\n",
       "              ('segment', 1),\n",
       "              ('sonorant', -1),\n",
       "              ('spread glottis', -1),\n",
       "              ('stress', -1),\n",
       "              ('strident', 0),\n",
       "              ('syllabic', -1),\n",
       "              ('tap', -1),\n",
       "              ('tense', 0),\n",
       "              ('trill', -1),\n",
       "              ('voice', 1)]),\n",
       " OrderedDict([('anterior', 1),\n",
       "              ('approximant', -1),\n",
       "              ('back', -1),\n",
       "              ('consonantal', 1),\n",
       "              ('constricted glottis', -1),\n",
       "              ('continuant', 1),\n",
       "              ('coronal', 1),\n",
       "              ('delayed_release', 1),\n",
       "              ('diphthong', 0),\n",
       "              ('distributed', 1),\n",
       "              ('dorsal', 1),\n",
       "              ('front', 1),\n",
       "              ('front-diphthong', 0),\n",
       "              ('high', 1),\n",
       "              ('labial', -1),\n",
       "              ('labiodental', -1),\n",
       "              ('lateral', -1),\n",
       "              ('long', -1),\n",
       "              ('low', -1),\n",
       "              ('nasal', -1),\n",
       "              ('round', -1),\n",
       "              ('segment', 1),\n",
       "              ('sonorant', -1),\n",
       "              ('spread glottis', -1),\n",
       "              ('stress', -1),\n",
       "              ('strident', 1),\n",
       "              ('syllabic', -1),\n",
       "              ('tap', -1),\n",
       "              ('tense', 0),\n",
       "              ('trill', -1),\n",
       "              ('voice', 1)])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_columns_to_remove\n",
    "my_preprocessed_objects = prague.convert.preprocess_objects(my_objects, \n",
    "                                                            keys_to_remove=my_columns_to_remove)\n",
    "my_preprocessed_objects[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:54.451243Z",
     "start_time": "2020-02-19T01:21:54.448890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Given a preprocessed collection of N objects (dicts) and an optional\n",
      "    ordering of the M features of the objects, this returns an M x N ternary\n",
      "    NumPy ndarray representing the collection.\n",
      "\n",
      "    If feature_ordering is not specified, then the features of the first object\n",
      "    will be sorted and used.\n",
      "\n",
      "    If remove_duplicates is False (or if objects contains no duplicates), this\n",
      "    will preserve the ordering (if any) in objects.\n",
      "\n",
      "    If remove_duplicates is True, this function will return a tuple where the\n",
      "    second value is a list of deleted indices.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(prague.convert.to_ternary_feature_vectors.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:54.456206Z",
     "start_time": "2020-02-19T01:21:54.452407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('anterior',\n",
       " 'approximant',\n",
       " 'back',\n",
       " 'consonantal',\n",
       " 'constricted glottis',\n",
       " 'continuant',\n",
       " 'coronal',\n",
       " 'delayed_release',\n",
       " 'diphthong',\n",
       " 'distributed',\n",
       " 'dorsal',\n",
       " 'front',\n",
       " 'front-diphthong',\n",
       " 'high',\n",
       " 'labial',\n",
       " 'labiodental',\n",
       " 'lateral',\n",
       " 'long',\n",
       " 'low',\n",
       " 'nasal',\n",
       " 'round',\n",
       " 'segment',\n",
       " 'sonorant',\n",
       " 'spread glottis',\n",
       " 'stress',\n",
       " 'strident',\n",
       " 'syllabic',\n",
       " 'tap',\n",
       " 'tense',\n",
       " 'trill',\n",
       " 'voice')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_feature_ordering = tuple(sorted(my_preprocessed_objects[0].keys()))\n",
    "my_feature_ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:54.468072Z",
     "start_time": "2020-02-19T01:21:54.458402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, -1,  0,  1, -1, -1,  1,  0,  0, -1, -1,  0,  0,  0, -1, -1,\n",
       "        -1, -1,  0,  1, -1,  1,  1, -1, -1, -1,  1, -1,  0, -1,  1],\n",
       "       [ 0, -1,  0,  1, -1, -1, -1, -1,  0,  0,  1,  0,  0,  1,  1, -1,\n",
       "        -1, -1, -1, -1, -1,  1, -1, -1, -1,  0, -1, -1,  0, -1, -1],\n",
       "       [ 0,  1, -1, -1, -1,  1, -1,  0, -1,  0,  1,  1,  0,  1, -1, -1,\n",
       "        -1, -1, -1, -1, -1,  1,  1, -1, -1,  0,  1, -1,  1, -1,  1],\n",
       "       [ 0, -1,  0,  1, -1, -1, -1, -1,  0,  0,  1,  0,  0,  1,  1, -1,\n",
       "        -1, -1, -1, -1, -1,  1, -1, -1, -1,  0, -1, -1,  0, -1,  1],\n",
       "       [ 1, -1, -1,  1, -1,  1,  1,  1,  0,  1,  1,  1,  0,  1, -1, -1,\n",
       "        -1, -1, -1, -1, -1,  1, -1, -1, -1,  1, -1, -1,  0, -1,  1]],\n",
       "      dtype=int8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75, 85, 100, 114, 121, 129, 130, 133, 134, 140, 150, 159, 169, 170, 174, 183, 199, 200, 204, 205, 206, 210, 218, 219, 223, 230, 232, 237, 238, 239, 243, 244, 245, 250, 255, 261, 268, 270, 274, 278, 286, 288, 294, 297, 300, 301, 310, 314, 315, 318, 319, 320, 325, 328, 330, 333, 337, 338, 342, 343]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(285, 31)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('int8')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_objects_np_no_dups, removed_indices = prague.convert.to_ternary_feature_vectors(my_preprocessed_objects,\n",
    "                                                                                   remove_duplicates=True,\n",
    "                                                                                   feature_ordering=my_feature_ordering)\n",
    "my_objects_np_no_dups[:5]\n",
    "print(removed_indices)\n",
    "my_objects_np_no_dups.shape\n",
    "my_objects_np_no_dups.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep track of the mapping from symbols to binary feature vectors, we'll neglect to do de-duplication right here and now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:54.474377Z",
     "start_time": "2020-02-19T01:21:54.469406Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345, 31)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('int8')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_objects_np = prague.convert.to_ternary_feature_vectors(my_preprocessed_objects,\n",
    "                                                          remove_duplicates=False,\n",
    "                                                          feature_ordering=my_feature_ordering)\n",
    "my_objects_np.shape\n",
    "my_objects_np.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, ordering of objects has been preserved across transformations here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:54.482096Z",
     "start_time": "2020-02-19T01:21:54.475574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('symbol', 'n̩'),\n",
       "              ('anterior', '+'),\n",
       "              ('approximant', '-'),\n",
       "              ('back', '0'),\n",
       "              ('consonantal', '+'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '-'),\n",
       "              ('coronal', '+'),\n",
       "              ('delayed_release', '0'),\n",
       "              ('diphthong', '0'),\n",
       "              ('distributed', '-'),\n",
       "              ('dorsal', '-'),\n",
       "              ('front', '0'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '0'),\n",
       "              ('labial', '-'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '-'),\n",
       "              ('low', '0'),\n",
       "              ('nasal', '+'),\n",
       "              ('round', '-'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '+'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '-'),\n",
       "              ('syllabic', '+'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '0'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '+')]),\n",
       " OrderedDict([('symbol', 'k͡p'),\n",
       "              ('anterior', '0'),\n",
       "              ('approximant', '-'),\n",
       "              ('back', '0'),\n",
       "              ('consonantal', '+'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '-'),\n",
       "              ('coronal', '-'),\n",
       "              ('delayed_release', '-'),\n",
       "              ('diphthong', '0'),\n",
       "              ('distributed', '0'),\n",
       "              ('dorsal', '+'),\n",
       "              ('front', '0'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '+'),\n",
       "              ('labial', '+'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '-'),\n",
       "              ('low', '-'),\n",
       "              ('nasal', '-'),\n",
       "              ('round', '-'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '-'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '0'),\n",
       "              ('syllabic', '-'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '0'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '-')])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_objects[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:54.490362Z",
     "start_time": "2020-02-19T01:21:54.483429Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('anterior', 1),\n",
       "              ('approximant', -1),\n",
       "              ('back', 0),\n",
       "              ('consonantal', 1),\n",
       "              ('constricted glottis', -1),\n",
       "              ('continuant', -1),\n",
       "              ('coronal', 1),\n",
       "              ('delayed_release', 0),\n",
       "              ('diphthong', 0),\n",
       "              ('distributed', -1),\n",
       "              ('dorsal', -1),\n",
       "              ('front', 0),\n",
       "              ('front-diphthong', 0),\n",
       "              ('high', 0),\n",
       "              ('labial', -1),\n",
       "              ('labiodental', -1),\n",
       "              ('lateral', -1),\n",
       "              ('long', -1),\n",
       "              ('low', 0),\n",
       "              ('nasal', 1),\n",
       "              ('round', -1),\n",
       "              ('segment', 1),\n",
       "              ('sonorant', 1),\n",
       "              ('spread glottis', -1),\n",
       "              ('stress', -1),\n",
       "              ('strident', -1),\n",
       "              ('syllabic', 1),\n",
       "              ('tap', -1),\n",
       "              ('tense', 0),\n",
       "              ('trill', -1),\n",
       "              ('voice', 1)]),\n",
       " OrderedDict([('anterior', 0),\n",
       "              ('approximant', -1),\n",
       "              ('back', 0),\n",
       "              ('consonantal', 1),\n",
       "              ('constricted glottis', -1),\n",
       "              ('continuant', -1),\n",
       "              ('coronal', -1),\n",
       "              ('delayed_release', -1),\n",
       "              ('diphthong', 0),\n",
       "              ('distributed', 0),\n",
       "              ('dorsal', 1),\n",
       "              ('front', 0),\n",
       "              ('front-diphthong', 0),\n",
       "              ('high', 1),\n",
       "              ('labial', 1),\n",
       "              ('labiodental', -1),\n",
       "              ('lateral', -1),\n",
       "              ('long', -1),\n",
       "              ('low', -1),\n",
       "              ('nasal', -1),\n",
       "              ('round', -1),\n",
       "              ('segment', 1),\n",
       "              ('sonorant', -1),\n",
       "              ('spread glottis', -1),\n",
       "              ('stress', -1),\n",
       "              ('strident', 0),\n",
       "              ('syllabic', -1),\n",
       "              ('tap', -1),\n",
       "              ('tense', 0),\n",
       "              ('trill', -1),\n",
       "              ('voice', -1)])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_preprocessed_objects[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:54.495893Z",
     "start_time": "2020-02-19T01:21:54.491854Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0],\n",
       "       [-1, -1],\n",
       "       [ 0,  0],\n",
       "       [ 1,  1],\n",
       "       [-1, -1],\n",
       "       [-1, -1],\n",
       "       [ 1, -1],\n",
       "       [ 0, -1],\n",
       "       [ 0,  0],\n",
       "       [-1,  0],\n",
       "       [-1,  1],\n",
       "       [ 0,  0],\n",
       "       [ 0,  0],\n",
       "       [ 0,  1],\n",
       "       [-1,  1],\n",
       "       [-1, -1],\n",
       "       [-1, -1],\n",
       "       [-1, -1],\n",
       "       [ 0, -1],\n",
       "       [ 1, -1],\n",
       "       [-1, -1],\n",
       "       [ 1,  1],\n",
       "       [ 1, -1],\n",
       "       [-1, -1],\n",
       "       [-1, -1],\n",
       "       [-1,  0],\n",
       "       [ 1, -1],\n",
       "       [-1, -1],\n",
       "       [ 0,  0],\n",
       "       [-1, -1],\n",
       "       [ 1, -1]], dtype=int8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_objects_np[0:2].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:54.502077Z",
     "start_time": "2020-02-19T01:21:54.497328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['n̩', 'k͡p', 'i', 'ɡ͡b', 'ʑ']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_objects)\n",
    "my_symbols = lmap(lambda d: d['symbol'],\n",
    "                  my_objects)\n",
    "my_symbols[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:54.507045Z",
     "start_time": "2020-02-19T01:21:54.503107Z"
    }
   },
   "outputs": [],
   "source": [
    "symbol_to_ternary_feature_vector_map = dict(zip(my_symbols, my_objects_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:54.515502Z",
     "start_time": "2020-02-19T01:21:54.508052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1 -1 -1 -1  1 -1  0 -1  0  1  1  0  1 -1 -1 -1 -1 -1 -1 -1  1  1 -1\n",
      " -1  0  1 -1  1 -1  1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('symbol', 'i'),\n",
       "             ('anterior', '0'),\n",
       "             ('approximant', '+'),\n",
       "             ('back', '-'),\n",
       "             ('consonantal', '-'),\n",
       "             ('constricted glottis', '-'),\n",
       "             ('continuant', '+'),\n",
       "             ('coronal', '-'),\n",
       "             ('delayed_release', '0'),\n",
       "             ('diphthong', '-'),\n",
       "             ('distributed', '0'),\n",
       "             ('dorsal', '+'),\n",
       "             ('front', '+'),\n",
       "             ('front-diphthong', '0'),\n",
       "             ('high', '+'),\n",
       "             ('labial', '-'),\n",
       "             ('labiodental', '-'),\n",
       "             ('lateral', '-'),\n",
       "             ('long', '-'),\n",
       "             ('low', '-'),\n",
       "             ('nasal', '-'),\n",
       "             ('round', '-'),\n",
       "             ('segment', '+'),\n",
       "             ('sonorant', '+'),\n",
       "             ('spread glottis', '-'),\n",
       "             ('stress', '-'),\n",
       "             ('strident', '0'),\n",
       "             ('syllabic', '+'),\n",
       "             ('tap', '-'),\n",
       "             ('tense', '+'),\n",
       "             ('trill', '-'),\n",
       "             ('voice', '+')])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(symbol_to_ternary_feature_vector_map['i'])\n",
    "[o for o in my_objects if o['symbol'] == 'i'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove duplicates, we can make use of the relevant NumPy functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:54.519836Z",
     "start_time": "2020-02-19T01:21:54.516850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345, 31)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_objects_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:21:54.525549Z",
     "start_time": "2020-02-19T01:21:54.521111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(285, 31)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_unique_objects_np = np.unique(my_objects_np, axis=0)\n",
    "my_unique_objects_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:22:47.971862Z",
     "start_time": "2020-02-19T01:22:47.967957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Writes the object matrix and the sequence of feature labels to the specified filepaths.\n",
      "\n",
      "    The object matrix is saved using `np.save` (i.e. as .npy file) and the feature labels\n",
      "    are written to a textfile.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(prague.convert.export_ternary_feature_vectors.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:23:16.189309Z",
     "start_time": "2020-02-19T01:23:16.184297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/hayes.npy'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'data/hayes_features.txt'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_output_filepath\n",
    "my_features_list_output_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:24:22.200807Z",
     "start_time": "2020-02-19T01:24:22.194806Z"
    }
   },
   "outputs": [],
   "source": [
    "prague.convert.export_ternary_feature_vectors(my_objects_np,\n",
    "                                              my_feature_ordering,\n",
    "                                              my_output_filepath,\n",
    "                                              my_features_list_output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T01:24:26.776021Z",
     "start_time": "2020-02-19T01:24:26.659644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bakovic_chart_riggle_hayes_remapped.tsv  brh.npy             hayes_remapped.tsv\r\n",
      "bakovic_chart_riggle_hayes.tsv           hayes_features.txt  hayes.tsv\r\n",
      "brh_features.txt                         hayes.npy\r\n"
     ]
    }
   ],
   "source": [
    "%ls data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
