{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:34:44.707845Z",
     "start_time": "2020-02-19T05:34:44.704719Z"
    }
   },
   "outputs": [],
   "source": [
    "#Prints **all** console output, not just last item in cell \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eric Meinhardt / emeinhardt@ucsd.edu**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Motivation\" data-toc-modified-id=\"Motivation-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Motivation</a></span></li><li><span><a href=\"#Load-data\" data-toc-modified-id=\"Load-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load data</a></span></li><li><span><a href=\"#Overhead\" data-toc-modified-id=\"Overhead-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Overhead</a></span></li><li><span><a href=\"#Identifying-a-possible-Boolean-concept\" data-toc-modified-id=\"Identifying-a-possible-Boolean-concept-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Identifying a possible Boolean concept</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we show `prague` can be used to identify feature vectors compatible with (or that exactly pick out) an observed set of objects, using phonology as a motivating example. Some implementation details potentially relevant for usage are also discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:34:46.360923Z",
     "start_time": "2020-02-19T05:34:44.712481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/cube/home/AD/emeinhar/prague\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:34:46.677946Z",
     "start_time": "2020-02-19T05:34:46.363017Z"
    }
   },
   "outputs": [],
   "source": [
    "from funcy import *\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:34:48.439004Z",
     "start_time": "2020-02-19T05:34:46.679708Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:34:48.877997Z",
     "start_time": "2020-02-19T05:34:48.440711Z"
    }
   },
   "outputs": [],
   "source": [
    "import prague"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:34:49.006663Z",
     "start_time": "2020-02-19T05:34:48.879064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bakovic_chart_riggle_hayes_remapped.tsv  brh.npy             hayes_remapped.tsv\r\n",
      "bakovic_chart_riggle_hayes.tsv           hayes_features.txt  hayes.tsv\r\n",
      "brh_features.txt                         hayes.npy\r\n"
     ]
    }
   ],
   "source": [
    "%ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:34:49.010483Z",
     "start_time": "2020-02-19T05:34:49.008092Z"
    }
   },
   "outputs": [],
   "source": [
    "# objects_in_fp = 'data/hayes.tsv'\n",
    "# objects_np_in_fp = 'data/hayes.npy'\n",
    "# feature_list_fp = 'data/hayes_features.txt'\n",
    "\n",
    "objects_in_fp = 'data/bakovic_chart_riggle_hayes.tsv'\n",
    "objects_np_in_fp = 'data/brh.npy'\n",
    "feature_list_fp = 'data/brh_features.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:34:49.027584Z",
     "start_time": "2020-02-19T05:34:49.011659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('symbol', 'p'),\n",
       "              ('syll', '-'),\n",
       "              ('cons', '+'),\n",
       "              ('son', '-'),\n",
       "              ('labial', '+'),\n",
       "              ('coronal', '-'),\n",
       "              ('dorsal', '-'),\n",
       "              ('voice', '-'),\n",
       "              ('cont', '-'),\n",
       "              ('del. rel.', '-'),\n",
       "              ('ant', '0'),\n",
       "              ('dist', '0'),\n",
       "              ('strid', '0'),\n",
       "              ('high', '0'),\n",
       "              ('low', '0'),\n",
       "              ('back', '0'),\n",
       "              ('front', '0'),\n",
       "              ('approx', '-'),\n",
       "              ('nas', '-'),\n",
       "              ('lat', '-'),\n",
       "              ('s.g.', '-'),\n",
       "              ('c.g.', '-'),\n",
       "              ('round', '0'),\n",
       "              ('ATR', '0')]),\n",
       " OrderedDict([('symbol', 'b'),\n",
       "              ('syll', '-'),\n",
       "              ('cons', '+'),\n",
       "              ('son', '-'),\n",
       "              ('labial', '+'),\n",
       "              ('coronal', '-'),\n",
       "              ('dorsal', '-'),\n",
       "              ('voice', '+'),\n",
       "              ('cont', '-'),\n",
       "              ('del. rel.', '-'),\n",
       "              ('ant', '0'),\n",
       "              ('dist', '0'),\n",
       "              ('strid', '0'),\n",
       "              ('high', '0'),\n",
       "              ('low', '0'),\n",
       "              ('back', '0'),\n",
       "              ('front', '0'),\n",
       "              ('approx', '-'),\n",
       "              ('nas', '-'),\n",
       "              ('lat', '-'),\n",
       "              ('s.g.', '-'),\n",
       "              ('c.g.', '-'),\n",
       "              ('round', '0'),\n",
       "              ('ATR', '0')]),\n",
       " OrderedDict([('symbol', 'ɸ'),\n",
       "              ('syll', '-'),\n",
       "              ('cons', '+'),\n",
       "              ('son', '-'),\n",
       "              ('labial', '+'),\n",
       "              ('coronal', '-'),\n",
       "              ('dorsal', '-'),\n",
       "              ('voice', '-'),\n",
       "              ('cont', '+'),\n",
       "              ('del. rel.', '+'),\n",
       "              ('ant', '0'),\n",
       "              ('dist', '+'),\n",
       "              ('strid', '-'),\n",
       "              ('high', '0'),\n",
       "              ('low', '0'),\n",
       "              ('back', '0'),\n",
       "              ('front', '0'),\n",
       "              ('approx', '-'),\n",
       "              ('nas', '-'),\n",
       "              ('lat', '-'),\n",
       "              ('s.g.', '-'),\n",
       "              ('c.g.', '-'),\n",
       "              ('round', '0'),\n",
       "              ('ATR', '0')])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['p', 'b', 'ɸ', 'β', 'f', 'v', 't̪', 'd̪', 'θ', 'ð']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects = prague.load_objects(objects_in_fp)\n",
    "len(objects)\n",
    "objects[:3]\n",
    "\n",
    "symbols = [o['symbol'] for o in objects]\n",
    "symbols[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:34:49.031584Z",
     "start_time": "2020-02-19T05:34:49.029118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(objects[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:34:49.038240Z",
     "start_time": "2020-02-19T05:34:49.032686Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list = []\n",
    "with open(feature_list_fp, 'r') as feature_file:\n",
    "    for feature in feature_file:\n",
    "        feature_list.append(feature.strip())\n",
    "len(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:34:49.042489Z",
     "start_time": "2020-02-19T05:34:49.039115Z"
    }
   },
   "outputs": [],
   "source": [
    "assert len(feature_list) == len(objects[0].keys()) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:34:49.051166Z",
     "start_time": "2020-02-19T05:34:49.043351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 23)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('int8')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects_np = np.load(objects_np_in_fp)\n",
    "objects_np.shape\n",
    "objects_np.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:34:49.054655Z",
     "start_time": "2020-02-19T05:34:49.052385Z"
    }
   },
   "outputs": [],
   "source": [
    "assert objects_np.shape[1] == len(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:34:49.059778Z",
     "start_time": "2020-02-19T05:34:49.056068Z"
    }
   },
   "outputs": [],
   "source": [
    "assert objects_np.shape[0] == len(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:34:49.068810Z",
     "start_time": "2020-02-19T05:34:49.060834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('symbol', 'p'),\n",
       "              ('syll', '-'),\n",
       "              ('cons', '+'),\n",
       "              ('son', '-'),\n",
       "              ('labial', '+'),\n",
       "              ('coronal', '-'),\n",
       "              ('dorsal', '-'),\n",
       "              ('voice', '-'),\n",
       "              ('cont', '-'),\n",
       "              ('del. rel.', '-'),\n",
       "              ('ant', '0'),\n",
       "              ('dist', '0'),\n",
       "              ('strid', '0'),\n",
       "              ('high', '0'),\n",
       "              ('low', '0'),\n",
       "              ('back', '0'),\n",
       "              ('front', '0'),\n",
       "              ('approx', '-'),\n",
       "              ('nas', '-'),\n",
       "              ('lat', '-'),\n",
       "              ('s.g.', '-'),\n",
       "              ('c.g.', '-'),\n",
       "              ('round', '0'),\n",
       "              ('ATR', '0')]),\n",
       " OrderedDict([('symbol', 'b'),\n",
       "              ('syll', '-'),\n",
       "              ('cons', '+'),\n",
       "              ('son', '-'),\n",
       "              ('labial', '+'),\n",
       "              ('coronal', '-'),\n",
       "              ('dorsal', '-'),\n",
       "              ('voice', '+'),\n",
       "              ('cont', '-'),\n",
       "              ('del. rel.', '-'),\n",
       "              ('ant', '0'),\n",
       "              ('dist', '0'),\n",
       "              ('strid', '0'),\n",
       "              ('high', '0'),\n",
       "              ('low', '0'),\n",
       "              ('back', '0'),\n",
       "              ('front', '0'),\n",
       "              ('approx', '-'),\n",
       "              ('nas', '-'),\n",
       "              ('lat', '-'),\n",
       "              ('s.g.', '-'),\n",
       "              ('c.g.', '-'),\n",
       "              ('round', '0'),\n",
       "              ('ATR', '0')])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:34:49.073539Z",
     "start_time": "2020-02-19T05:34:49.070130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0, -1,  0, -1,  1, -1, -1, -1,  0, -1,  0,  0,  1, -1,  0,\n",
       "        -1,  0, -1, -1,  0, -1, -1],\n",
       "       [ 0,  0, -1,  0, -1,  1, -1, -1, -1,  0, -1,  0,  0,  1, -1,  0,\n",
       "        -1,  0, -1, -1,  0, -1,  1]], dtype=int8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects_np[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:34:49.077616Z",
     "start_time": "2020-02-19T05:34:49.074831Z"
    }
   },
   "outputs": [],
   "source": [
    "symbol_to_pfv = {o['symbol']:objects_np[i]\n",
    "                 for i,o in enumerate(objects)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:34:49.085305Z",
     "start_time": "2020-02-19T05:34:49.078793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 23)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(91, 23)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects_np.shape\n",
    "unique_objects_np = np.unique(objects_np, axis=0)\n",
    "unique_objects_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:34:49.096819Z",
     "start_time": "2020-02-19T05:34:49.086521Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|O| = 94 distinct object types (including labels)'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'23 object features'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'8.39E+06 logically possible object feature vectors'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'|V| = 91 distinct object feature vectors'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'2.48E+27 possible subsets of V'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'9.41E+10 possible partial feature vectors'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"|O| = {len(objects)} distinct object types (including labels)\"\n",
    "f\"{unique_objects_np.shape[1]} object features\"\n",
    "\"{0:.2E} logically possible object feature vectors\".format(2**unique_objects_np.shape[1])\n",
    "f\"|V| = {unique_objects_np.shape[0]} distinct object feature vectors\"\n",
    "\"{0:.2E} possible subsets of V\".format(2**unique_objects_np.shape[0])\n",
    "\"{0:.2E} possible partial feature vectors\".format(3**unique_objects_np.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:34:49.107852Z",
     "start_time": "2020-02-19T05:34:49.097703Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:34:49.221056Z",
     "start_time": "2020-02-19T05:34:49.109047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           125G        914M        115G        3.0M        9.3G        123G\r\n",
      "Swap:          2.0G          0B        2.0G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:34:55.122565Z",
     "start_time": "2020-02-19T05:34:49.222681Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91/91 [00:05<00:00, 15.45it/s]\n"
     ]
    }
   ],
   "source": [
    "#7s on wittgenstein\n",
    "upper_closures = [prague.upper_closure(o, strict=False) \n",
    "                  for o in tqdm(unique_objects_np)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:34:55.168237Z",
     "start_time": "2020-02-19T05:34:55.123789Z"
    }
   },
   "outputs": [],
   "source": [
    "upper_closures_as_matrix = np.concatenate(upper_closures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:36:57.677886Z",
     "start_time": "2020-02-19T05:34:55.170482Z"
    }
   },
   "outputs": [],
   "source": [
    "#2m on wittgenstein\n",
    "all_pfvs_with_nonempty_extension = np.unique(upper_closures_as_matrix, \n",
    "                                             return_index=False,\n",
    "                                             axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:54:22.641126Z",
     "start_time": "2020-02-19T05:54:22.637424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9115112, 23)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pfvs_with_nonempty_extension.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:56:21.205419Z",
     "start_time": "2020-02-19T05:56:21.200973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# partial feature vectors that pick out a non-empty subset of O: 9.12E+06\n",
      " # logically possible partial feature vectors: 9.41E+10\n"
     ]
    }
   ],
   "source": [
    "print(\"# partial feature vectors that pick out a non-empty subset of O: \"\n",
    "      \"{0:.2E}\\n\".format(all_pfvs_with_nonempty_extension.shape[0]),\n",
    "      \"# logically possible partial feature vectors: \"\n",
    "      \"{0:.2E}\".format(3**all_pfvs_with_nonempty_extension.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:36:57.819770Z",
     "start_time": "2020-02-19T05:36:57.679579Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           125G        2.2G        114G        3.0M        9.3G        122G\r\n",
      "Swap:          2.0G          0B        2.0G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:36:57.823988Z",
     "start_time": "2020-02-19T05:36:57.821770Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2m on wittgenstein\n",
    "# unique_upper_closures = set(lmap(prague.HashableArray,\n",
    "#                                  list(upper_closures_as_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:36:57.966817Z",
     "start_time": "2020-02-19T05:36:57.825746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           125G        2.2G        114G        3.0M        9.3G        122G\r\n",
      "Swap:          2.0G          0B        2.0G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:36:57.970998Z",
     "start_time": "2020-02-19T05:36:57.968836Z"
    }
   },
   "outputs": [],
   "source": [
    "# >>>2m on wittgenstein, uses way too much memory\n",
    "# unique_upper_closures2 = set(lmap(prague.HashableArray,\n",
    "#                                   cat(map(list, upper_closures_as_matrix))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:36:58.166866Z",
     "start_time": "2020-02-19T05:36:57.972625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           125G        2.2G        114G        3.0M        9.3G        122G\r\n",
      "Swap:          2.0G          0B        2.0G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:37:46.333810Z",
     "start_time": "2020-02-19T05:36:58.168868Z"
    }
   },
   "outputs": [],
   "source": [
    "#48s on wittgenstein\n",
    "nonempty_pfv_extensions = prague.extensions(all_pfvs_with_nonempty_extension,\n",
    "                                            object_inventory=unique_objects_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:37:46.482110Z",
     "start_time": "2020-02-19T05:37:46.335154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           125G        3.0G        113G        3.0M        9.3G        121G\r\n",
      "Swap:          2.0G          0B        2.0G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:37:46.926048Z",
     "start_time": "2020-02-19T05:37:46.484222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My random PFV = [ 0  0  0  1  0  1  0  0  0  0  1  0  0 -1  1  0 -1  0  0  0  0  0  1]\n",
      "My extension as an 'indicator' vector = \n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "My extension as a stack of 1 objects S = \n",
      "[[ 0  0  1  1 -1  1 -1 -1  0  0  1 -1  1 -1  1 -1 -1  0 -1  1  0 -1  1]]\n"
     ]
    }
   ],
   "source": [
    "a_random_pfv = prague.feature_vector.make_random_pfv(num_features=len(feature_list))\n",
    "random_extension = prague.extension(a_random_pfv, \n",
    "                                    object_inventory=unique_objects_np)\n",
    "random_objects = prague.extension_vector_to_objects(random_extension, \n",
    "                                                    object_inventory=unique_objects_np)\n",
    "my_x = random_extension\n",
    "my_S = random_objects\n",
    "\n",
    "\n",
    "while my_x.sum() == 0:\n",
    "    a_random_pfv = prague.feature_vector.make_random_pfv(num_features=len(feature_list))\n",
    "    random_extension = prague.extension(a_random_pfv, \n",
    "                                        object_inventory=unique_objects_np)\n",
    "    random_objects = prague.extension_vector_to_objects(random_extension, \n",
    "                                                        object_inventory=unique_objects_np)\n",
    "    my_x = random_extension\n",
    "    my_S = random_objects\n",
    "\n",
    "\n",
    "print(f\"My random PFV = {a_random_pfv}\")\n",
    "print(f\"My extension as an 'indicator' vector = \\n{my_x}\")\n",
    "print(f\"My extension as a stack of {my_S.shape[0]} objects S = \\n{my_S}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T05:58:59.083030Z",
     "start_time": "2020-02-19T05:58:58.306783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131,072 PFVs whose extension contains S = \n",
      "[[ 0  0  1 ...  0 -1  1]\n",
      " [ 0  0  0 ...  0 -1  1]\n",
      " [ 0  0  1 ...  0 -1  1]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  1 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      "69,312 PFVs whose extension is exactly S = \n",
      "[[ 0  0  1 ...  0 -1  1]\n",
      " [ 0  0  0 ...  0 -1  1]\n",
      " [ 0  0  1 ...  0 -1  1]\n",
      " ...\n",
      " [ 0  0  1 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      "2 PFVs whose extension is exactly S and which are maximally simple (i.e. unspecified) = \n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0 -1  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0]]\n",
      "original generating pfv = \n",
      " [ 0  0  0  1  0  1  0  0  0  0  1  0  0 -1  1  0 -1  0  0  0  0  0  1]\n"
     ]
    }
   ],
   "source": [
    "pfvs_containing_my_S = prague.get_pfvs_whose_extension_contains(my_S)\n",
    "pfvs_exactly_matching_my_S = prague.get_pfvs_whose_extension_is_exactly(my_S, \n",
    "                                                                        object_inventory=unique_objects_np)\n",
    "specification_of_exact_matches = np.abs(pfvs_exactly_matching_my_S).sum(axis=1)\n",
    "minimal_specification = np.min(specification_of_exact_matches)\n",
    "minimal_pfvs_exactly_matching_my_s = pfvs_exactly_matching_my_S[specification_of_exact_matches == minimal_specification]\n",
    "\n",
    "print(\"{0:,} PFVs\".format(pfvs_containing_my_S.shape[0]),\n",
    "      f\"whose extension contains S = \\n{pfvs_containing_my_S}\")\n",
    "print(\"{0:,} PFVs\".format(pfvs_exactly_matching_my_S.shape[0]),\n",
    "      f\"whose extension is exactly S = \\n{pfvs_exactly_matching_my_S}\")\n",
    "print(\"{0:,} PFVs\".format(minimal_pfvs_exactly_matching_my_s.shape[0]),\n",
    "      f\"whose extension is exactly S and which are maximally simple\"\n",
    "      f\" (i.e. unspecified) = \\n{minimal_pfvs_exactly_matching_my_s}\")\n",
    "print(f\"original generating pfv = \\n {a_random_pfv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying a possible Boolean concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the two sets of objects defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:44:41.979949Z",
     "start_time": "2020-02-19T02:44:41.977648Z"
    }
   },
   "outputs": [],
   "source": [
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:44:42.440577Z",
     "start_time": "2020-02-19T02:44:42.426987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ɑ̃ː', 'ɶː', 'ʑ̥', 'ɡ̠̥']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('symbol', 'ɑ̃ː'),\n",
       "              ('anterior', '0'),\n",
       "              ('approximant', '+'),\n",
       "              ('back', '+'),\n",
       "              ('consonantal', '-'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '+'),\n",
       "              ('coronal', '-'),\n",
       "              ('delayed_release', '0'),\n",
       "              ('diphthong', '-'),\n",
       "              ('distributed', '0'),\n",
       "              ('dorsal', '+'),\n",
       "              ('front', '-'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '-'),\n",
       "              ('labial', '-'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '+'),\n",
       "              ('low', '+'),\n",
       "              ('nasal', '+'),\n",
       "              ('round', '-'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '+'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '0'),\n",
       "              ('syllabic', '+'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '0'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '+')]),\n",
       " OrderedDict([('symbol', 'ɶː'),\n",
       "              ('anterior', '0'),\n",
       "              ('approximant', '+'),\n",
       "              ('back', '-'),\n",
       "              ('consonantal', '-'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '+'),\n",
       "              ('coronal', '-'),\n",
       "              ('delayed_release', '0'),\n",
       "              ('diphthong', '-'),\n",
       "              ('distributed', '0'),\n",
       "              ('dorsal', '+'),\n",
       "              ('front', '+'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '-'),\n",
       "              ('labial', '+'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '+'),\n",
       "              ('low', '+'),\n",
       "              ('nasal', '-'),\n",
       "              ('round', '+'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '+'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '0'),\n",
       "              ('syllabic', '+'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '0'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '+')]),\n",
       " OrderedDict([('symbol', 'ʑ̥'),\n",
       "              ('anterior', '+'),\n",
       "              ('approximant', '-'),\n",
       "              ('back', '-'),\n",
       "              ('consonantal', '+'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '+'),\n",
       "              ('coronal', '+'),\n",
       "              ('delayed_release', '+'),\n",
       "              ('diphthong', '0'),\n",
       "              ('distributed', '+'),\n",
       "              ('dorsal', '+'),\n",
       "              ('front', '+'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '+'),\n",
       "              ('labial', '-'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '-'),\n",
       "              ('low', '-'),\n",
       "              ('nasal', '-'),\n",
       "              ('round', '-'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '-'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '+'),\n",
       "              ('syllabic', '-'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '0'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '-')]),\n",
       " OrderedDict([('symbol', 'ɡ̠̥'),\n",
       "              ('anterior', '0'),\n",
       "              ('approximant', '-'),\n",
       "              ('back', '+'),\n",
       "              ('consonantal', '+'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '-'),\n",
       "              ('coronal', '-'),\n",
       "              ('delayed_release', '-'),\n",
       "              ('diphthong', '0'),\n",
       "              ('distributed', '0'),\n",
       "              ('dorsal', '+'),\n",
       "              ('front', '-'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '+'),\n",
       "              ('labial', '-'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '-'),\n",
       "              ('low', '-'),\n",
       "              ('nasal', '-'),\n",
       "              ('round', '-'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '-'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '0'),\n",
       "              ('syllabic', '-'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '0'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '-')])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_observations = 4\n",
    "random_observation = [choice(objects) for each in range(num_observations)]\n",
    "lmap(lambda o: o['symbol'],\n",
    "     random_observation)\n",
    "random_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:44:43.721742Z",
     "start_time": "2020-02-19T02:44:43.713543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('symbol', 'j'),\n",
       "              ('anterior', '0'),\n",
       "              ('approximant', '+'),\n",
       "              ('back', '-'),\n",
       "              ('consonantal', '-'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '+'),\n",
       "              ('coronal', '-'),\n",
       "              ('delayed_release', '0'),\n",
       "              ('diphthong', '0'),\n",
       "              ('distributed', '0'),\n",
       "              ('dorsal', '+'),\n",
       "              ('front', '+'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '+'),\n",
       "              ('labial', '-'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '-'),\n",
       "              ('low', '-'),\n",
       "              ('nasal', '-'),\n",
       "              ('round', '-'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '+'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '0'),\n",
       "              ('syllabic', '-'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '+'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '+')]),\n",
       " OrderedDict([('symbol', 'w'),\n",
       "              ('anterior', '0'),\n",
       "              ('approximant', '+'),\n",
       "              ('back', '+'),\n",
       "              ('consonantal', '-'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '+'),\n",
       "              ('coronal', '-'),\n",
       "              ('delayed_release', '0'),\n",
       "              ('diphthong', '0'),\n",
       "              ('distributed', '0'),\n",
       "              ('dorsal', '+'),\n",
       "              ('front', '-'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '+'),\n",
       "              ('labial', '+'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '-'),\n",
       "              ('low', '-'),\n",
       "              ('nasal', '-'),\n",
       "              ('round', '+'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '+'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '0'),\n",
       "              ('syllabic', '-'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '+'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '+')])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matching_symbols = {'t','d','p','b','k','g'} #will probably consume ALL available memory a few cells downstream\n",
    "matching_symbols = {'j','w'}\n",
    "non_random_observation = lfilter(lambda o: o['symbol'] in matching_symbols,\n",
    "                                 objects)\n",
    "len(non_random_observation)\n",
    "non_random_observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we didn't know how either set of observations were generated, but that we want to know if all of the examples in each set of observations are instances of at least one Boolean concept (i.e. plausibly generated by/instances of the same defining partial feature vector).\n",
    "\n",
    "`prague`'s main functionality is to facilitate this kind of calculation and analysis via two functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:44:46.398380Z",
     "start_time": "2020-02-19T02:44:46.394767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Given\n",
      "        a set of observed objects (a stack of feature vectors)\n",
      "    this returns\n",
      "        the set of partial feature vectors (a stack, one vector per row)\n",
      "    whose extension must contain the set of observed objects.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(prague.get_pfvs_whose_extension_contains.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:44:47.620437Z",
     "start_time": "2020-02-19T02:44:47.616950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Given\n",
      "        a set of observed objects (a stack of feature vectors)\n",
      "        a set of potentially observable objects (another stack of vectors)\n",
      "    this returns\n",
      "        the set of partial feature vectors (a stack, one vector per row)\n",
      "    whose extension must be exactly the set of observed objects.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(prague.get_pfvs_whose_extension_is_exactly.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:44:50.594892Z",
     "start_time": "2020-02-19T02:44:50.589627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  1, -1, -1,  1, -1,  0, -1,  0,  1, -1,  0, -1, -1, -1,\n",
       "        -1,  1,  1,  1, -1,  1,  1, -1, -1,  0,  1, -1,  0, -1,  1],\n",
       "       [ 0,  1, -1, -1, -1,  1, -1,  0, -1,  0,  1,  1,  0, -1,  1, -1,\n",
       "        -1,  1,  1, -1,  1,  1,  1, -1, -1,  0,  1, -1,  0, -1,  1],\n",
       "       [ 1, -1, -1,  1, -1,  1,  1,  1,  0,  1,  1,  1,  0,  1, -1, -1,\n",
       "        -1, -1, -1, -1, -1,  1, -1, -1, -1,  1, -1, -1,  0, -1, -1],\n",
       "       [ 0, -1,  1,  1, -1, -1, -1, -1,  0,  0,  1, -1,  0,  1, -1, -1,\n",
       "        -1, -1, -1, -1, -1,  1, -1, -1, -1,  0, -1, -1,  0, -1, -1]],\n",
       "      dtype=int8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_observation_pfvs = np.array([symbol_to_pfv[o['symbol']]\n",
    "                                   for o in random_observation])\n",
    "random_observation_pfvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:44:56.443841Z",
     "start_time": "2020-02-19T02:44:56.426168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32768, 31)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  0, -1,  0],\n",
       "       [ 0,  0,  0, ...,  0, -1,  0],\n",
       "       [ 0,  0,  0, ...,  0, -1,  0],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0]], dtype=int8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_explanations_for_random_observation = prague.get_pfvs_whose_extension_contains(random_observation_pfvs)\n",
    "possible_explanations_for_random_observation.shape\n",
    "possible_explanations_for_random_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T03:08:35.140284Z",
     "start_time": "2020-02-19T03:08:35.131823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  1,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0, -1,  0,  1,  0, -1, -1,  0,  0, -1,  0,  0,  0], dtype=int8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=int8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_compatible_concept = choice(possible_explanations_for_random_observation)\n",
    "a_compatible_concept\n",
    "prague.extension(a_compatible_concept, unique_objects_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:15.604704Z",
     "start_time": "2020-02-19T02:01:15.603186Z"
    }
   },
   "outputs": [],
   "source": [
    "# precise_explanations_for_random_observation = prague.get_pfvs_whose_extension_is_exactly(random_observation_pfvs,\n",
    "#                                                                                          objects_np)\n",
    "# precise_explanations_for_random_observation.shape\n",
    "# precise_explanations_for_random_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:45:01.689080Z",
     "start_time": "2020-02-19T02:45:01.684210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1, -1, -1, -1,  1, -1,  0,  0,  0,  1,  1,  0,  1, -1, -1,\n",
       "        -1, -1, -1, -1, -1,  1,  1, -1, -1,  0, -1, -1,  1, -1,  1],\n",
       "       [ 0,  1,  1, -1, -1,  1, -1,  0,  0,  0,  1, -1,  0,  1,  1, -1,\n",
       "        -1, -1, -1, -1,  1,  1,  1, -1, -1,  0, -1, -1,  1, -1,  1]],\n",
       "      dtype=int8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_random_observation_pfvs = np.array([symbol_to_pfv[o['symbol']]\n",
    "                                        for o in non_random_observation])\n",
    "non_random_observation_pfvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:45:06.696776Z",
     "start_time": "2020-02-19T02:45:05.816479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2097152, 31)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  0, ...,  1, -1,  1],\n",
       "       [ 0,  0,  0, ...,  1, -1,  1],\n",
       "       [ 0,  1,  0, ...,  1, -1,  1],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  1,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0]], dtype=int8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_explanations_for_non_random_observation = prague.get_pfvs_whose_extension_contains(non_random_observation_pfvs)\n",
    "possible_explanations_for_non_random_observation.shape\n",
    "possible_explanations_for_non_random_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:45:12.266584Z",
     "start_time": "2020-02-19T02:45:12.263961Z"
    }
   },
   "outputs": [],
   "source": [
    "# precise_explanations_for_non_random_observation = prague.get_pfvs_whose_extension_is_exactly(non_random_observation_pfvs,\n",
    "#                                                                                              objects_np)\n",
    "# precise_explanations_for_non_random_observation.shape\n",
    "# precise_explanations_for_non_random_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
