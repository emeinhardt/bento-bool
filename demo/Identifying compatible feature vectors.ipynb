{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:05.305182Z",
     "start_time": "2020-02-19T02:01:05.302046Z"
    }
   },
   "outputs": [],
   "source": [
    "#Prints **all** console output, not just last item in cell \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eric Meinhardt / emeinhardt@ucsd.edu**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Motivation\" data-toc-modified-id=\"Motivation-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Motivation</a></span></li><li><span><a href=\"#Load-data\" data-toc-modified-id=\"Load-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load data</a></span></li><li><span><a href=\"#Identifying-a-possible-Boolean-concept\" data-toc-modified-id=\"Identifying-a-possible-Boolean-concept-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Identifying a possible Boolean concept</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we show `prague` can be used to identify feature vectors compatible with (or that exactly pick out) an observed set of objects, using phonology as a motivating example. Some implementation details potentially relevant for usage are also discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:05.339876Z",
     "start_time": "2020-02-19T02:01:05.312283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/cube/home/AD/emeinhar/prague\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:05.358693Z",
     "start_time": "2020-02-19T02:01:05.341541Z"
    }
   },
   "outputs": [],
   "source": [
    "from funcy import *\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:05.491467Z",
     "start_time": "2020-02-19T02:01:05.360465Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:05.622357Z",
     "start_time": "2020-02-19T02:01:05.493128Z"
    }
   },
   "outputs": [],
   "source": [
    "import prague"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:05.739608Z",
     "start_time": "2020-02-19T02:01:05.623886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bakovic_chart_riggle_hayes_remapped.tsv  brh.npy             hayes_remapped.tsv\r\n",
      "bakovic_chart_riggle_hayes.tsv           hayes_features.txt  hayes.tsv\r\n",
      "brh_features.txt                         hayes.npy\r\n"
     ]
    }
   ],
   "source": [
    "%ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:05.744986Z",
     "start_time": "2020-02-19T02:01:05.741647Z"
    }
   },
   "outputs": [],
   "source": [
    "objects_in_fp = 'data/hayes.tsv'\n",
    "objects_np_in_fp = 'data/hayes.npy'\n",
    "feature_list_fp = 'data/hayes_features.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:05.768733Z",
     "start_time": "2020-02-19T02:01:05.746726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('symbol', 'n̩'),\n",
       "              ('anterior', '+'),\n",
       "              ('approximant', '-'),\n",
       "              ('back', '0'),\n",
       "              ('consonantal', '+'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '-'),\n",
       "              ('coronal', '+'),\n",
       "              ('delayed_release', '0'),\n",
       "              ('diphthong', '0'),\n",
       "              ('distributed', '-'),\n",
       "              ('dorsal', '-'),\n",
       "              ('front', '0'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '0'),\n",
       "              ('labial', '-'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '-'),\n",
       "              ('low', '0'),\n",
       "              ('nasal', '+'),\n",
       "              ('round', '-'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '+'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '-'),\n",
       "              ('syllabic', '+'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '0'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '+')]),\n",
       " OrderedDict([('symbol', 'k͡p'),\n",
       "              ('anterior', '0'),\n",
       "              ('approximant', '-'),\n",
       "              ('back', '0'),\n",
       "              ('consonantal', '+'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '-'),\n",
       "              ('coronal', '-'),\n",
       "              ('delayed_release', '-'),\n",
       "              ('diphthong', '0'),\n",
       "              ('distributed', '0'),\n",
       "              ('dorsal', '+'),\n",
       "              ('front', '0'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '+'),\n",
       "              ('labial', '+'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '-'),\n",
       "              ('low', '-'),\n",
       "              ('nasal', '-'),\n",
       "              ('round', '-'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '-'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '0'),\n",
       "              ('syllabic', '-'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '0'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '-')]),\n",
       " OrderedDict([('symbol', 'i'),\n",
       "              ('anterior', '0'),\n",
       "              ('approximant', '+'),\n",
       "              ('back', '-'),\n",
       "              ('consonantal', '-'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '+'),\n",
       "              ('coronal', '-'),\n",
       "              ('delayed_release', '0'),\n",
       "              ('diphthong', '-'),\n",
       "              ('distributed', '0'),\n",
       "              ('dorsal', '+'),\n",
       "              ('front', '+'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '+'),\n",
       "              ('labial', '-'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '-'),\n",
       "              ('low', '-'),\n",
       "              ('nasal', '-'),\n",
       "              ('round', '-'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '+'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '0'),\n",
       "              ('syllabic', '+'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '+'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '+')])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['n̩', 'k͡p', 'i', 'ɡ͡b', 'ʑ', 'ʕ', 'ã', 'ɣ', 'ɶ̃', 'ɵː']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects = prague.load_objects(objects_in_fp)\n",
    "len(objects)\n",
    "objects[:3]\n",
    "\n",
    "symbols = [o['symbol'] for o in objects]\n",
    "symbols[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:05.773424Z",
     "start_time": "2020-02-19T02:01:05.770490Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(objects[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:05.779008Z",
     "start_time": "2020-02-19T02:01:05.774568Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list = []\n",
    "with open(feature_list_fp, 'r') as feature_file:\n",
    "    for feature in feature_file:\n",
    "        feature_list.append(feature)\n",
    "len(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:05.782385Z",
     "start_time": "2020-02-19T02:01:05.780032Z"
    }
   },
   "outputs": [],
   "source": [
    "assert len(feature_list) == len(objects[0].keys()) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:05.790029Z",
     "start_time": "2020-02-19T02:01:05.783815Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(345, 31)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('int8')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects_np = np.load(objects_np_in_fp)\n",
    "objects_np.shape\n",
    "objects_np.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:05.794222Z",
     "start_time": "2020-02-19T02:01:05.791585Z"
    }
   },
   "outputs": [],
   "source": [
    "assert objects_np.shape[1] == len(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:05.798791Z",
     "start_time": "2020-02-19T02:01:05.795548Z"
    }
   },
   "outputs": [],
   "source": [
    "assert objects_np.shape[0] == len(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:05.807344Z",
     "start_time": "2020-02-19T02:01:05.800218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('symbol', 'n̩'),\n",
       "              ('anterior', '+'),\n",
       "              ('approximant', '-'),\n",
       "              ('back', '0'),\n",
       "              ('consonantal', '+'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '-'),\n",
       "              ('coronal', '+'),\n",
       "              ('delayed_release', '0'),\n",
       "              ('diphthong', '0'),\n",
       "              ('distributed', '-'),\n",
       "              ('dorsal', '-'),\n",
       "              ('front', '0'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '0'),\n",
       "              ('labial', '-'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '-'),\n",
       "              ('low', '0'),\n",
       "              ('nasal', '+'),\n",
       "              ('round', '-'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '+'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '-'),\n",
       "              ('syllabic', '+'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '0'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '+')]),\n",
       " OrderedDict([('symbol', 'k͡p'),\n",
       "              ('anterior', '0'),\n",
       "              ('approximant', '-'),\n",
       "              ('back', '0'),\n",
       "              ('consonantal', '+'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '-'),\n",
       "              ('coronal', '-'),\n",
       "              ('delayed_release', '-'),\n",
       "              ('diphthong', '0'),\n",
       "              ('distributed', '0'),\n",
       "              ('dorsal', '+'),\n",
       "              ('front', '0'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '+'),\n",
       "              ('labial', '+'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '-'),\n",
       "              ('low', '-'),\n",
       "              ('nasal', '-'),\n",
       "              ('round', '-'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '-'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '0'),\n",
       "              ('syllabic', '-'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '0'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '-')])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:05.811706Z",
     "start_time": "2020-02-19T02:01:05.808715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, -1,  0,  1, -1, -1,  1,  0,  0, -1, -1,  0,  0,  0, -1, -1,\n",
       "        -1, -1,  0,  1, -1,  1,  1, -1, -1, -1,  1, -1,  0, -1,  1],\n",
       "       [ 0, -1,  0,  1, -1, -1, -1, -1,  0,  0,  1,  0,  0,  1,  1, -1,\n",
       "        -1, -1, -1, -1, -1,  1, -1, -1, -1,  0, -1, -1,  0, -1, -1]],\n",
       "      dtype=int8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects_np[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:05.815312Z",
     "start_time": "2020-02-19T02:01:05.812734Z"
    }
   },
   "outputs": [],
   "source": [
    "symbol_to_pfv = {o['symbol']:objects_np[i]\n",
    "                 for i,o in enumerate(objects)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying a possible Boolean concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the two sets of objects defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:05.819483Z",
     "start_time": "2020-02-19T02:01:05.816445Z"
    }
   },
   "outputs": [],
   "source": [
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:05.834036Z",
     "start_time": "2020-02-19T02:01:05.820983Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ɘ̥', 'ʑ̥', 'k̟x̟', 'oʊ']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('symbol', 'ɘ̥'),\n",
       "              ('anterior', '0'),\n",
       "              ('approximant', '+'),\n",
       "              ('back', '-'),\n",
       "              ('consonantal', '-'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '+'),\n",
       "              ('coronal', '-'),\n",
       "              ('delayed_release', '0'),\n",
       "              ('diphthong', '-'),\n",
       "              ('distributed', '0'),\n",
       "              ('dorsal', '+'),\n",
       "              ('front', '-'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '-'),\n",
       "              ('labial', '-'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '-'),\n",
       "              ('low', '-'),\n",
       "              ('nasal', '-'),\n",
       "              ('round', '-'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '+'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '0'),\n",
       "              ('syllabic', '+'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '+'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '-')]),\n",
       " OrderedDict([('symbol', 'ʑ̥'),\n",
       "              ('anterior', '+'),\n",
       "              ('approximant', '-'),\n",
       "              ('back', '-'),\n",
       "              ('consonantal', '+'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '+'),\n",
       "              ('coronal', '+'),\n",
       "              ('delayed_release', '+'),\n",
       "              ('diphthong', '0'),\n",
       "              ('distributed', '+'),\n",
       "              ('dorsal', '+'),\n",
       "              ('front', '+'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '+'),\n",
       "              ('labial', '-'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '-'),\n",
       "              ('low', '-'),\n",
       "              ('nasal', '-'),\n",
       "              ('round', '-'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '-'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '+'),\n",
       "              ('syllabic', '-'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '0'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '-')]),\n",
       " OrderedDict([('symbol', 'k̟x̟'),\n",
       "              ('anterior', '0'),\n",
       "              ('approximant', '-'),\n",
       "              ('back', '-'),\n",
       "              ('consonantal', '+'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '-'),\n",
       "              ('coronal', '-'),\n",
       "              ('delayed_release', '+'),\n",
       "              ('diphthong', '0'),\n",
       "              ('distributed', '0'),\n",
       "              ('dorsal', '+'),\n",
       "              ('front', '+'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '+'),\n",
       "              ('labial', '-'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '-'),\n",
       "              ('low', '-'),\n",
       "              ('nasal', '-'),\n",
       "              ('round', '-'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '-'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '0'),\n",
       "              ('syllabic', '-'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '0'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '-')]),\n",
       " OrderedDict([('symbol', 'oʊ'),\n",
       "              ('anterior', '0'),\n",
       "              ('approximant', '+'),\n",
       "              ('back', '+'),\n",
       "              ('consonantal', '-'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '+'),\n",
       "              ('coronal', '-'),\n",
       "              ('delayed_release', '0'),\n",
       "              ('diphthong', '+'),\n",
       "              ('distributed', '0'),\n",
       "              ('dorsal', '+'),\n",
       "              ('front', '-'),\n",
       "              ('front-diphthong', '-'),\n",
       "              ('high', '-'),\n",
       "              ('labial', '-'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '-'),\n",
       "              ('low', '-'),\n",
       "              ('nasal', '-'),\n",
       "              ('round', '+'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '+'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '+'),\n",
       "              ('strident', '0'),\n",
       "              ('syllabic', '+'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '+'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '+')])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_observations = 4\n",
    "random_observation = [choice(objects) for each in range(num_observations)]\n",
    "lmap(lambda o: o['symbol'],\n",
    "     random_observation)\n",
    "random_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:09.155317Z",
     "start_time": "2020-02-19T02:01:09.144541Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('symbol', 'j'),\n",
       "              ('anterior', '0'),\n",
       "              ('approximant', '+'),\n",
       "              ('back', '-'),\n",
       "              ('consonantal', '-'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '+'),\n",
       "              ('coronal', '-'),\n",
       "              ('delayed_release', '0'),\n",
       "              ('diphthong', '0'),\n",
       "              ('distributed', '0'),\n",
       "              ('dorsal', '+'),\n",
       "              ('front', '+'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '+'),\n",
       "              ('labial', '-'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '-'),\n",
       "              ('low', '-'),\n",
       "              ('nasal', '-'),\n",
       "              ('round', '-'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '+'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '0'),\n",
       "              ('syllabic', '-'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '+'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '+')]),\n",
       " OrderedDict([('symbol', 'w'),\n",
       "              ('anterior', '0'),\n",
       "              ('approximant', '+'),\n",
       "              ('back', '+'),\n",
       "              ('consonantal', '-'),\n",
       "              ('constricted glottis', '-'),\n",
       "              ('continuant', '+'),\n",
       "              ('coronal', '-'),\n",
       "              ('delayed_release', '0'),\n",
       "              ('diphthong', '0'),\n",
       "              ('distributed', '0'),\n",
       "              ('dorsal', '+'),\n",
       "              ('front', '-'),\n",
       "              ('front-diphthong', '0'),\n",
       "              ('high', '+'),\n",
       "              ('labial', '+'),\n",
       "              ('labiodental', '-'),\n",
       "              ('lateral', '-'),\n",
       "              ('long', '-'),\n",
       "              ('low', '-'),\n",
       "              ('nasal', '-'),\n",
       "              ('round', '+'),\n",
       "              ('segment', '+'),\n",
       "              ('sonorant', '+'),\n",
       "              ('spread glottis', '-'),\n",
       "              ('stress', '-'),\n",
       "              ('strident', '0'),\n",
       "              ('syllabic', '-'),\n",
       "              ('tap', '-'),\n",
       "              ('tense', '+'),\n",
       "              ('trill', '-'),\n",
       "              ('voice', '+')])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matching_symbols = {'t','d','p','b','k','g'} #will probably consume ALL available memory a few cells downstream\n",
    "matching_symbols = {'j','w'}\n",
    "non_random_observation = lfilter(lambda o: o['symbol'] in matching_symbols,\n",
    "                                 objects)\n",
    "len(non_random_observation)\n",
    "non_random_observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we didn't know how either set of observations were generated, but that we want to know if all of the examples in each set of observations are instances of at least one Boolean concept (i.e. plausibly generated by/instances of the same defining partial feature vector).\n",
    "\n",
    "`prague`'s main functionality is to facilitate this kind of calculation and analysis via two functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:13.104789Z",
     "start_time": "2020-02-19T02:01:13.100921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given\n",
      "        a set of observed objects (a stack of feature vectors)\n",
      "    this returns\n",
      "        the set of partial feature vectors (a stack, one vector per row)\n",
      "    whose extension must contain the set of observed objects.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(prague.get_pfvs_whose_extension_contains.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:13.378141Z",
     "start_time": "2020-02-19T02:01:13.374802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given\n",
      "        a set of observed objects (a stack of feature vectors)\n",
      "        a set of potentially observable objects (another stack of vectors)\n",
      "    this returns\n",
      "        the set of partial feature vectors (a stack, one vector per row)\n",
      "    whose extension must be exactly the set of observed objects.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(prague.get_pfvs_whose_extension_is_exactly.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:13.516738Z",
     "start_time": "2020-02-19T02:01:13.511421Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1, -1, -1, -1,  1, -1,  0, -1,  0,  1, -1,  0, -1, -1, -1,\n",
       "        -1, -1, -1, -1, -1,  1,  1, -1, -1,  0,  1, -1,  1, -1, -1],\n",
       "       [ 1, -1, -1,  1, -1,  1,  1,  1,  0,  1,  1,  1,  0,  1, -1, -1,\n",
       "        -1, -1, -1, -1, -1,  1, -1, -1, -1,  1, -1, -1,  0, -1, -1],\n",
       "       [ 0, -1, -1,  1, -1, -1, -1,  1,  0,  0,  1,  1,  0,  1, -1, -1,\n",
       "        -1, -1, -1, -1, -1,  1, -1, -1, -1,  0, -1, -1,  0, -1, -1],\n",
       "       [ 0,  1,  1, -1, -1,  1, -1,  0,  1,  0,  1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1, -1,  1,  1,  1, -1,  1,  0,  1, -1,  1, -1,  1]],\n",
       "      dtype=int8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_observation_pfvs = np.array([symbol_to_pfv[o['symbol']]\n",
    "                                   for o in random_observation])\n",
    "random_observation_pfvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:15.602162Z",
     "start_time": "2020-02-19T02:01:13.635133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048576, 31)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0, -1, ...,  1, -1, -1],\n",
       "       [ 0,  0,  0, ...,  1, -1, -1],\n",
       "       [ 0,  0, -1, ...,  1, -1, -1],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0, -1, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0]], dtype=int8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_explanations_for_random_observation = prague.get_pfvs_whose_extension_contains(random_observation_pfvs)\n",
    "possible_explanations_for_random_observation.shape\n",
    "possible_explanations_for_random_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:15.604704Z",
     "start_time": "2020-02-19T02:01:15.603186Z"
    }
   },
   "outputs": [],
   "source": [
    "# precise_explanations_for_random_observation = prague.get_pfvs_whose_extension_is_exactly(random_observation_pfvs,\n",
    "#                                                                                          objects_np)\n",
    "# precise_explanations_for_random_observation.shape\n",
    "# precise_explanations_for_random_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:17.733879Z",
     "start_time": "2020-02-19T02:01:17.729134Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1, -1, -1, -1,  1, -1,  0,  0,  0,  1,  1,  0,  1, -1, -1,\n",
       "        -1, -1, -1, -1, -1,  1,  1, -1, -1,  0, -1, -1,  1, -1,  1],\n",
       "       [ 0,  1,  1, -1, -1,  1, -1,  0,  0,  0,  1, -1,  0,  1,  1, -1,\n",
       "        -1, -1, -1, -1,  1,  1,  1, -1, -1,  0, -1, -1,  1, -1,  1]],\n",
       "      dtype=int8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_random_observation_pfvs = np.array([symbol_to_pfv[o['symbol']]\n",
    "                                        for o in non_random_observation])\n",
    "non_random_observation_pfvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:01:22.472077Z",
     "start_time": "2020-02-19T02:01:21.711460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2097152, 31)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  0, ...,  1, -1,  1],\n",
       "       [ 0,  0,  0, ...,  1, -1,  1],\n",
       "       [ 0,  1,  0, ...,  1, -1,  1],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  1,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0]], dtype=int8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_explanations_for_non_random_observation = prague.get_pfvs_whose_extension_contains(non_random_observation_pfvs)\n",
    "possible_explanations_for_non_random_observation.shape\n",
    "possible_explanations_for_non_random_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T02:02:18.290833Z",
     "start_time": "2020-02-19T02:01:26.459453Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,345) (2097152,345) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-8b46d17ab50c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m precise_explanations_for_non_random_observation = prague.get_pfvs_whose_extension_is_exactly(non_random_observation_pfvs,\n\u001b[0;32m----> 2\u001b[0;31m                                                                                              objects_np)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprecise_explanations_for_non_random_observation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprecise_explanations_for_non_random_observation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/home/AD/emeinhar/prague/prague/feature_vector.py\u001b[0m in \u001b[0;36mget_pfvs_whose_extension_is_exactly\u001b[0;34m(observed_objects, object_inventory)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     matching_extensions = np.equal(observed_objects_as_extension,\n\u001b[0;32m--> 485\u001b[0;31m                                    my_extensions).prod(axis=1)\n\u001b[0m\u001b[1;32m    486\u001b[0m     \u001b[0mselection_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatching_extensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0mmatching_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,345) (2097152,345) "
     ]
    }
   ],
   "source": [
    "precise_explanations_for_non_random_observation = prague.get_pfvs_whose_extension_is_exactly(non_random_observation_pfvs,\n",
    "                                                                                             objects_np)\n",
    "precise_explanations_for_non_random_observation.shape\n",
    "precise_explanations_for_non_random_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
