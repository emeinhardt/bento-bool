{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:24.539615Z",
     "start_time": "2020-02-27T18:04:24.536307Z"
    }
   },
   "outputs": [],
   "source": [
    "#Prints **all** console output, not just last item in cell \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eric Meinhardt / emeinhardt@ucsd.edu**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Motivation\" data-toc-modified-id=\"Motivation-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Motivation</a></span></li><li><span><a href=\"#Load-data\" data-toc-modified-id=\"Load-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Combinatoric-summary\" data-toc-modified-id=\"Combinatoric-summary-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Combinatoric summary</a></span></li></ul></li><li><span><a href=\"#Identifying-a-possible-Boolean-concept\" data-toc-modified-id=\"Identifying-a-possible-Boolean-concept-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Identifying a possible Boolean concept</a></span></li><li><span><a href=\"#General-case\" data-toc-modified-id=\"General-case-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>General case</a></span><ul class=\"toc-item\"><li><span><a href=\"#Demo\" data-toc-modified-id=\"Demo-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Demo</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we show `prague` can be used to identify feature vectors compatible with (or that exactly pick out) an observed set of objects, using phonology as a motivating example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that on the current test dataset (`brh.py`), the machine running this notebook will probably need (at peak) 20-30GB of RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:24.640331Z",
     "start_time": "2020-02-27T18:04:24.543936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/cube/home/AD/emeinhar/prague\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:24.698818Z",
     "start_time": "2020-02-27T18:04:24.641669Z"
    }
   },
   "outputs": [],
   "source": [
    "from funcy import *\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:24.965718Z",
     "start_time": "2020-02-27T18:04:24.700405Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.218232Z",
     "start_time": "2020-02-27T18:04:24.967347Z"
    }
   },
   "outputs": [],
   "source": [
    "import prague"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.344613Z",
     "start_time": "2020-02-27T18:04:25.219772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bakovic_chart_riggle_hayes_remapped.tsv  brh.npy             hayes_remapped.tsv\r\n",
      "bakovic_chart_riggle_hayes.tsv           hayes_features.txt  hayes.tsv\r\n",
      "brh_features.txt                         hayes.npy\r\n"
     ]
    }
   ],
   "source": [
    "%ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.349407Z",
     "start_time": "2020-02-27T18:04:25.346325Z"
    }
   },
   "outputs": [],
   "source": [
    "# objects_in_fp = 'data/hayes.tsv'\n",
    "# objects_np_in_fp = 'data/hayes.npy'\n",
    "# feature_list_fp = 'data/hayes_features.txt'\n",
    "\n",
    "objects_in_fp = 'data/bakovic_chart_riggle_hayes.tsv'\n",
    "objects_np_in_fp = 'data/brh.npy'\n",
    "feature_list_fp = 'data/brh_features.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.369219Z",
     "start_time": "2020-02-27T18:04:25.350854Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('symbol', 'p'),\n",
       "              ('syll', '-'),\n",
       "              ('cons', '+'),\n",
       "              ('son', '-'),\n",
       "              ('labial', '+'),\n",
       "              ('coronal', '-'),\n",
       "              ('dorsal', '-'),\n",
       "              ('voice', '-'),\n",
       "              ('cont', '-'),\n",
       "              ('del. rel.', '-'),\n",
       "              ('ant', '0'),\n",
       "              ('dist', '0'),\n",
       "              ('strid', '0'),\n",
       "              ('high', '0'),\n",
       "              ('low', '0'),\n",
       "              ('back', '0'),\n",
       "              ('front', '0'),\n",
       "              ('approx', '-'),\n",
       "              ('nas', '-'),\n",
       "              ('lat', '-'),\n",
       "              ('s.g.', '-'),\n",
       "              ('c.g.', '-'),\n",
       "              ('round', '0'),\n",
       "              ('ATR', '0')]),\n",
       " OrderedDict([('symbol', 'b'),\n",
       "              ('syll', '-'),\n",
       "              ('cons', '+'),\n",
       "              ('son', '-'),\n",
       "              ('labial', '+'),\n",
       "              ('coronal', '-'),\n",
       "              ('dorsal', '-'),\n",
       "              ('voice', '+'),\n",
       "              ('cont', '-'),\n",
       "              ('del. rel.', '-'),\n",
       "              ('ant', '0'),\n",
       "              ('dist', '0'),\n",
       "              ('strid', '0'),\n",
       "              ('high', '0'),\n",
       "              ('low', '0'),\n",
       "              ('back', '0'),\n",
       "              ('front', '0'),\n",
       "              ('approx', '-'),\n",
       "              ('nas', '-'),\n",
       "              ('lat', '-'),\n",
       "              ('s.g.', '-'),\n",
       "              ('c.g.', '-'),\n",
       "              ('round', '0'),\n",
       "              ('ATR', '0')]),\n",
       " OrderedDict([('symbol', 'ɸ'),\n",
       "              ('syll', '-'),\n",
       "              ('cons', '+'),\n",
       "              ('son', '-'),\n",
       "              ('labial', '+'),\n",
       "              ('coronal', '-'),\n",
       "              ('dorsal', '-'),\n",
       "              ('voice', '-'),\n",
       "              ('cont', '+'),\n",
       "              ('del. rel.', '+'),\n",
       "              ('ant', '0'),\n",
       "              ('dist', '+'),\n",
       "              ('strid', '-'),\n",
       "              ('high', '0'),\n",
       "              ('low', '0'),\n",
       "              ('back', '0'),\n",
       "              ('front', '0'),\n",
       "              ('approx', '-'),\n",
       "              ('nas', '-'),\n",
       "              ('lat', '-'),\n",
       "              ('s.g.', '-'),\n",
       "              ('c.g.', '-'),\n",
       "              ('round', '0'),\n",
       "              ('ATR', '0')])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['p', 'b', 'ɸ', 'β', 'f', 'v', 't̪', 'd̪', 'θ', 'ð']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects = prague.load_objects(objects_in_fp)\n",
    "len(objects)\n",
    "objects[:3]\n",
    "\n",
    "symbols = [o['symbol'] for o in objects]\n",
    "symbols[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.373369Z",
     "start_time": "2020-02-27T18:04:25.370765Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(objects[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.379900Z",
     "start_time": "2020-02-27T18:04:25.374836Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list = []\n",
    "with open(feature_list_fp, 'r') as feature_file:\n",
    "    for feature in feature_file:\n",
    "        feature_list.append(feature.strip())\n",
    "len(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.384099Z",
     "start_time": "2020-02-27T18:04:25.381168Z"
    }
   },
   "outputs": [],
   "source": [
    "assert len(feature_list) == len(objects[0].keys()) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.391935Z",
     "start_time": "2020-02-27T18:04:25.385413Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 23)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "dtype('int8')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects_np = np.load(objects_np_in_fp)\n",
    "objects_np.shape\n",
    "objects_np.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.395793Z",
     "start_time": "2020-02-27T18:04:25.393248Z"
    }
   },
   "outputs": [],
   "source": [
    "assert objects_np.shape[1] == len(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.399960Z",
     "start_time": "2020-02-27T18:04:25.397035Z"
    }
   },
   "outputs": [],
   "source": [
    "assert objects_np.shape[0] == len(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.408450Z",
     "start_time": "2020-02-27T18:04:25.401188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('symbol', 'p'),\n",
       "              ('syll', '-'),\n",
       "              ('cons', '+'),\n",
       "              ('son', '-'),\n",
       "              ('labial', '+'),\n",
       "              ('coronal', '-'),\n",
       "              ('dorsal', '-'),\n",
       "              ('voice', '-'),\n",
       "              ('cont', '-'),\n",
       "              ('del. rel.', '-'),\n",
       "              ('ant', '0'),\n",
       "              ('dist', '0'),\n",
       "              ('strid', '0'),\n",
       "              ('high', '0'),\n",
       "              ('low', '0'),\n",
       "              ('back', '0'),\n",
       "              ('front', '0'),\n",
       "              ('approx', '-'),\n",
       "              ('nas', '-'),\n",
       "              ('lat', '-'),\n",
       "              ('s.g.', '-'),\n",
       "              ('c.g.', '-'),\n",
       "              ('round', '0'),\n",
       "              ('ATR', '0')]),\n",
       " OrderedDict([('symbol', 'b'),\n",
       "              ('syll', '-'),\n",
       "              ('cons', '+'),\n",
       "              ('son', '-'),\n",
       "              ('labial', '+'),\n",
       "              ('coronal', '-'),\n",
       "              ('dorsal', '-'),\n",
       "              ('voice', '+'),\n",
       "              ('cont', '-'),\n",
       "              ('del. rel.', '-'),\n",
       "              ('ant', '0'),\n",
       "              ('dist', '0'),\n",
       "              ('strid', '0'),\n",
       "              ('high', '0'),\n",
       "              ('low', '0'),\n",
       "              ('back', '0'),\n",
       "              ('front', '0'),\n",
       "              ('approx', '-'),\n",
       "              ('nas', '-'),\n",
       "              ('lat', '-'),\n",
       "              ('s.g.', '-'),\n",
       "              ('c.g.', '-'),\n",
       "              ('round', '0'),\n",
       "              ('ATR', '0')])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.413070Z",
     "start_time": "2020-02-27T18:04:25.409738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0, -1,  0, -1,  1, -1, -1, -1,  0, -1,  0,  0,  1, -1,  0,\n",
       "        -1,  0, -1, -1,  0, -1, -1],\n",
       "       [ 0,  0, -1,  0, -1,  1, -1, -1, -1,  0, -1,  0,  0,  1, -1,  0,\n",
       "        -1,  0, -1, -1,  0, -1,  1]], dtype=int8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects_np[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.417007Z",
     "start_time": "2020-02-27T18:04:25.414298Z"
    }
   },
   "outputs": [],
   "source": [
    "symbol_to_fv = {o['symbol']:objects_np[i]\n",
    "                for i,o in enumerate(objects)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.423899Z",
     "start_time": "2020-02-27T18:04:25.418274Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 23)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(91, 23)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects_np.shape\n",
    "unique_objects_np = np.unique(objects_np, axis=0)\n",
    "unique_objects_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.462729Z",
     "start_time": "2020-02-27T18:04:25.425185Z"
    }
   },
   "outputs": [],
   "source": [
    "fv_to_symbols_map = {prague.HashableArray(fv):{s for s in symbol_to_fv\n",
    "                                               if np.array_equal(fv, symbol_to_fv[s])}\n",
    "                     for fv in unique_objects_np}\n",
    "\n",
    "def fv_to_symbols(fv):\n",
    "    return fv_to_symbols_map[prague.HashableArray(fv)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.468307Z",
     "start_time": "2020-02-27T18:04:25.463676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ħ'},\n",
       " {'ʕ'},\n",
       " {'ə', 'ɜ'},\n",
       " {'ɞ'},\n",
       " {'ɛ'},\n",
       " {'a'},\n",
       " {'œ'},\n",
       " {'ɶ'},\n",
       " {'ɪ'},\n",
       " {'ʏ'},\n",
       " {'ʌ'},\n",
       " {'ɑ'},\n",
       " {'ɔ'},\n",
       " {'ɒ'},\n",
       " {'ʊ'},\n",
       " {'ʈ'},\n",
       " {'ɖ'},\n",
       " {'ɳ'},\n",
       " {'ʧ'},\n",
       " {'ʤ'},\n",
       " {'ʂ'},\n",
       " {'ʐ'},\n",
       " {'ʃ'},\n",
       " {'ʒ'},\n",
       " {'ɽ'},\n",
       " {'ɭ'},\n",
       " {'c'},\n",
       " {'ɟ'},\n",
       " {'ɲ'},\n",
       " {'ç'},\n",
       " {'ʝ'},\n",
       " {'h'},\n",
       " {'ɦ'},\n",
       " {'p'},\n",
       " {'b'},\n",
       " {'m', 'ɱ'},\n",
       " {'f'},\n",
       " {'v'},\n",
       " {'ɸ'},\n",
       " {'β'},\n",
       " {'ʔ'},\n",
       " {'q'},\n",
       " {'ɢ'},\n",
       " {'k'},\n",
       " {'ɡ'},\n",
       " {'ɴ'},\n",
       " {'ŋ'},\n",
       " {'χ'},\n",
       " {'ʁ'},\n",
       " {'x'},\n",
       " {'ɣ'},\n",
       " {'j'},\n",
       " {'ʎ'},\n",
       " {'ʋ'},\n",
       " {'ⱱ'},\n",
       " {'ʙ'},\n",
       " {'w', 'ɥ'},\n",
       " {'ʟ'},\n",
       " {'ʀ'},\n",
       " {'t'},\n",
       " {'d'},\n",
       " {'t̪'},\n",
       " {'d̪'},\n",
       " {'n'},\n",
       " {'n̪'},\n",
       " {'ʦ'},\n",
       " {'ʣ'},\n",
       " {'s'},\n",
       " {'z'},\n",
       " {'θ'},\n",
       " {'ð'},\n",
       " {'ɹ'},\n",
       " {'ɻ'},\n",
       " {'ɾ'},\n",
       " {'l'},\n",
       " {'l̪'},\n",
       " {'r'},\n",
       " {'ɘ'},\n",
       " {'ɐ'},\n",
       " {'ɵ'},\n",
       " {'ɨ'},\n",
       " {'ʉ'},\n",
       " {'e'},\n",
       " {'æ'},\n",
       " {'ø'},\n",
       " {'i'},\n",
       " {'y'},\n",
       " {'ɤ'},\n",
       " {'o'},\n",
       " {'ɯ'},\n",
       " {'u'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_symbols = [fv_to_symbols(fv) for fv in unique_objects_np]\n",
    "index_to_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.472897Z",
     "start_time": "2020-02-27T18:04:25.469150Z"
    }
   },
   "outputs": [],
   "source": [
    "def extension_to_symbols(extension):\n",
    "    return np.array(index_to_symbols)[extension.nonzero()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.480834Z",
     "start_time": "2020-02-27T18:04:25.473804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('symbol', 'i'),\n",
       "              ('syll', '+'),\n",
       "              ('cons', '-'),\n",
       "              ('son', '+'),\n",
       "              ('labial', '-'),\n",
       "              ('coronal', '-'),\n",
       "              ('dorsal', '+'),\n",
       "              ('voice', '+'),\n",
       "              ('cont', '+'),\n",
       "              ('del. rel.', '0'),\n",
       "              ('ant', '0'),\n",
       "              ('dist', '0'),\n",
       "              ('strid', '0'),\n",
       "              ('high', '+'),\n",
       "              ('low', '-'),\n",
       "              ('back', '-'),\n",
       "              ('front', '+'),\n",
       "              ('approx', '+'),\n",
       "              ('nas', '-'),\n",
       "              ('lat', '-'),\n",
       "              ('s.g.', '-'),\n",
       "              ('c.g.', '-'),\n",
       "              ('round', '-'),\n",
       "              ('ATR', '+')])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def symbol_to_fd(symbol):\n",
    "    return [fd for fd in objects if fd['symbol'] == symbol]\n",
    "\n",
    "symbol_to_fd('i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.485202Z",
     "start_time": "2020-02-27T18:04:25.482182Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ATR',\n",
       " 'ant',\n",
       " 'approx',\n",
       " 'back',\n",
       " 'c.g.',\n",
       " 'cons',\n",
       " 'cont',\n",
       " 'coronal',\n",
       " 'del. rel.',\n",
       " 'dist',\n",
       " 'dorsal',\n",
       " 'front',\n",
       " 'high',\n",
       " 'labial',\n",
       " 'lat',\n",
       " 'low',\n",
       " 'nas',\n",
       " 'round',\n",
       " 's.g.',\n",
       " 'son',\n",
       " 'strid',\n",
       " 'syll',\n",
       " 'voice']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.492946Z",
     "start_time": "2020-02-27T18:04:25.488692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ATR': 1,\n",
       " 'ant': -1,\n",
       " 'approx': 1,\n",
       " 'back': 0,\n",
       " 'c.g.': 1,\n",
       " 'cons': 0,\n",
       " 'cont': 0,\n",
       " 'coronal': -1,\n",
       " 'del. rel.': -1,\n",
       " 'dist': 0,\n",
       " 'dorsal': 1,\n",
       " 'front': 1,\n",
       " 'high': 1,\n",
       " 'labial': 1,\n",
       " 'lat': 1,\n",
       " 'low': 0,\n",
       " 'nas': 1,\n",
       " 'round': 1,\n",
       " 's.g.': -1,\n",
       " 'son': 1,\n",
       " 'strid': 0,\n",
       " 'syll': 0,\n",
       " 'voice': 0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pfv_to_fd(pfv):\n",
    "    return dict(zip(feature_list, pfv))\n",
    "\n",
    "pfv_to_fd(prague.feature_vector.make_random_pfv(len(feature_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.497494Z",
     "start_time": "2020-02-27T18:04:25.494538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ATR': '-',\n",
       " 'ant': '0',\n",
       " 'approx': '-',\n",
       " 'back': '0',\n",
       " 'c.g.': '0',\n",
       " 'cons': '+',\n",
       " 'cont': '+',\n",
       " 'coronal': '-',\n",
       " 'del. rel.': '-',\n",
       " 'dist': '+',\n",
       " 'dorsal': '0',\n",
       " 'front': '-',\n",
       " 'high': '+',\n",
       " 'labial': '-',\n",
       " 'lat': '-',\n",
       " 'low': '-',\n",
       " 'nas': '+',\n",
       " 'round': '0',\n",
       " 's.g.': '-',\n",
       " 'son': '+',\n",
       " 'strid': '-',\n",
       " 'syll': '0',\n",
       " 'voice': '0'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#more verbose\n",
    "prague.feature_vector.to_feature_dict(feature_list,\n",
    "                                      prague.feature_vector.make_random_pfv(len(feature_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinatoric summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.507289Z",
     "start_time": "2020-02-27T18:04:25.498335Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|O| = 94 distinct object types (including labels)'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'23 object features'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'8.39E+06 logically possible object feature vectors'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'|V| = 91 distinct object feature vectors'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'2.48E+27 possible subsets of V'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'9.41E+10 possible partial feature vectors'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"|O| = {len(objects)} distinct object types (including labels)\"\n",
    "f\"{unique_objects_np.shape[1]} object features\"\n",
    "\"{0:.2E} logically possible object feature vectors\".format(2**unique_objects_np.shape[1])\n",
    "f\"|V| = {unique_objects_np.shape[0]} distinct object feature vectors\"\n",
    "\"{0:.2E} possible subsets of V\".format(2**unique_objects_np.shape[0])\n",
    "\"{0:.2E} possible partial feature vectors\".format(3**unique_objects_np.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying a possible Boolean concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the two sets of objects defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.510571Z",
     "start_time": "2020-02-27T18:04:25.508503Z"
    }
   },
   "outputs": [],
   "source": [
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.521148Z",
     "start_time": "2020-02-27T18:04:25.511806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n', 'l', 'ʔ', 'ʌ']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('symbol', 'n'),\n",
       "              ('syll', '-'),\n",
       "              ('cons', '+'),\n",
       "              ('son', '+'),\n",
       "              ('labial', '-'),\n",
       "              ('coronal', '+'),\n",
       "              ('dorsal', '-'),\n",
       "              ('voice', '+'),\n",
       "              ('cont', '-'),\n",
       "              ('del. rel.', '0'),\n",
       "              ('ant', '+'),\n",
       "              ('dist', '-'),\n",
       "              ('strid', '0'),\n",
       "              ('high', '0'),\n",
       "              ('low', '0'),\n",
       "              ('back', '0'),\n",
       "              ('front', '0'),\n",
       "              ('approx', '-'),\n",
       "              ('nas', '+'),\n",
       "              ('lat', '-'),\n",
       "              ('s.g.', '-'),\n",
       "              ('c.g.', '-'),\n",
       "              ('round', '0'),\n",
       "              ('ATR', '0')]),\n",
       " OrderedDict([('symbol', 'l'),\n",
       "              ('syll', '-'),\n",
       "              ('cons', '+'),\n",
       "              ('son', '+'),\n",
       "              ('labial', '-'),\n",
       "              ('coronal', '+'),\n",
       "              ('dorsal', '-'),\n",
       "              ('voice', '+'),\n",
       "              ('cont', '-'),\n",
       "              ('del. rel.', '0'),\n",
       "              ('ant', '+'),\n",
       "              ('dist', '-'),\n",
       "              ('strid', '0'),\n",
       "              ('high', '0'),\n",
       "              ('low', '0'),\n",
       "              ('back', '0'),\n",
       "              ('front', '0'),\n",
       "              ('approx', '+'),\n",
       "              ('nas', '-'),\n",
       "              ('lat', '+'),\n",
       "              ('s.g.', '-'),\n",
       "              ('c.g.', '-'),\n",
       "              ('round', '0'),\n",
       "              ('ATR', '0')]),\n",
       " OrderedDict([('symbol', 'ʔ'),\n",
       "              ('syll', '-'),\n",
       "              ('cons', '-'),\n",
       "              ('son', '-'),\n",
       "              ('labial', '-'),\n",
       "              ('coronal', '-'),\n",
       "              ('dorsal', '-'),\n",
       "              ('voice', '-'),\n",
       "              ('cont', '-'),\n",
       "              ('del. rel.', '-'),\n",
       "              ('ant', '0'),\n",
       "              ('dist', '0'),\n",
       "              ('strid', '0'),\n",
       "              ('high', '0'),\n",
       "              ('low', '0'),\n",
       "              ('back', '0'),\n",
       "              ('front', '0'),\n",
       "              ('approx', '-'),\n",
       "              ('nas', '-'),\n",
       "              ('lat', '-'),\n",
       "              ('s.g.', '-'),\n",
       "              ('c.g.', '+'),\n",
       "              ('round', '0'),\n",
       "              ('ATR', '0')]),\n",
       " OrderedDict([('symbol', 'ʌ'),\n",
       "              ('syll', '+'),\n",
       "              ('cons', '-'),\n",
       "              ('son', '+'),\n",
       "              ('labial', '-'),\n",
       "              ('coronal', '-'),\n",
       "              ('dorsal', '+'),\n",
       "              ('voice', '+'),\n",
       "              ('cont', '+'),\n",
       "              ('del. rel.', '0'),\n",
       "              ('ant', '0'),\n",
       "              ('dist', '0'),\n",
       "              ('strid', '0'),\n",
       "              ('high', '-'),\n",
       "              ('low', '-'),\n",
       "              ('back', '+'),\n",
       "              ('front', '-'),\n",
       "              ('approx', '+'),\n",
       "              ('nas', '-'),\n",
       "              ('lat', '-'),\n",
       "              ('s.g.', '-'),\n",
       "              ('c.g.', '-'),\n",
       "              ('round', '-'),\n",
       "              ('ATR', '-')])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_observations = 4\n",
    "random_observation = [choice(objects) for each in range(num_observations)]\n",
    "lmap(lambda o: o['symbol'],\n",
    "     random_observation)\n",
    "random_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.526916Z",
     "start_time": "2020-02-27T18:04:25.522023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('symbol', 'w'),\n",
       "              ('syll', '-'),\n",
       "              ('cons', '-'),\n",
       "              ('son', '+'),\n",
       "              ('labial', '+'),\n",
       "              ('coronal', '-'),\n",
       "              ('dorsal', '+'),\n",
       "              ('voice', '+'),\n",
       "              ('cont', '+'),\n",
       "              ('del. rel.', '0'),\n",
       "              ('ant', '0'),\n",
       "              ('dist', '0'),\n",
       "              ('strid', '0'),\n",
       "              ('high', '+'),\n",
       "              ('low', '-'),\n",
       "              ('back', '+'),\n",
       "              ('front', '-'),\n",
       "              ('approx', '+'),\n",
       "              ('nas', '-'),\n",
       "              ('lat', '-'),\n",
       "              ('s.g.', '-'),\n",
       "              ('c.g.', '-'),\n",
       "              ('round', '+'),\n",
       "              ('ATR', '0')]),\n",
       " OrderedDict([('symbol', 'j'),\n",
       "              ('syll', '-'),\n",
       "              ('cons', '-'),\n",
       "              ('son', '+'),\n",
       "              ('labial', '-'),\n",
       "              ('coronal', '-'),\n",
       "              ('dorsal', '+'),\n",
       "              ('voice', '+'),\n",
       "              ('cont', '+'),\n",
       "              ('del. rel.', '0'),\n",
       "              ('ant', '0'),\n",
       "              ('dist', '0'),\n",
       "              ('strid', '0'),\n",
       "              ('high', '+'),\n",
       "              ('low', '-'),\n",
       "              ('back', '-'),\n",
       "              ('front', '+'),\n",
       "              ('approx', '+'),\n",
       "              ('nas', '-'),\n",
       "              ('lat', '-'),\n",
       "              ('s.g.', '-'),\n",
       "              ('c.g.', '-'),\n",
       "              ('round', '-'),\n",
       "              ('ATR', '0')])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matching_symbols = {'t','d','p','b','k','g'} #will probably consume ALL available memory a few cells downstream\n",
    "matching_symbols = {'j','w'}\n",
    "non_random_observation = lfilter(lambda o: o['symbol'] in matching_symbols,\n",
    "                                 objects)\n",
    "len(non_random_observation)\n",
    "non_random_observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we didn't know how either set of observations were generated, but that we want to know if all of the examples in each set of observations are instances of at least one Boolean concept (i.e. plausibly generated by/instances of the same defining partial feature vector).\n",
    "\n",
    "`prague`'s main functionality is to facilitate this kind of calculation and analysis via two functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.529955Z",
     "start_time": "2020-02-27T18:04:25.527791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Given\n",
      "        a set of observed objects (a stack of feature vectors)\n",
      "    this returns\n",
      "        the set of partial feature vectors (a stack, one vector per row)\n",
      "    whose extension must contain the set of observed objects.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(prague.get_pfvs_whose_extension_contains.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.534424Z",
     "start_time": "2020-02-27T18:04:25.531179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Given\n",
      "        a set of observed objects (a stack of feature vectors)\n",
      "        a set of potentially observable objects (another stack of vectors)\n",
      "    this returns\n",
      "        the set of partial feature vectors (a stack, one vector per row)\n",
      "    whose extension must be exactly the set of observed objects.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(prague.get_pfvs_whose_extension_is_exactly.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use these functions, we first (for each set of observations) map each object to its associated NumPy vector representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.539773Z",
     "start_time": "2020-02-27T18:04:25.535635Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1, -1,  0, -1,  1, -1,  1,  0, -1, -1,  0,  0, -1, -1,  0,\n",
       "         1,  0, -1,  1,  0, -1,  1],\n",
       "       [ 0,  1,  1,  0, -1,  1, -1,  1,  0, -1, -1,  0,  0, -1,  1,  0,\n",
       "        -1,  0, -1,  1,  0, -1,  1],\n",
       "       [ 0,  0, -1,  0,  1, -1, -1, -1, -1,  0, -1,  0,  0, -1, -1,  0,\n",
       "        -1,  0, -1, -1,  0, -1, -1],\n",
       "       [-1,  0,  1,  1, -1, -1,  1, -1,  0,  0,  1, -1, -1, -1, -1, -1,\n",
       "        -1, -1, -1,  1,  0,  1,  1]], dtype=int8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_observation_pfvs = np.array([symbol_to_fv[o['symbol']]\n",
    "                                   for o in random_observation])\n",
    "random_observation_pfvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the random observation set is random from run to run of the notebook, your specific results (if you execute this notebook locally) may vary, but in general, there will be thousands of partial feature vectors (= conjunctive normal form formulas = restricted Boolean concepts) that are compatible with (i.e. could have given rise to) this observation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.545626Z",
     "start_time": "2020-02-27T18:04:25.540890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 23)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,\n",
       "         0,  0, -1,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0, -1,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0]], dtype=int8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_explanations_for_random_observation = prague.get_pfvs_whose_extension_contains(random_observation_pfvs)\n",
    "possible_explanations_for_random_observation.shape\n",
    "possible_explanations_for_random_observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.553842Z",
     "start_time": "2020-02-27T18:04:25.546752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: the random observation = \n",
      "['n', 'l', 'ʔ', 'ʌ']\n",
      "A possible partial feature vector that could have given rise to this observation:\n",
      "{'labial': '-'}\n",
      "The total set of observations that exhibit this concept:\n",
      " {'ʈ', 'χ', 'ɑ', 'æ', 'ɻ', 'ɡ', 'i', 'ɹ', 'ħ', 'ʃ', 'ɽ', 'n', 'a', 'ɪ', 'ʔ', 'ʂ', 'x', 'ɨ', 'ʎ', 'l̪', 'ɟ', 'ʁ', 'ɛ', 's', 'ɾ', 'ʣ', 'ð', 'd', 'd̪', 'q', 'ɤ', 'r', 'ʊ', 'ɐ', 'ʟ', 'ʝ', 'ɯ', 'ɴ', 'ç', 'k', 'z', 'ʤ', 'ʒ', 'θ', 'ə', 'ɲ', 'ʀ', 'ɦ', 'ɘ', 'c', 't̪', 'ʦ', 'l', 'ɖ', 'ʐ', 'ɳ', 'ŋ', 'ɭ', 'ʌ', 'ɢ', 'ʕ', 'ɜ', 'e', 'ɣ', 'ʧ', 't', 'n̪', 'h', 'j'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Recall: the random observation = \\n{lmap(lambda o: o['symbol'], random_observation)}\")\n",
    "a_compatible_concept = choice(possible_explanations_for_random_observation)\n",
    "print(\"A possible partial feature vector that could have given rise to this observation:\\n\"\n",
    "#       f\"{a_compatible_concept}\\n\"\n",
    "      \"{0}\".format({feature_list[i]:{-1:'-',1:'+'}[v] for i,v in enumerate(a_compatible_concept) if v in {1,-1}}))\n",
    "      \n",
    "compatible_concept_extension_vector = prague.extension(a_compatible_concept, \n",
    "                                                       unique_objects_np)\n",
    "compatible_concept_extension_as_objects = prague.extension_vector_to_objects(compatible_concept_extension_vector, \n",
    "                                                                             unique_objects_np)\n",
    "compatible_concept_extension_as_symbols = reduce(set.union, \n",
    "                                                 lmap(fv_to_symbols, \n",
    "                                                      compatible_concept_extension_as_objects), \n",
    "                                                 set())\n",
    "      \n",
    "print(\"The total set of observations that exhibit this concept:\\n\",\n",
    "      f\"{compatible_concept_extension_as_symbols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.559708Z",
     "start_time": "2020-02-27T18:04:25.555080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 23)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 23), dtype=int8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precise_explanations_for_random_observation = prague.get_pfvs_whose_extension_is_exactly(random_observation_pfvs,\n",
    "                                                                                         objects_np)\n",
    "precise_explanations_for_random_observation.shape\n",
    "precise_explanations_for_random_observation\n",
    "\n",
    "#This will usually be empty: most subsets of the set of logically possible objects\n",
    "# can't be described by a formula in conjunctive normal form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.563404Z",
     "start_time": "2020-02-27T18:04:25.560563Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  1,  1, -1, -1,  1, -1,  0,  0,  1, -1,  1,  1, -1, -1,\n",
       "        -1,  1, -1,  1,  0, -1,  1],\n",
       "       [ 0,  0,  1, -1, -1, -1,  1, -1,  0,  0,  1,  1,  1, -1, -1, -1,\n",
       "        -1, -1, -1,  1,  0, -1,  1]], dtype=int8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_random_observation_pfvs = np.array([symbol_to_fv[o['symbol']]\n",
    "                                        for o in non_random_observation])\n",
    "non_random_observation_pfvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.575501Z",
     "start_time": "2020-02-27T18:04:25.564268Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16384, 23)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  1, ...,  0, -1,  1],\n",
       "       [ 0,  0,  0, ...,  0, -1,  1],\n",
       "       [ 0,  0,  1, ...,  0, -1,  1],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  0,  0,  0],\n",
       "       [ 0,  0,  1, ...,  0,  0,  0],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0]], dtype=int8)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_explanations_for_non_random_observation = prague.get_pfvs_whose_extension_contains(non_random_observation_pfvs)\n",
    "possible_explanations_for_non_random_observation.shape\n",
    "possible_explanations_for_non_random_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.680198Z",
     "start_time": "2020-02-27T18:04:25.576673Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4672, 23)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  1, ...,  0, -1,  1],\n",
       "       [ 0,  0,  0, ...,  0, -1,  1],\n",
       "       [ 0,  0,  1, ...,  0, -1,  1],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  0, -1,  0],\n",
       "       [ 0,  0,  0, ...,  0, -1,  0],\n",
       "       [ 0,  0,  0, ...,  0, -1,  0]], dtype=int8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precise_explanations_for_non_random_observation = prague.get_pfvs_whose_extension_is_exactly(non_random_observation_pfvs,\n",
    "                                                                                             objects_np)\n",
    "precise_explanations_for_non_random_observation.shape\n",
    "precise_explanations_for_non_random_observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.690645Z",
     "start_time": "2020-02-27T18:04:25.681308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0, -1,\n",
       "         0,  0,  0,  0,  0, -1,  0],\n",
       "       [ 0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0, -1,  0],\n",
       "       [ 0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0, -1,  0]], dtype=int8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(3, 23)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ATR': 0, 'ant': 0, 'approx': 0, 'back': 0, 'c.g.': 0, 'cons': -1, 'cont': 0, 'coronal': 0, 'del. rel.': 0, 'dist': 0, 'dorsal': 0, 'front': 0, 'high': 0, 'labial': 0, 'lat': 0, 'low': -1, 'nas': 0, 'round': 0, 's.g.': 0, 'son': 0, 'strid': 0, 'syll': -1, 'voice': 0}\n",
      "{'ATR': 0, 'ant': 0, 'approx': 0, 'back': 0, 'c.g.': 0, 'cons': -1, 'cont': 0, 'coronal': 0, 'del. rel.': 0, 'dist': 0, 'dorsal': 0, 'front': 0, 'high': 1, 'labial': 0, 'lat': 0, 'low': 0, 'nas': 0, 'round': 0, 's.g.': 0, 'son': 0, 'strid': 0, 'syll': -1, 'voice': 0}\n",
      "{'ATR': 0, 'ant': 0, 'approx': 0, 'back': 0, 'c.g.': 0, 'cons': -1, 'cont': 0, 'coronal': 0, 'del. rel.': 0, 'dist': 0, 'dorsal': 1, 'front': 0, 'high': 0, 'labial': 0, 'lat': 0, 'low': 0, 'nas': 0, 'round': 0, 's.g.': 0, 'son': 0, 'strid': 0, 'syll': -1, 'voice': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([{'j'}, {'w', 'ɥ'}], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([{'j'}, {'w', 'ɥ'}], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([{'j'}, {'w', 'ɥ'}], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree_of_specification_of_exact_matches = np.abs(precise_explanations_for_non_random_observation).sum(axis=1)\n",
    "minimal_specification_of_exact_matches = np.min(degree_of_specification_of_exact_matches)\n",
    "minimal_specification_of_exact_matches\n",
    "minimal_pfvs_that_are_exact_matches = precise_explanations_for_non_random_observation[degree_of_specification_of_exact_matches == minimal_specification_of_exact_matches]\n",
    "minimal_pfvs_that_are_exact_matches\n",
    "minimal_pfvs_that_are_exact_matches.shape\n",
    "\n",
    "for each_pfv in minimal_pfvs_that_are_exact_matches:\n",
    "    print(pfv_to_fd(each_pfv))\n",
    "    \n",
    "for each_pfv in minimal_pfvs_that_are_exact_matches:\n",
    "    each_ext = prague.extension(each_pfv, unique_objects_np)\n",
    "    extension_to_symbols(each_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.712966Z",
     "start_time": "2020-02-27T18:04:25.691410Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:25.826346Z",
     "start_time": "2020-02-27T18:04:25.714138Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           125G        606M        124G        3.0M        1.0G        124G\r\n",
      "Swap:          2.0G          0B        2.0G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:31.620223Z",
     "start_time": "2020-02-27T18:04:25.828024Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91/91 [00:05<00:00, 15.73it/s]\n"
     ]
    }
   ],
   "source": [
    "#7s on wittgenstein\n",
    "lower_closures = [prague.lower_closure(o, strict=False) \n",
    "                  for o in tqdm(unique_objects_np)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:04:31.666433Z",
     "start_time": "2020-02-27T18:04:31.621471Z"
    }
   },
   "outputs": [],
   "source": [
    "lower_closures_as_matrix = np.concatenate(lower_closures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:06:38.959878Z",
     "start_time": "2020-02-27T18:04:31.667738Z"
    }
   },
   "outputs": [],
   "source": [
    "#2m on wittgenstein\n",
    "all_pfvs_with_nonempty_extension = np.unique(lower_closures_as_matrix, \n",
    "                                             return_index=False,\n",
    "                                             axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:06:38.964282Z",
     "start_time": "2020-02-27T18:06:38.961157Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9115112, 23)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pfvs_with_nonempty_extension.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:06:38.971747Z",
     "start_time": "2020-02-27T18:06:38.965555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# partial feature vectors that pick out a non-empty subset of O: 9.12E+06\n",
      " # logically possible partial feature vectors: 9.41E+10\n"
     ]
    }
   ],
   "source": [
    "print(\"# partial feature vectors that pick out a non-empty subset of O: \"\n",
    "      \"{0:.2E}\\n\".format(all_pfvs_with_nonempty_extension.shape[0]),\n",
    "      \"# logically possible partial feature vectors: \"\n",
    "      \"{0:.2E}\".format(3**all_pfvs_with_nonempty_extension.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:06:39.130393Z",
     "start_time": "2020-02-27T18:06:38.973106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           125G        1.9G        122G        3.0M        1.0G        122G\r\n",
      "Swap:          2.0G          0B        2.0G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:06:39.134259Z",
     "start_time": "2020-02-27T18:06:39.132082Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2m on wittgenstein\n",
    "# unique_lower_closures = set(lmap(prague.HashableArray,\n",
    "#                                  list(lower_closures_as_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:06:39.273606Z",
     "start_time": "2020-02-27T18:06:39.135665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           125G        1.9G        122G        3.0M        1.0G        122G\r\n",
      "Swap:          2.0G          0B        2.0G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:06:39.277932Z",
     "start_time": "2020-02-27T18:06:39.275647Z"
    }
   },
   "outputs": [],
   "source": [
    "# >>>2m on wittgenstein, uses way too much memory\n",
    "# unique_lower_closures2 = set(lmap(prague.HashableArray,\n",
    "#                                   cat(map(list, lower_closures_as_matrix))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:06:39.451779Z",
     "start_time": "2020-02-27T18:06:39.279600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           125G        1.9G        122G        3.0M        1.0G        122G\r\n",
      "Swap:          2.0G          0B        2.0G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:07:27.206559Z",
     "start_time": "2020-02-27T18:06:39.453451Z"
    }
   },
   "outputs": [],
   "source": [
    "#48s on wittgenstein\n",
    "nonempty_pfv_extensions = prague.extensions(all_pfvs_with_nonempty_extension,\n",
    "                                            object_inventory=unique_objects_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:07:27.211357Z",
     "start_time": "2020-02-27T18:07:27.207895Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9115112, 91)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonempty_pfv_extensions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:07:27.363363Z",
     "start_time": "2020-02-27T18:07:27.212782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:           125G        2.8G        122G        3.0M        1.0G        122G\r\n",
      "Swap:          2.0G          0B        2.0G\r\n"
     ]
    }
   ],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:07:27.518742Z",
     "start_time": "2020-02-27T18:07:27.364997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My random PFV = [-1  0  0  0 -1 -1  0  0  0  0  0 -1 -1 -1  0  0  0  0  0  0  0  1  1]\n",
      "My random PFV as a feature dict =\n",
      "{'ATR': -1, 'ant': 0, 'approx': 0, 'back': 0, 'c.g.': -1, 'cons': -1, 'cont': 0, 'coronal': 0, 'del. rel.': 0, 'dist': 0, 'dorsal': 0, 'front': -1, 'high': -1, 'labial': -1, 'lat': 0, 'low': 0, 'nas': 0, 'round': 0, 's.g.': 0, 'son': 0, 'strid': 0, 'syll': 1, 'voice': 1}\n",
      "My extension as an 'indicator' vector = \n",
      "[0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "My extension as a stack of 3 objects S = \n",
      "[[-1  0  1 -1 -1 -1  1 -1  0  0  1 -1 -1 -1 -1 -1 -1 -1 -1  1  0  1  1]\n",
      " [-1  0  1  1 -1 -1  1 -1  0  0  1 -1 -1 -1 -1 -1 -1 -1 -1  1  0  1  1]\n",
      " [-1  0  1  1 -1 -1  1 -1  0  0  1 -1 -1 -1 -1  1 -1 -1 -1  1  0  1  1]]\n",
      "My extension as a set of matching symbols = \n",
      "{'ɜ', 'ʌ', 'ə', 'ɑ'}\n",
      "My extension as a set of feature dicts = \n",
      " [{'ATR': -1, 'ant': 0, 'approx': 1, 'back': -1, 'c.g.': -1, 'cons': -1, 'cont': 1, 'coronal': -1, 'del. rel.': 0, 'dist': 0, 'dorsal': 1, 'front': -1, 'high': -1, 'labial': -1, 'lat': -1, 'low': -1, 'nas': -1, 'round': -1, 's.g.': -1, 'son': 1, 'strid': 0, 'syll': 1, 'voice': 1}, {'ATR': -1, 'ant': 0, 'approx': 1, 'back': 1, 'c.g.': -1, 'cons': -1, 'cont': 1, 'coronal': -1, 'del. rel.': 0, 'dist': 0, 'dorsal': 1, 'front': -1, 'high': -1, 'labial': -1, 'lat': -1, 'low': -1, 'nas': -1, 'round': -1, 's.g.': -1, 'son': 1, 'strid': 0, 'syll': 1, 'voice': 1}, {'ATR': -1, 'ant': 0, 'approx': 1, 'back': 1, 'c.g.': -1, 'cons': -1, 'cont': 1, 'coronal': -1, 'del. rel.': 0, 'dist': 0, 'dorsal': 1, 'front': -1, 'high': -1, 'labial': -1, 'lat': -1, 'low': 1, 'nas': -1, 'round': -1, 's.g.': -1, 'son': 1, 'strid': 0, 'syll': 1, 'voice': 1}]\n"
     ]
    }
   ],
   "source": [
    "a_random_pfv = prague.feature_vector.make_random_pfv(num_features=len(feature_list))\n",
    "random_extension = prague.extension(a_random_pfv, \n",
    "                                    object_inventory=unique_objects_np)\n",
    "random_objects = prague.extension_vector_to_objects(random_extension, \n",
    "                                                    object_inventory=unique_objects_np)\n",
    "# random_symbols = extension_to_symbols(random_extension)\n",
    "random_symbols = reduce(set.union, extension_to_symbols(random_extension), set())\n",
    "my_x = random_extension\n",
    "my_S = random_objects\n",
    "my_symbs = random_symbols\n",
    "my_fd = pfv_to_fd(a_random_pfv)\n",
    "my_symbs_fds = [pfv_to_fd(pfv) for pfv in my_S]\n",
    "\n",
    "\n",
    "while my_x.sum() == 0:\n",
    "    a_random_pfv = prague.feature_vector.make_random_pfv(num_features=len(feature_list))\n",
    "    random_extension = prague.extension(a_random_pfv, \n",
    "                                        object_inventory=unique_objects_np)\n",
    "    random_objects = prague.extension_vector_to_objects(random_extension, \n",
    "                                                        object_inventory=unique_objects_np)\n",
    "#     random_symbols = extension_to_symbols(random_extension)\n",
    "    random_symbols = reduce(set.union, extension_to_symbols(random_extension), set())\n",
    "    my_x = random_extension\n",
    "    my_S = random_objects\n",
    "    my_symbs = random_symbols\n",
    "    my_fd = pfv_to_fd(a_random_pfv)\n",
    "    my_symbs_fds = [pfv_to_fd(pfv) for pfv in my_S]\n",
    "\n",
    "\n",
    "print(f\"My random PFV = {a_random_pfv}\")\n",
    "print(f\"My random PFV as a feature dict =\\n{my_fd}\")\n",
    "print(f\"My extension as an 'indicator' vector = \\n{my_x}\")\n",
    "print(f\"My extension as a stack of {my_S.shape[0]} objects S = \\n{my_S}\")\n",
    "print(f\"My extension as a set of matching symbols = \\n{my_symbs}\")\n",
    "print(f\"My extension as a set of feature dicts = \\n\",\n",
    "      my_symbs_fds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:07:28.301005Z",
     "start_time": "2020-02-27T18:07:27.519974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131,072 PFVs whose extension contains S = \n",
      "[[-1  0  1 ...  0  1  1]\n",
      " [ 0  0  1 ...  0  1  1]\n",
      " [-1  0  0 ...  0  1  1]\n",
      " ...\n",
      " [ 0  0  1 ...  0  0  0]\n",
      " [-1  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      "12,032 PFVs whose extension is exactly S = \n",
      "[[-1  0  1 ...  0  1  1]\n",
      " [-1  0  0 ...  0  1  1]\n",
      " [-1  0  1 ...  0  1  1]\n",
      " ...\n",
      " [-1  0  1 ...  0  0  0]\n",
      " [-1  0  1 ...  0  0  0]\n",
      " [-1  0  0 ...  0  0  0]]\n",
      "1 PFVs whose extension is exactly S and which are maximally simple (i.e. unspecified) = \n",
      "[[-1  0  0  0  0  0  0  0  0  0  0 -1 -1  0  0  0  0 -1  0  0  0  0  0]]\n",
      "original generating pfv = \n",
      " [-1  0  0  0 -1 -1  0  0  0  0  0 -1 -1 -1  0  0  0  0  0  0  0  1  1]\n"
     ]
    }
   ],
   "source": [
    "pfvs_containing_my_S = prague.get_pfvs_whose_extension_contains(my_S)\n",
    "pfvs_exactly_matching_my_S = prague.get_pfvs_whose_extension_is_exactly(my_S, \n",
    "                                                                        object_inventory=unique_objects_np)\n",
    "specification_of_exact_matches = np.abs(pfvs_exactly_matching_my_S).sum(axis=1)\n",
    "minimal_specification = np.min(specification_of_exact_matches)\n",
    "minimal_pfvs_exactly_matching_my_s = pfvs_exactly_matching_my_S[specification_of_exact_matches == minimal_specification]\n",
    "\n",
    "print(\"{0:,} PFVs\".format(pfvs_containing_my_S.shape[0]),\n",
    "      f\"whose extension contains S = \\n{pfvs_containing_my_S}\")\n",
    "print(\"{0:,} PFVs\".format(pfvs_exactly_matching_my_S.shape[0]),\n",
    "      f\"whose extension is exactly S = \\n{pfvs_exactly_matching_my_S}\")\n",
    "print(\"{0:,} PFVs\".format(minimal_pfvs_exactly_matching_my_s.shape[0]),\n",
    "      f\"whose extension is exactly S and which are maximally simple\"\n",
    "      f\" (i.e. unspecified) = \\n{minimal_pfvs_exactly_matching_my_s}\")\n",
    "print(f\"original generating pfv = \\n {a_random_pfv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:07:28.305826Z",
     "start_time": "2020-02-27T18:07:28.301887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(prague.extension(a_random_pfv, unique_objects_np))\n",
    "for each_exact_match in minimal_pfvs_exactly_matching_my_s:\n",
    "    print(prague.extension(each_exact_match, unique_objects_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-27T18:07:28.314637Z",
     "start_time": "2020-02-27T18:07:28.307062Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'ɜ', 'ə'}, {'ʌ'}, {'ɑ'}], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([{'ɜ', 'ə'}, {'ʌ'}, {'ɑ'}], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extension_to_symbols(prague.extension(a_random_pfv, unique_objects_np))\n",
    "for each_exact_match in minimal_pfvs_exactly_matching_my_s:\n",
    "    extension_to_symbols(prague.extension(each_exact_match, unique_objects_np))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
