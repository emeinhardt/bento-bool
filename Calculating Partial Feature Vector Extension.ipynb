{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Overview</a></span><ul class=\"toc-item\"><li><span><a href=\"#Motivation\" data-toc-modified-id=\"Motivation-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Motivation</a></span></li><li><span><a href=\"#Use-cases\" data-toc-modified-id=\"Use-cases-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Use cases</a></span></li><li><span><a href=\"#Implementation\" data-toc-modified-id=\"Implementation-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Implementation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Objects,-subsets,-feature-vectors-and-feature-space\" data-toc-modified-id=\"Objects,-subsets,-feature-vectors-and-feature-space-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Objects, subsets, feature vectors and feature space</a></span></li><li><span><a href=\"#Key-Operations\" data-toc-modified-id=\"Key-Operations-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Key Operations</a></span></li><li><span><a href=\"#Key-Identities-and-Intuitions-for-Dynamic-Programming\" data-toc-modified-id=\"Key-Identities-and-Intuitions-for-Dynamic-Programming-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>Key Identities and Intuitions for Dynamic Programming</a></span></li></ul></li><li><span><a href=\"#Todo:\" data-toc-modified-id=\"Todo:-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Todo:</a></span></li></ul></li><li><span><a href=\"#Create-a-set-of-observed-objects-drawn-from-a-binary-feature-space\" data-toc-modified-id=\"Create-a-set-of-observed-objects-drawn-from-a-binary-feature-space-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Create a set of observed objects drawn from a binary feature space</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-a-binary-feature-space\" data-toc-modified-id=\"Define-a-binary-feature-space-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Define a binary feature space</a></span></li><li><span><a href=\"#Create-some-objects\" data-toc-modified-id=\"Create-some-objects-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Create some objects</a></span></li></ul></li><li><span><a href=\"#Define-the-extensions-of-partial-vectors\" data-toc-modified-id=\"Define-the-extensions-of-partial-vectors-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Define the extensions of partial vectors</a></span><ul class=\"toc-item\"><li><span><a href=\"#How-do-the-two-methods-for-calculating-extensions-compare?\" data-toc-modified-id=\"How-do-the-two-methods-for-calculating-extensions-compare?-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>How do the two methods for calculating extensions compare?</a></span><ul class=\"toc-item\"><li><span><a href=\"#Is-the-non-naive-method-correct?\" data-toc-modified-id=\"Is-the-non-naive-method-correct?-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Is the non-naive method correct?</a></span></li></ul></li><li><span><a href=\"#Is-the-non-naive-method-faster?\" data-toc-modified-id=\"Is-the-non-naive-method-faster?-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Is the non-naive method faster?</a></span></li></ul></li><li><span><a href=\"#Sketch-inductive-calculation-of-the-extensions-of-increasingly-complex-partial-feature-vectors-in-terms-of-simpler,-already-calculated-ones\" data-toc-modified-id=\"Sketch-inductive-calculation-of-the-extensions-of-increasingly-complex-partial-feature-vectors-in-terms-of-simpler,-already-calculated-ones-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Sketch inductive calculation of the extensions of increasingly complex partial feature vectors in terms of simpler, already calculated ones</a></span><ul class=\"toc-item\"><li><span><a href=\"#Agreement/conflict\" data-toc-modified-id=\"Agreement/conflict-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Agreement/conflict</a></span></li><li><span><a href=\"#Union-of-partial-feature-vectors-in-agreement\" data-toc-modified-id=\"Union-of-partial-feature-vectors-in-agreement-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Union of partial feature vectors in agreement</a></span></li><li><span><a href=\"#Inductive-calculation-of-extensions\" data-toc-modified-id=\"Inductive-calculation-of-extensions-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Inductive calculation of extensions</a></span></li></ul></li><li><span><a href=\"#Matrix-operations\" data-toc-modified-id=\"Matrix-operations-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Matrix operations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Representing-$S_i$\" data-toc-modified-id=\"Representing-$S_i$-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Representing $S_i$</a></span><ul class=\"toc-item\"><li><span><a href=\"#Complexity-calculations\" data-toc-modified-id=\"Complexity-calculations-5.1.1\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>Complexity calculations</a></span></li><li><span><a href=\"#Constructing-$S_i$\" data-toc-modified-id=\"Constructing-$S_i$-5.1.2\"><span class=\"toc-item-num\">5.1.2&nbsp;&nbsp;</span>Constructing $S_i$</a></span></li><li><span><a href=\"#Constructing-$\\overline{S}_i$-given-$S_{i-1}$-or-$\\overline{S}_{i-1}$\" data-toc-modified-id=\"Constructing-$\\overline{S}_i$-given-$S_{i-1}$-or-$\\overline{S}_{i-1}$-5.1.3\"><span class=\"toc-item-num\">5.1.3&nbsp;&nbsp;</span>Constructing $\\overline{S}_i$ given $S_{i-1}$ or $\\overline{S}_{i-1}$</a></span></li></ul></li><li><span><a href=\"#Decomposing-$S_i$\" data-toc-modified-id=\"Decomposing-$S_i$-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Decomposing $S_i$</a></span></li><li><span><a href=\"#Calculating-$X_i-=-⟦S_i⟧$:-$S_i-=-B-\\cup-V-\\iff-⟦S_i⟧-=-⟦B⟧-\\cap-⟦V⟧$\" data-toc-modified-id=\"Calculating-$X_i-=-⟦S_i⟧$:-$S_i-=-B-\\cup-V-\\iff-⟦S_i⟧-=-⟦B⟧-\\cap-⟦V⟧$-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Calculating $X_i = ⟦S_i⟧$: $S_i = B \\cup V \\iff ⟦S_i⟧ = ⟦B⟧ \\cap ⟦V⟧$</a></span></li><li><span><a href=\"#Compressing-arrays-and-matrices\" data-toc-modified-id=\"Compressing-arrays-and-matrices-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Compressing arrays and matrices</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sparse-representations\" data-toc-modified-id=\"Sparse-representations-5.4.1\"><span class=\"toc-item-num\">5.4.1&nbsp;&nbsp;</span>Sparse representations</a></span></li><li><span><a href=\"#bitarrays\" data-toc-modified-id=\"bitarrays-5.4.2\"><span class=\"toc-item-num\">5.4.2&nbsp;&nbsp;</span><code>bitarray</code>s</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:04.580597Z",
     "start_time": "2019-05-01T16:10:02.900960Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "myint = np.int8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:04.585384Z",
     "start_time": "2019-05-01T16:10:04.583016Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import product, combinations, starmap\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:05.446906Z",
     "start_time": "2019-05-01T16:10:04.586943Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "J = 15\n",
    "BACKEND = 'multiprocessing'\n",
    "# BACKEND = 'loky'\n",
    "V = 10\n",
    "PREFER = 'processes'\n",
    "# PREFER = 'threads'\n",
    "\n",
    "def par(gen_expr, j=None, backend=None, verbose=None, prefer=None):\n",
    "    if j is None:\n",
    "        j = J\n",
    "    if backend is None:\n",
    "        backend = BACKEND\n",
    "    if verbose is None:\n",
    "        verbose = V\n",
    "    if prefer is None:\n",
    "        prefer = PREFER\n",
    "    return Parallel(n_jobs=j, backend=backend, verbose=verbose, prefer=prefer)(gen_expr)\n",
    "\n",
    "def identity(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:05.450862Z",
     "start_time": "2019-05-01T16:10:05.448886Z"
    }
   },
   "outputs": [],
   "source": [
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:05.857439Z",
     "start_time": "2019-05-01T16:10:05.453406Z"
    }
   },
   "outputs": [],
   "source": [
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager().update('notebook', {'limit_output': 100000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:05.861811Z",
     "start_time": "2019-05-01T16:10:05.859252Z"
    }
   },
   "outputs": [],
   "source": [
    "# from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:05.868932Z",
     "start_time": "2019-05-01T16:10:05.863241Z"
    }
   },
   "outputs": [],
   "source": [
    "def np2t(numpy_arrays):\n",
    "    return tuple(map(tuple, numpy_arrays))\n",
    "\n",
    "def t2np(tuples):\n",
    "    return np.array(tuple(map(np.array, tuples)), dtype=myint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:06.595340Z",
     "start_time": "2019-05-01T16:10:05.870457Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.special import binom#, comb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "The goal of this notebook is producing a script that, given a list of observed fully specified feature vectors (i.e. an inventory of observed objects described as feature vectors), can pre-calculate (i.e. write to file) the extension of large numbers of partial feature vectors for subsequent use. \n",
    "\n",
    "Examples of such uses include:\n",
    " - quickly looking up **all** partial feature vectors with some particular extension.\n",
    " - finding the set of **minimal** partial feature vectors with some particular extension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Given a file containing a sequence of fully specified feature vectors, calculate the extension of every logically possible partial feature vector.\n",
    "2. Given a file containing a sequence of fully specified feature vectors, calculate the extension of every partial feature vector with a non-empty extension.\n",
    "3. Given a file containing a sequence of fully specified feature vectors and a file containing a set of partially specified feature vectors, calculate the extension of every partial feature vector in the second file.\n",
    "\n",
    "Currently, only use case 1 is supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a computationally difficult problem, so on top of \n",
    " - choosing a method of calculation (dynamic programming) to take advantage of substructure and shared computations\n",
    "\n",
    "the goal is to make as many representations numpy arrays and as many operations vector or matrix operations that can be done via highly optimized linear algebra libraries and taking advantage of any available GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objects, subsets, feature vectors and feature space\n",
    "\n",
    " - The number of features is assumed to be fixed and known a priori.\n",
    " - A **fully specified feature vector** represents **an object**, or, more precisely, it represents a subset of all possible objects that can contain **at most** one object. In the simplest case, an object is a vector of $-1$s and $+1$s.\n",
    " - A **partially specified feature vector** represents **a set of objects**, or more precisely, a subset of the set of all possible objects. In general, a partial feature vector (or \"subset vector\") is a vector of $0$s, $-1$s, or $+1$s.\n",
    " - With respect to a particular set $O$ of $|O| = l$ observed objects (= fully specified feature vectors), the **extension** of a partial feature vector $⟦v⟧^O$ (or just \"$⟦v⟧$\" when $O$ is clear from context) is given by a vector in $\\{0,1\\}^l$, where $⟦v⟧_j = 1$ iff $o_j \\in ⟦v⟧$ and $⟦v⟧_j = 0$ otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The use of $-1$, $0$, and $+1$ facilitates vector operations for calculating \n",
    " - the **intersection of the extensions** of two partial feature vectors.\n",
    " - the **combination ('union') of the specifications** of two partial feature vectors.\n",
    " - the relationship between these two things."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As explained in more detail below, if two partial feature vectors $u, v$ don't have any conflicting feature values (i.e. $\\not \\exists j.(u_j = +1 \\land v_j = -1) \\lor (u_j = -1 \\land v_j = +1)$, then \n",
    " - the combination - **union** - of two partial feature vectors can be calculated as `union(u,v) = sign(u + v)` where `+` is vector addition and sign takes a vector and returns a vector indicating the sign (-1, 0, or +1) of its input at each index. Ex: `union(<1, 0, -1>, <1,-1,0>) = <1,-1,-1>`.\n",
    " - the **intersection** of two partial feature vectors can be calculated as `intersection(u,v) = sign(equal(u, v) * (u + v))`, where `+`, `*`, `equal`, and `sign` are all element-wise functions on vectors. Ex: `intersection(<1, 0, -1>, <1,-1,0>) = <1,0,0>`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Identities and Intuitions for Dynamic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides being vector-based representations that can be efficiently calculated and parallelized, there is an identity relating the decomposition of partial feature vectors and the decomposition of their extensions that permits an efficient calculation of the extension of more complex feature vectors in terms of the extensions of simpler component  partial feature vectors:\n",
    "$$⟦u \\cup v⟧ = ⟦u⟧ \\cap ⟦v⟧$$\n",
    "\n",
    "It is easy to construct --- or decompose --- any more complex partial feature vector $s$ as the union of a vector $b$ with only one non-zero bit with some (in general) more complex partial vector $v$ (i.e. $v$ has >=1 non-zero bits). Accordingly, the interpretation $⟦s⟧$ of every partial feature vector with $i > 1$ non-zero bits $s \\in S_i$ can be calculated by choosing a decomposition $s = b \\cup v$ (with $b \\in S_1$, $v \\in S_{i-1}$) and then calculating $⟦s⟧$ as $⟦b⟧ \\cap ⟦v⟧$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo:\n",
    "\n",
    "**Basic**\n",
    " 0. Support naive file IO.\n",
    " 1. *Space complexity/data structures:* Determine what data structures + operations would be best to support downstream use (e.g. presumably emphasizing speed of access and use over storage space).\n",
    " 2. *Space complexity:* Write code to support not calculating and/or not storing any partial feature vector with an empty extension. Useful first step might be writing code to count the number of such partial feature vectors.\n",
    "\n",
    "**Optimization Tarpit**\n",
    " 0. *Space complexity:* The more features there are, the sparser extension vectors will be - sparse representations should probably be used at least for storage. (I have no idea how efficient operations on sparse representations are, but I imagine they're generally slower than on dense representations unless perhaps you have a very large *and* very sparse matrix.)\n",
    " 1. *Core representations + processes:* Maybe there are more efficient integer-vector representations and operations (union + intersection) than I chose?\n",
    " 2. *Core representations + processes:* Maybe manipulating some bit-based representation (see the `bitarray`, `bitstring`, and `BitVector` packages) would be more time efficient?\n",
    " 3. *Parallelism + space complexity:* Time joblib + do numpy memory mapping of sufficiently small chunks of each $S_i$ at a time.\n",
    " 4. *Parallelism:* Try pytorch cpu (+ joblib) and gpu representations.\n",
    " 5. *Parallelism + space complexity:* Use Dask - get it to do more of the work wrt deciding how to store small chunks of very large arrays.\n",
    " 6. *Parallelism + space complexity:* Use Dask - restructure calculations to take better advantage of laziness in deciding what computations to do.\n",
    " \n",
    "ctrl/cmd+f for \"TODO\" throughout the notebook..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a set of observed objects drawn from a binary feature space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a binary feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:06.612166Z",
     "start_time": "2019-05-01T16:10:06.597131Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "59049"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = 10\n",
    "\n",
    "basis_vectors_pos = [np.zeros(num_features, dtype=myint) for each in range(num_features)]\n",
    "basis_vectors_neg = [np.zeros(num_features, dtype=myint) for each in range(num_features)]\n",
    "for i,v in enumerate(basis_vectors_pos):\n",
    "    v[i] = 1\n",
    "for i,v in enumerate(basis_vectors_neg):\n",
    "    v[i] = -1\n",
    "basis_vectors = basis_vectors_pos + basis_vectors_neg\n",
    "\n",
    "max_num_objects = 2 ** num_features\n",
    "max_num_objects\n",
    "\n",
    "max_num_partial_fvs = (2 + 1) ** num_features\n",
    "max_num_partial_fvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:06.626099Z",
     "start_time": "2019-05-01T16:10:06.613316Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int8),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int8),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0], dtype=int8),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0], dtype=int8),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0], dtype=int8),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int8),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0], dtype=int8),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int8),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0], dtype=int8),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=int8),\n",
       " array([-1,  0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int8),\n",
       " array([ 0, -1,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int8),\n",
       " array([ 0,  0, -1,  0,  0,  0,  0,  0,  0,  0], dtype=int8),\n",
       " array([ 0,  0,  0, -1,  0,  0,  0,  0,  0,  0], dtype=int8),\n",
       " array([ 0,  0,  0,  0, -1,  0,  0,  0,  0,  0], dtype=int8),\n",
       " array([ 0,  0,  0,  0,  0, -1,  0,  0,  0,  0], dtype=int8),\n",
       " array([ 0,  0,  0,  0,  0,  0, -1,  0,  0,  0], dtype=int8),\n",
       " array([ 0,  0,  0,  0,  0,  0,  0, -1,  0,  0], dtype=int8),\n",
       " array([ 0,  0,  0,  0,  0,  0,  0,  0, -1,  0], dtype=int8),\n",
       " array([ 0,  0,  0,  0,  0,  0,  0,  0,  0, -1], dtype=int8)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basis_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create some objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:06.636075Z",
     "start_time": "2019-05-01T16:10:06.627787Z"
    }
   },
   "outputs": [],
   "source": [
    "def wffv(v):\n",
    "    allowedValues = {-1,0,1}\n",
    "    return all([x in allowedValues for x in v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:06.648938Z",
     "start_time": "2019-05-01T16:10:06.637942Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actual_num_objects = np.random.randint(max_num_objects)\n",
    "actual_num_objects = 20\n",
    "actual_num_objects\n",
    "\n",
    "assert actual_num_objects < max_num_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:06.663553Z",
     "start_time": "2019-05-01T16:10:06.650298Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(array([-1, -1, -1,  1,  1,  1,  1,  1, -1, -1]),\n",
       " array([-1,  1,  1, -1,  1,  1,  1, -1,  1,  1]),\n",
       " array([-1,  1, -1,  1, -1,  1,  1,  1,  1, -1]),\n",
       " array([-1,  1,  1,  1, -1, -1,  1, -1,  1, -1]),\n",
       " array([-1, -1,  1, -1, -1,  1, -1, -1,  1,  1]),\n",
       " array([ 1, -1, -1,  1, -1,  1, -1,  1, -1, -1]),\n",
       " array([ 1,  1,  1,  1,  1, -1,  1, -1, -1, -1]),\n",
       " array([-1,  1,  1,  1,  1, -1,  1, -1, -1, -1]),\n",
       " array([-1, -1, -1,  1, -1, -1, -1, -1, -1, -1]),\n",
       " array([-1, -1,  1, -1, -1,  1,  1, -1,  1,  1]),\n",
       " array([-1,  1,  1,  1, -1,  1,  1,  1, -1, -1]),\n",
       " array([-1, -1,  1, -1, -1,  1, -1,  1, -1, -1]),\n",
       " array([-1, -1, -1, -1, -1,  1,  1,  1,  1, -1]),\n",
       " array([-1, -1,  1, -1, -1,  1,  1, -1, -1, -1]),\n",
       " array([-1, -1,  1, -1,  1, -1,  1,  1,  1, -1]),\n",
       " array([ 1, -1, -1, -1, -1,  1, -1, -1,  1,  1]),\n",
       " array([ 1, -1, -1, -1,  1, -1, -1, -1,  1, -1]),\n",
       " array([-1,  1, -1, -1,  1, -1, -1,  1, -1,  1]),\n",
       " array([-1, -1,  1,  1, -1,  1,  1, -1,  1, -1]),\n",
       " array([-1, -1,  1, -1, -1, -1, -1, -1, -1,  1]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects = tuple(set([tuple(np.random.randint(2, size=num_features)) for each in range(actual_num_objects)]))\n",
    "objects = tuple(map(np.array, objects))\n",
    "\n",
    "def zeroToMinusOne(u):\n",
    "    return np.array([x if x == 1 else -1 for x in u])\n",
    "objects = tuple([zeroToMinusOne(o) for o in objects])\n",
    "\n",
    "actual_num_objects = len(objects)\n",
    "actual_num_objects\n",
    "objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:06.672168Z",
     "start_time": "2019-05-01T16:10:06.665038Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[-1, -1, -1,  1,  1,  1,  1,  1, -1, -1],\n",
       "       [-1,  1,  1, -1,  1,  1,  1, -1,  1,  1],\n",
       "       [-1,  1, -1,  1, -1,  1,  1,  1,  1, -1],\n",
       "       [-1,  1,  1,  1, -1, -1,  1, -1,  1, -1],\n",
       "       [-1, -1,  1, -1, -1,  1, -1, -1,  1,  1],\n",
       "       [ 1, -1, -1,  1, -1,  1, -1,  1, -1, -1],\n",
       "       [ 1,  1,  1,  1,  1, -1,  1, -1, -1, -1],\n",
       "       [-1,  1,  1,  1,  1, -1,  1, -1, -1, -1],\n",
       "       [-1, -1, -1,  1, -1, -1, -1, -1, -1, -1],\n",
       "       [-1, -1,  1, -1, -1,  1,  1, -1,  1,  1],\n",
       "       [-1,  1,  1,  1, -1,  1,  1,  1, -1, -1],\n",
       "       [-1, -1,  1, -1, -1,  1, -1,  1, -1, -1],\n",
       "       [-1, -1, -1, -1, -1,  1,  1,  1,  1, -1],\n",
       "       [-1, -1,  1, -1, -1,  1,  1, -1, -1, -1],\n",
       "       [-1, -1,  1, -1,  1, -1,  1,  1,  1, -1],\n",
       "       [ 1, -1, -1, -1, -1,  1, -1, -1,  1,  1],\n",
       "       [ 1, -1, -1, -1,  1, -1, -1, -1,  1, -1],\n",
       "       [-1,  1, -1, -1,  1, -1, -1,  1, -1,  1],\n",
       "       [-1, -1,  1,  1, -1,  1,  1, -1,  1, -1],\n",
       "       [-1, -1,  1, -1, -1, -1, -1, -1, -1,  1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1,  1,  1,  1,  1,  1, -1, -1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objectMap = np.array([objects[i] for i in range(len(objects))])\n",
    "objectMap.shape\n",
    "objectMap\n",
    "objectMap[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:06.677398Z",
     "start_time": "2019-05-01T16:10:06.673673Z"
    }
   },
   "outputs": [],
   "source": [
    "def getIndex(o):\n",
    "    matches = [i for i,v in enumerate(objectMap) if np.array_equal(v,o)]\n",
    "    if len(matches) == 0:\n",
    "        return -1\n",
    "    assert len(matches) == 1\n",
    "    return matches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:06.683380Z",
     "start_time": "2019-05-01T16:10:06.679059Z"
    }
   },
   "outputs": [],
   "source": [
    "def makeExtensionVector(positive_Indices):\n",
    "    return np.array([1 if i in positive_Indices else 0 for i in np.arange(objectMap.shape[0])], dtype=myint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:06.691276Z",
     "start_time": "2019-05-01T16:10:06.684501Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "makeExtensionVector([0, 4, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the extensions of partial vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:06.703597Z",
     "start_time": "2019-05-01T16:10:06.696026Z"
    }
   },
   "outputs": [],
   "source": [
    "# @njit\n",
    "def agree(u,v):\n",
    "    '''\n",
    "    Given two vectors u and v, returns a binary vector indicating,\n",
    "    elementwise, whether u and v 'agree'.\n",
    "    \n",
    "    agree(u[i], v[i]) iff (u[i] == 0 or v[i] == 0) or (u[i] == v[i])\n",
    "    '''\n",
    "#     return np.array([True if (u[i] == 0 or v[i] == 0) or (u[i] == v[i]) else False \n",
    "#                      for i in range(len(u))])\n",
    "    return np.array([1 if (u[i] == 0 or v[i] == 0) or (u[i] == v[i]) else 0 \n",
    "                     for i in range(len(u))])\n",
    "\n",
    "# @njit\n",
    "def agree_(u,v):\n",
    "    ag = agree(u,v)\n",
    "    total_agreement = np.linalg.norm(agree(u,v), 1) == num_features\n",
    "    return int(total_agreement)\n",
    "#     if total_agreement:\n",
    "#         return 1.0\n",
    "#     return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:06.713092Z",
     "start_time": "2019-05-01T16:10:06.709383Z"
    }
   },
   "outputs": [],
   "source": [
    "# @njit\n",
    "# def extension_naive_njit(v):\n",
    "#     matches = np.array([agree_(v,o) for o in objects])\n",
    "#     return matches\n",
    "\n",
    "# @njit\n",
    "def extension_naive(v, asIndexVector=True):\n",
    "    '''\n",
    "    The extension of a partial feature vector v is the set of object vectors\n",
    "    (= fully specified feature vectors) that 'agree' with it.\n",
    "    '''\n",
    "    matches = tuple([o for o in objects if agree(v,o).all()])\n",
    "#     matches = np.array([1.0 if np.linalg.norm(agree(v,o), 1) == num_features else 0.0 for o in objects])\n",
    "    if asIndexVector:\n",
    "        return makeExtensionVector([getIndex(o) for o in matches])\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:06.718971Z",
     "start_time": "2019-05-01T16:10:06.714437Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_random_partial_fv():\n",
    "    return np.random.randint(3, size=num_features) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:06.735040Z",
     "start_time": "2019-05-01T16:10:06.720782Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, -1,  1, -1,  0,  0,  0,  0,  0,  1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=int8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_partial_fv = make_random_partial_fv()\n",
    "while len(extension_naive(random_partial_fv, False)) < 2:\n",
    "    random_partial_fv = make_random_partial_fv()\n",
    "random_partial_fv\n",
    "extension_naive(random_partial_fv, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:06.745175Z",
     "start_time": "2019-05-01T16:10:06.736920Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, -1,  1, -1,  0,  0,  0,  0,  0,  1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-1, -1,  1, -1, -1,  1, -1, -1,  1,  1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-1, -1,  1, -1, -1,  1,  1, -1,  1,  1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-1, -1,  1, -1, -1, -1, -1, -1, -1,  1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_partial_fv\n",
    "for instance in extension_naive(random_partial_fv, False):\n",
    "    instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:06.748941Z",
     "start_time": "2019-05-01T16:10:06.746863Z"
    }
   },
   "outputs": [],
   "source": [
    "# extension_naive(random_partial_fv, True)\n",
    "# extension_naive_njit(random_partial_fv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:06.755929Z",
     "start_time": "2019-05-01T16:10:06.750664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1,  1, -1, -1,  1,  1, -1,  1,  1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_instance = choice(list(extension_naive(random_partial_fv, False)))\n",
    "random_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:06.873927Z",
     "start_time": "2019-05-01T16:10:06.757567Z"
    }
   },
   "outputs": [],
   "source": [
    "import vg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:06.883221Z",
     "start_time": "2019-05-01T16:10:06.875933Z"
    }
   },
   "outputs": [],
   "source": [
    "normalized_0 = vg.normalize\n",
    "\n",
    "def normalized_1(v):\n",
    "    return v / np.sqrt(np.sum(v**2))\n",
    "\n",
    "def normalized_2(v):\n",
    "    norm=np.linalg.norm(v, ord=2)\n",
    "    if norm==0:\n",
    "        norm=np.finfo(v.dtype).eps\n",
    "    return v/norm\n",
    "\n",
    "# from https://stackoverflow.com/a/21032099\n",
    "def normalized_3(a, axis=-1, order=2):\n",
    "    l2 = np.atleast_1d(np.linalg.norm(a, order, axis))\n",
    "    l2[l2==0] = 1\n",
    "    return a / np.expand_dims(l2, axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:06.889835Z",
     "start_time": "2019-05-01T16:10:06.884471Z"
    }
   },
   "outputs": [],
   "source": [
    "a = np.array([1,0,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:07.028180Z",
     "start_time": "2019-05-01T16:10:06.891727Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.31622777,  0.        ,  0.9486833 ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.31622777,  0.        ,  0.9486833 ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.31622777,  0.        ,  0.9486833 ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.31622777,  0.        ,  0.9486833 ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_0(a)\n",
    "normalized_1(a)\n",
    "normalized_2(a)\n",
    "normalized_3(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:07.044951Z",
     "start_time": "2019-05-01T16:10:07.029833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s : [ 0 -1  1 -1  0  0  0  0  0  1]\n",
      "s': [0 1 1 1 0 0 0 0 0 1]\n",
      "o : [-1 -1  1 -1 -1  1  1 -1  1  1]\n",
      "o': [ 0 -1  1 -1  0  0  0  0  0  1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0. , -0.5,  0.5, -0.5,  0. ,  0. ,  0. ,  0. ,  0. ,  0.5]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0. , -0.5,  0.5, -0.5,  0. ,  0. ,  0. ,  0. ,  0. ,  0.5]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized = normalized_3\n",
    "print('s : {0}'.format(  random_partial_fv  ))\n",
    "print(\"s': {0}\".format( np.abs(random_partial_fv) ))\n",
    "print('o : {0}'.format( random_instance ))\n",
    "print(\"o': {0}\".format( np.abs(random_partial_fv) * random_instance ))\n",
    "np.dot(random_partial_fv, \n",
    "       (np.abs(random_partial_fv) * random_instance))\n",
    "np.dot(random_partial_fv, random_partial_fv)\n",
    "normalized(random_partial_fv)\n",
    "normalized(np.abs(random_partial_fv) * random_instance)\n",
    "np.dot( normalized(random_partial_fv)[0],\n",
    "        normalized(np.abs(random_partial_fv) * random_instance)[0] )\n",
    "# np.dot(normalized(random_partial_fv),\n",
    "#        normalized(np.abs(random_partial_fv) * random_instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:07.049590Z",
     "start_time": "2019-05-01T16:10:07.046469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isclose(1.0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:07.055273Z",
     "start_time": "2019-05-01T16:10:07.050865Z"
    }
   },
   "outputs": [],
   "source": [
    "normalized = normalized_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:07.067658Z",
     "start_time": "2019-05-01T16:10:07.057118Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=int8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def in_extension(s, o):\n",
    "    '''\n",
    "    Given a partial feature vector s and a fully specified object vector o,\n",
    "    returns True iff o ∈ ⟦s⟧ and False otherwise.\n",
    "    '''\n",
    "    if np.array_equal( s, np.zeros(s.shape) ):\n",
    "        return True\n",
    "    \n",
    "    s_ = np.abs(s)\n",
    "    o_ = s_ * o\n",
    "    s_normed = normalized(s)#[0] #uncomment the last part here if normalized == normalized_3\n",
    "    o_normed = normalized(o_)#[0]\n",
    "    pr = np.dot(s_normed, o_normed)\n",
    "#     return pr\n",
    "#     return pr == 1.0 # WRONG\n",
    "    return np.isclose(1.0, pr)\n",
    "\n",
    "def extension(s, asIndexVector=True):\n",
    "    matches = tuple([o for o in objects if in_extension(s, o)])\n",
    "    if asIndexVector:\n",
    "        return makeExtensionVector([getIndex(o) for o in matches])\n",
    "    return matches\n",
    "\n",
    "extension(random_partial_fv, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:07.081366Z",
     "start_time": "2019-05-01T16:10:07.068967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=int8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=int8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extension_naive(random_partial_fv)\n",
    "extension(random_partial_fv)\n",
    "np.array_equal(extension_naive(random_partial_fv), extension(random_partial_fv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:07.085227Z",
     "start_time": "2019-05-01T16:10:07.082522Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1,  1, -1, -1,  1,  1, -1,  1,  1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:07.093448Z",
     "start_time": "2019-05-01T16:10:07.086603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_extension(random_partial_fv, random_instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do the two methods for calculating extensions compare?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the non-naive method correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:12.874043Z",
     "start_time": "2019-05-01T16:10:07.095232Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59049"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials = int(1e6)\n",
    "generated_partial_fvs = tuple(map(np.array,\n",
    "                                  set(map(tuple, \n",
    "                                          (make_random_partial_fv() for s in range(trials))))))\n",
    "len(generated_partial_fvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:10:12.877536Z",
     "start_time": "2019-05-01T16:10:12.875560Z"
    }
   },
   "outputs": [],
   "source": [
    "# J = 15\n",
    "# V = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:11:22.131772Z",
     "start_time": "2019-05-01T16:10:12.879057Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59049/59049 [01:09<00:00, 852.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# for num_features = 13, ~20m on wittgenstein with a lot of other things going on in the background\n",
    "# for num_features = 12, ~12m on wittgenstein with a lot of other things going on in the background\n",
    "# for num_features = 10, ~1.66m on wittgenstein with a lot of other things going on in the background\n",
    "#  num_features = 10, normalized_0 => ~1.1m on wittgenstein with a lot of other things going on in the background\n",
    "#  num_features = 10, normalized_1 => ~1.26m on wittgenstein with a lot of other things going on in the background\n",
    "#  num_features = 10, normalized_2 => ~1.16m on wittgenstein with a lot of other things going on in the background\n",
    "#  num_features = 10, normalized_3 => ~1.83m on wittgenstein with a lot of other things going on in the background\n",
    "subset_vectors_with_mismatch = tuple(s for s in tqdm(generated_partial_fvs) \n",
    "                                     if not np.array_equal(extension(s), extension_naive(s)))\n",
    "\n",
    "# subset_vectors_with_mismatch = par((delayed(identity)(s) for s in generated_partial_fvs \n",
    "#                                    if not np.array_equal(extension(s), extension_naive(s))), j=15, verbose=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:12:27.443852Z",
     "start_time": "2019-05-01T16:11:22.133469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend MultiprocessingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   0 out of   0 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "J = 16\n",
    "V = 50\n",
    "# bizarre behavior: num_features = 10 + 16 jobs -> ~1m on wittgenstein with a lot of other things going on in the background\n",
    "subset_vectors_with_mismatch = par(delayed(identity)(s) for s in generated_partial_fvs \n",
    "                                   if not np.array_equal(extension(s), extension_naive(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:12:27.450628Z",
     "start_time": "2019-05-01T16:12:27.446252Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59049"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(generated_partial_fvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:12:27.500476Z",
     "start_time": "2019-05-01T16:12:27.452371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subset_vectors_with_mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:12:27.507282Z",
     "start_time": "2019-05-01T16:12:27.502740Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_vectors_with_mismatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is the non-naive method faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:12:33.335838Z",
     "start_time": "2019-05-01T16:12:27.509146Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59049"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials = int(1e6)\n",
    "generated_partial_fvs = tuple(map(np.array,\n",
    "                                  set(map(tuple, \n",
    "                                          (make_random_partial_fv() for s in range(trials))))))\n",
    "len(generated_partial_fvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:12:44.408905Z",
     "start_time": "2019-05-01T16:12:33.337460Z"
    }
   },
   "outputs": [],
   "source": [
    "#~11s for num_features = 10 on wittgenstein under heavy load from other users\n",
    "naive_extensions = [extension_naive(s) for s in generated_partial_fvs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:37.798128Z",
     "start_time": "2019-05-01T16:12:44.410492Z"
    }
   },
   "outputs": [],
   "source": [
    "#~52s for num_features = 10 on wittgenstein under heavy load from other users\n",
    "extensions = [extension(s) for s in generated_partial_fvs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:37.802014Z",
     "start_time": "2019-05-01T16:13:37.799722Z"
    }
   },
   "outputs": [],
   "source": [
    "V = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:39.528086Z",
     "start_time": "2019-05-01T16:13:37.803681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend MultiprocessingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0042s.) Setting batch_size=94.\n",
      "[Parallel(n_jobs=16)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done   3 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done   4 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done   7 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done   9 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  11 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  12 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  13 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  14 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  15 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  19 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  20 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  21 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  22 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  23 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  24 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  25 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  27 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  28 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  29 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  31 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  32 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 126 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0513s.) Setting batch_size=732.\n",
      "[Parallel(n_jobs=16)]: Done 220 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 314 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 408 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 502 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 596 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 690 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 784 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 878 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 972 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 1066 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 1160 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 1254 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 1348 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 1442 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 1536 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 1630 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 1724 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 1818 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 1912 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 2006 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 2100 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 2194 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 2288 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 2382 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 2476 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 2570 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 2664 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 2758 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 2852 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 2946 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 3040 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 3772 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=16)]: Done 4504 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=16)]: Done 5236 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=16)]: Done 5968 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=16)]: Done 6700 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=16)]: Done 7432 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=16)]: Done 8164 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=16)]: Done 8896 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=16)]: Done 9628 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=16)]: Done 10360 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=16)]: Done 11092 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=16)]: Done 11824 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=16)]: Done 12556 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=16)]: Done 13288 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=16)]: Done 14020 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=16)]: Done 14752 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=16)]: Done 15484 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=16)]: Done 16216 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=16)]: Done 16948 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=16)]: Done 17680 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=16)]: Done 18412 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=16)]: Done 19144 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=16)]: Done 19876 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=16)]: Done 20608 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=16)]: Done 21340 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=16)]: Done 22072 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=16)]: Done 22804 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=16)]: Done 23536 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=16)]: Done 24268 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=16)]: Done 25000 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=16)]: Done 25732 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=16)]: Done 26464 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=16)]: Done 27196 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=16)]: Done 27928 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=16)]: Done 28660 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=16)]: Done 29392 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=16)]: Done 30124 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=16)]: Done 30856 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=16)]: Done 31588 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=16)]: Done 32320 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=16)]: Done 33052 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=16)]: Done 33784 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=16)]: Done 34516 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=16)]: Done 35248 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=16)]: Done 35980 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=16)]: Done 36712 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=16)]: Done 59049 out of 59049 | elapsed:    1.5s finished\n"
     ]
    }
   ],
   "source": [
    "# bizarre behavior: num_features = 10 + 16 jobs -> ~2.167m on wittgenstein with a lot of other things going on in the background\n",
    "naive_extensions = par(delayed(extension_naive)(s) for s in generated_partial_fvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.124777Z",
     "start_time": "2019-05-01T16:13:39.531542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend MultiprocessingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0052s.) Setting batch_size=76.\n",
      "[Parallel(n_jobs=16)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done   3 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done   4 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done   6 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done   7 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done   8 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done   9 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  10 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  11 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  12 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  13 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  14 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  15 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  16 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  19 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  20 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  21 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  22 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  23 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  24 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  25 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  26 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  27 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  28 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  29 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  31 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  32 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 108 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Batch computation too fast (0.0827s.) Setting batch_size=366.\n",
      "[Parallel(n_jobs=16)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 260 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 336 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 412 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 488 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 564 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 640 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 716 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done 792 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 868 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 944 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 1020 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 1096 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 1172 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 1248 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 1324 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 1400 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 1476 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 1552 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 1628 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 1704 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 1780 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 1856 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 1932 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=16)]: Done 2008 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=16)]: Done 2084 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=16)]: Done 2160 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=16)]: Done 2236 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=16)]: Done 2312 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=16)]: Done 2388 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=16)]: Done 2464 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=16)]: Done 2830 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=16)]: Done 3196 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=16)]: Done 3562 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=16)]: Done 3928 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=16)]: Done 4294 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=16)]: Done 4660 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=16)]: Done 5026 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=16)]: Done 5392 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=16)]: Done 5758 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=16)]: Done 6124 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=16)]: Done 6490 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=16)]: Done 6856 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=16)]: Done 7222 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=16)]: Done 7588 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=16)]: Done 7954 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=16)]: Done 8320 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=16)]: Done 8686 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=16)]: Done 9052 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=16)]: Done 9418 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=16)]: Done 9784 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=16)]: Done 10150 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=16)]: Done 10516 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=16)]: Done 10882 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=16)]: Done 11248 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=16)]: Done 11614 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=16)]: Done 11980 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=16)]: Done 12346 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=16)]: Done 12712 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=16)]: Done 13078 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=16)]: Done 13444 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=16)]: Done 13810 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=16)]: Done 14176 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=16)]: Done 14542 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=16)]: Done 14908 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=16)]: Done 15274 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=16)]: Done 15640 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=16)]: Done 16006 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=16)]: Done 16372 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=16)]: Done 16738 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=16)]: Done 17104 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=16)]: Done 17470 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=16)]: Done 17836 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=16)]: Done 18202 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=16)]: Done 18568 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=16)]: Done 18934 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=16)]: Done 19300 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=16)]: Done 19666 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=16)]: Done 20032 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=16)]: Done 20398 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=16)]: Done 20764 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=16)]: Done 21130 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=16)]: Done 21496 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=16)]: Done 21862 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=16)]: Done 22228 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=16)]: Done 22594 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=16)]: Done 22960 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=16)]: Done 23326 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=16)]: Done 23692 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=16)]: Done 24058 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=16)]: Done 24424 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=16)]: Done 24790 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=16)]: Done 25156 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=16)]: Done 25522 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=16)]: Done 25888 tasks      | elapsed:    2.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done 26254 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=16)]: Done 26620 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=16)]: Done 26986 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=16)]: Done 27352 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=16)]: Done 27718 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=16)]: Done 28084 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=16)]: Done 28450 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=16)]: Done 28816 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=16)]: Done 29182 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=16)]: Done 29548 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=16)]: Done 29914 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=16)]: Done 30280 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=16)]: Done 30646 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=16)]: Done 31012 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=16)]: Done 31378 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=16)]: Done 31744 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=16)]: Done 32110 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=16)]: Done 32476 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=16)]: Done 32842 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=16)]: Done 33208 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=16)]: Done 33574 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=16)]: Done 33940 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=16)]: Done 34306 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=16)]: Done 34672 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=16)]: Done 35038 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=16)]: Done 35404 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=16)]: Done 35770 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=16)]: Done 36136 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=16)]: Done 36502 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=16)]: Done 36868 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=16)]: Done 37234 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=16)]: Done 37600 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=16)]: Done 37966 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=16)]: Done 38332 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=16)]: Done 38698 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=16)]: Done 39064 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=16)]: Done 39430 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=16)]: Done 39796 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=16)]: Done 40162 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=16)]: Done 40528 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=16)]: Done 40894 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=16)]: Done 41260 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=16)]: Done 41626 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=16)]: Done 41992 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=16)]: Done 42358 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=16)]: Done 42724 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=16)]: Done 43090 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=16)]: Done 43456 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=16)]: Done 43822 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=16)]: Done 44188 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=16)]: Done 44554 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=16)]: Done 44920 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=16)]: Done 45286 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=16)]: Done 45652 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=16)]: Done 46018 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=16)]: Done 46384 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=16)]: Done 46750 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=16)]: Done 47116 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=16)]: Done 47482 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=16)]: Done 47848 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=16)]: Done 59049 out of 59049 | elapsed:    4.4s finished\n"
     ]
    }
   ],
   "source": [
    "# bizarre behavior: num_features = 10 + 16 jobs -> ~2.5m on wittgenstein with a lot of other things going on in the background\n",
    "extensions = par(delayed(extension)(s) for s in generated_partial_fvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sketch inductive calculation of the extensions of increasingly complex partial feature vectors in terms of simpler, already calculated ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.134329Z",
     "start_time": "2019-05-01T16:13:44.127402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, -1,  1, -1,  0,  0,  0,  0,  0,  1])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=int8)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(array([-1, -1,  1, -1, -1,  1, -1, -1,  1,  1]),\n",
       " array([-1, -1,  1, -1, -1,  1,  1, -1,  1,  1]),\n",
       " array([-1, -1,  1, -1, -1, -1, -1, -1, -1,  1]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = make_random_partial_fv()\n",
    "a = random_partial_fv\n",
    "a\n",
    "extension_naive(a)\n",
    "extension_naive(a, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.172762Z",
     "start_time": "2019-05-01T16:13:44.135441Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  1, -1, -1,  0,  0,  0,  0, -1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0], dtype=int8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(array([-1, -1,  1, -1, -1,  1, -1,  1, -1, -1]),\n",
       " array([-1, -1,  1, -1, -1,  1,  1, -1, -1, -1]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = make_random_partial_fv()\n",
    "while len(extension_naive(b, False)) < 2:\n",
    "    b = make_random_partial_fv()\n",
    "\n",
    "b\n",
    "extension_naive(b)\n",
    "extension_naive(b, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agreement/conflict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $u, v$ be partial feature vectors. Recall that \n",
    " - $u_i$ and $v_i$ *agree* iff $u_i = v_i \\lor u_i = 0 \\lor v_i = 0$\n",
    " - $u_i$ and $v_i$ *conflict* iff they do not agree\n",
    " - $u$ and $v$ *agree* iff $\\forall i$ $agree(u_i, v_i)$\n",
    " - $u$ and $v$ *conflict* iff they do not agree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.177982Z",
     "start_time": "2019-05-01T16:13:44.174028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, -1,  1, -1,  0,  0,  0,  0,  0,  1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  1, -1, -1,  0,  0,  0,  0, -1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.182634Z",
     "start_time": "2019-05-01T16:13:44.179287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agree(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.189333Z",
     "start_time": "2019-05-01T16:13:44.184329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agree_(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Union of partial feature vectors in agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - A partial feature vector over $F$ binary features can be thought of as a function in $F \\rightarrow {-1, 0, 1}$ (where $0$ represents 'unspecified'). \n",
    " - Suppose $u,v$ are vectors that agree.\n",
    " - Treating the functions of $u,v$ as *relations*, we can take the union of their relations  $u \\cup v$ to get a new partial feature vector that is at least as specified as either $u$ or $u$, and which in general will have every specified value that is in $u$, every specified value that is in $v$, and no other specified values.\n",
    " - Crucially, $⟦u \\cup v⟧ = ⟦u⟧ \\cap ⟦v⟧$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.195732Z",
     "start_time": "2019-05-01T16:13:44.190890Z"
    }
   },
   "outputs": [],
   "source": [
    "def twoToOne(x):\n",
    "    if x != 2 and x != -2:\n",
    "        return x\n",
    "    elif x == 2:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "twoToOne_v = np.vectorize(twoToOne)\n",
    "    \n",
    "def union(u,v):\n",
    "    assert agree_(u,v)\n",
    "    return np.sign(u + v)\n",
    "#     return twoToOne_v(u + v)\n",
    "#     s = u + v\n",
    "#     return np.trunc( np.sqrt(np.abs(s)) ) * np.sign(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.201437Z",
     "start_time": "2019-05-01T16:13:44.197561Z"
    }
   },
   "outputs": [],
   "source": [
    "def overlapping_extensions(u,v):\n",
    "    u_x = set(map(tuple, extension_naive(u, False)))\n",
    "    v_x = set(map(tuple, extension_naive(v, False)))\n",
    "    return u_x & v_x != set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.255007Z",
     "start_time": "2019-05-01T16:13:44.203407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1,  1, -1,  0,  0, -1,  1, -1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0, -1,  1,  0, -1,  1,  0,  0,  0, -1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0], dtype=int8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0], dtype=int8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = make_random_partial_fv()\n",
    "d = make_random_partial_fv()\n",
    "while (not agree_(c,d)) or len(extension_naive(c, False)) < 2 or len(extension_naive(d, False)) < 2 or not overlapping_extensions(c,d):\n",
    "    c = make_random_partial_fv()\n",
    "    d = make_random_partial_fv()\n",
    "c\n",
    "d\n",
    "agree_(c,d)\n",
    "extension_naive(c)\n",
    "extension_naive(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.261545Z",
     "start_time": "2019-05-01T16:13:44.256280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1,  1, -1,  0,  0, -1,  1, -1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0, -1,  1,  0, -1,  1,  0,  0,  0, -1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-1, -1,  1,  1, -1,  1,  0, -1,  1, -1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c\n",
    "d\n",
    "union(c,d)\n",
    "# union(c,d).nonzero()\n",
    "# np.vectorize(twoToOne)(union(c,d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can speedily calculate the intersection of two partial feature vectors $u, v$ as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.284434Z",
     "start_time": "2019-05-01T16:13:44.262772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 0), (0, 1), (1, -1), (1, 0), (1, 1))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((-1, -1), -1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((-1, 0), 0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((-1, 1), 0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((0, -1), 0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((0, 0), 0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((0, 1), 0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((1, -1), 0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((1, 0), 0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((1, 1), 1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XYs = tuple(product((-1,0,1), (-1,0,1)))\n",
    "XYs\n",
    "\n",
    "def foo(x,y):\n",
    "    return (x == y) * int((x + y) / 2)\n",
    "\n",
    "for x,y in XYs:\n",
    "    ((x,y), foo(x,y))\n",
    "    \n",
    "def intersection(u, v):\n",
    "#     return np.equal(u, v) * (u + v) * 0.5\n",
    "    return np.sign(  np.equal(u, v) * (u + v) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.289996Z",
     "start_time": "2019-05-01T16:13:44.286136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  0  1  1 -1  0  0 -1  1 -1]\n",
      "[ 0 -1  1  0 -1  1  0  0  0 -1]\n",
      "[ 0  0  1  0 -1  0  0  0  0 -1]\n"
     ]
    }
   ],
   "source": [
    "print(c)\n",
    "print(d)\n",
    "print(intersection(c,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.301668Z",
     "start_time": "2019-05-01T16:13:44.291305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\t\t[-1  0  1  1 -1  0  0 -1  1 -1]\n",
      "d:\t\t[ 0 -1  1  0 -1  1  0  0  0 -1]\n",
      "c ∪ d:\t\t[-1 -1  1  1 -1  1  0 -1  1 -1]\n",
      "⟦c⟧:\t\t[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "⟦d⟧:\t\t[0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0]\n",
      "⟦c ∪ d⟧:\t\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "⟦c⟧ ∩ ⟦d⟧:\t[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"c:\\t\\t{0}\".format(c))\n",
    "print(\"d:\\t\\t{0}\".format(d))\n",
    "print(\"c ∪ d:\\t\\t{0}\".format(union(c,d)))\n",
    "print(\"⟦c⟧:\\t\\t{0}\".format(extension_naive(c)))\n",
    "print(\"⟦d⟧:\\t\\t{0}\".format(extension_naive(d)))\n",
    "print(\"⟦c ∪ d⟧:\\t\\t{0}\".format(extension_naive(union(c,d))))\n",
    "print(\"⟦c⟧ ∩ ⟦d⟧:\\t{0}\".format(intersection(extension_naive(c), extension_naive(d))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inductive calculation of extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If \n",
    " - $u, v$ are partial feature vectors whose extensions $⟦u⟧$ and $⟦v⟧$ are known\n",
    " - $u, v$ are distinct \n",
    " - $u$ and $v$ are partial feature vectors that agree\n",
    "\n",
    "then $⟦u \\cup v⟧ = ⟦u⟧ \\cap ⟦v⟧$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accordingly, let $K$ represent the set of partial feature vectors with known extensions at any given point in time.\n",
    "\n",
    "$K$ can be constructed as $K = K_0 \\cup K_1 \\cup ... K_i ... \\cup K_m$, where $m$ is the number of defined features and $K_i$ represents the set of partial feature vectors with known extensions and with $i$ specified features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive calculation of the extension of every partial feature vector**\n",
    "\n",
    "Every $K_i$ for $i > 1$ can be constructed from $K_1$ and $K_{i-1}$ as follows:\n",
    " 1. lazily construct the Cartesian product $K_1 \\times K_{i-1}$\n",
    " 2. (lazily) filter the product to obtain only the set of pairs $P = {(b, v)}$ where $b$ and $v$\n",
    "   - are distinct\n",
    "   - agree\n",
    "\n",
    "Then $K_i = \\{b \\cup v | (b,v) \\in P\\}$.\n",
    "\n",
    "This calculation method misses two things:\n",
    "1. It does not take advantage of the fact that, typically, as $i$ increases, most partial feature vectors $v$ have an empty extension -- and therefore so must the union of $v$ with any choice of $u$: needless calculation will be done.\n",
    "2. It does not take advantage (or avoid the disadvantage) of the fact that for any choice of distinct and agreeing $b, v$, there are usually other distinct and agreeing $b', v'$ such that $b \\cup v = b' \\cup v'$:  much calculation will be duplicated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reduced calculation of the extension of empty partial feature vectors**\n",
    "\n",
    "If $S$ is a set of partial feature vectors, let $\\overline{S} = \\{v | v \\in S \\land ⟦v⟧ ≠ ∅ \\}$.\n",
    "\n",
    "Every $\\overline{K_i}$ for $i > 1$ can be constructed from $\\overline{K}_1$ and $\\overline{K}_{i-1}$ as follows:\n",
    " 1. lazily construct $\\overline{K}_{i-1} = \\{v | v \\in K_{i-1} \\land ⟦v⟧ ≠ ∅ \\}$\n",
    " 2. lazily construct the Cartesian product $K_1 \\times \\overline{K}_{i-1}$\n",
    " 3. (lazily) filter the product to obtain only the set of pairs $P = {(b, v)}$ where $b$ and $v$\n",
    "   - are distinct\n",
    "   - agree\n",
    "\n",
    "Then $\\overline{K}_i = \\{b \\cup v | (b,v) \\in P\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Avoiding duplicate calculation**\n",
    "\n",
    "To avoid the second problem mentioned above (duplicate calculation), we must intelligently construct a subset of $K_1 \\times K_{i-1}$ that avoids including distinct pairs $(b,v)$ and $(b',v')$ such that $b \\cup v = b' \\cup v'$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps the simplest approach to doing this is going in the 'reverse' order of the first approach:\n",
    " 1. Construct $S_i$, the set of all partial feature vectors with $i$ specified features. ($K_i$ will eventually equal $S_i$.)\n",
    " 2. For each $s \\in S_i$, efficiently choose *any single* decomposition $(b,v)$ of $s$, where $(b,v)$ is a decomposition of $s \\in S_i$ iff $b \\in S_1 \\land v \\in S_{i-1} \\land b \\cup v = s$.\n",
    " 3. Calculate the extension of each decomposition and add each $s$ to $K_i$.\n",
    " \n",
    "How do we efficiently find such a decomposition of a given $s$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.316635Z",
     "start_time": "2019-05-01T16:13:44.303363Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1,  1, -1,  0,  0, -1,  1, -1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 2, 3, 4, 7, 8, 9]),)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[-1,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  1,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, -1,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, -1,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  1,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, -1]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  1,  1, -1,  0,  0, -1,  1, -1])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c\n",
    "np.nonzero(c) # << key\n",
    "\n",
    "#adapted from https://stackoverflow.com/a/37323404\n",
    "def one_hot_stack(indices):\n",
    "#     n_values = np.max(indices) + 1\n",
    "    n_values = num_features\n",
    "    return np.eye(n_values,dtype=myint)[indices] \n",
    "\n",
    "def b_factors(partial_feature_vector):\n",
    "    return one_hot_stack(np.nonzero(partial_feature_vector)) * np.sign(partial_feature_vector)\n",
    "\n",
    "b_factors(c)\n",
    "b_0 = b_factors(c)[0]\n",
    "b_0\n",
    "\n",
    "c - b_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.325457Z",
     "start_time": "2019-05-01T16:13:44.318394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1,  1, -1,  0,  0, -1,  1, -1])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 2, 3, 4, 7, 8, 9]),)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c\n",
    "np.nonzero(c)\n",
    "b_factors(c) * np.sign(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.345699Z",
     "start_time": "2019-05-01T16:13:44.327228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1,  1, -1,  0,  0, -1,  1, -1])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0, -1,  1,  0, -1,  1,  0,  0,  0, -1])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((array([-1,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       "  array([ 0,  0,  1,  1, -1,  0,  0, -1,  1, -1])),\n",
       " (array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  array([-1,  0,  0,  1, -1,  0,  0, -1,  1, -1])),\n",
       " (array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0]),\n",
       "  array([-1,  0,  1,  0, -1,  0,  0, -1,  1, -1])),\n",
       " (array([ 0,  0,  0,  0, -1,  0,  0,  0,  0,  0]),\n",
       "  array([-1,  0,  1,  1,  0,  0,  0, -1,  1, -1])),\n",
       " (array([ 0,  0,  0,  0,  0,  0,  0, -1,  0,  0]),\n",
       "  array([-1,  0,  1,  1, -1,  0,  0,  0,  1, -1])),\n",
       " (array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0]),\n",
       "  array([-1,  0,  1,  1, -1,  0,  0, -1,  0, -1])),\n",
       " (array([ 0,  0,  0,  0,  0,  0,  0,  0,  0, -1]),\n",
       "  array([-1,  0,  1,  1, -1,  0,  0, -1,  1,  0])))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((array([ 0, -1,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       "  array([ 0,  0,  1,  0, -1,  1,  0,  0,  0, -1])),\n",
       " (array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  array([ 0, -1,  0,  0, -1,  1,  0,  0,  0, -1])),\n",
       " (array([ 0,  0,  0,  0, -1,  0,  0,  0,  0,  0]),\n",
       "  array([ 0, -1,  1,  0,  0,  1,  0,  0,  0, -1])),\n",
       " (array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0]),\n",
       "  array([ 0, -1,  1,  0, -1,  0,  0,  0,  0, -1])),\n",
       " (array([ 0,  0,  0,  0,  0,  0,  0,  0,  0, -1]),\n",
       "  array([ 0, -1,  1,  0, -1,  1,  0,  0,  0,  0])))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(array([-1,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([ 0,  0,  1,  1, -1,  0,  0, -1,  1, -1]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0, -1,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([ 0,  0,  1,  0, -1,  1,  0,  0,  0, -1]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c\n",
    "d\n",
    "\n",
    "def decompositions(partial_feature_vector):\n",
    "    Bs = b_factors(partial_feature_vector)\n",
    "    Vs = tuple([partial_feature_vector - b for b in Bs])\n",
    "    together = tuple(zip(Bs, Vs))\n",
    "    assert all([np.array_equal(partial_feature_vector, t) \n",
    "                for t in starmap(union, together)])\n",
    "    return together\n",
    "\n",
    "decompositions(c)\n",
    "decompositions(d)\n",
    "\n",
    "def decompose(partial_feature_vector):\n",
    "    Bs = b_factors(partial_feature_vector)\n",
    "    b = Bs[0]\n",
    "    v = partial_feature_vector - b\n",
    "    assert wffv(v)\n",
    "    assert np.array_equal( union(v, b), partial_feature_vector  )\n",
    "    return (b, v)\n",
    "\n",
    "decompose(c)\n",
    "decompose(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither of these two methods, however, take advantage of vector or matrix operations to do this massively in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing $S_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extension operation $⟦⸱⟧$ is a function from partial feature vectors $S$ to some representation of *objects*.\n",
    "\n",
    "An *object* can be represented as a fully specified feature vector, but directly using this to represent the extension of a partial feature vector $v$ would give us a set of fully specified feature vectors. We want operations to and from matrices.\n",
    "\n",
    "Accordingly, representing the extension of a partial feature vector $s$ as an *index vector* (i.e. representing an indicator function) gives us a nice, homogeneously shaped representation of the extension of any partial feature vector. \n",
    "\n",
    "I.e. if there are $l = |O|$ observed objects, then we can identify $⟦s⟧$ with an $l$-length vector where $⟦s⟧_j$ is 1 iff $o_j \\in ⟦s⟧$ and 0 otherwise.\n",
    "\n",
    "To break things down further, we can specify a distinct interpretation function $⟦⸱⟧_i$ for each number of specified features in the partial feature vectors of interest: $⟦⸱⟧_i : S_i \\rightarrow \\{0,1\\}^l$.\n",
    "\n",
    "If there are $m$ binary features, then the size of $S_i$ is given by $\\binom{m}{i} \\cdot 2^i$: \n",
    " - there are $\\binom{m}{i}$ ways to choose $i$ distinct indices (features) to specify among $m$ indices (features)\n",
    " - for each way of the $\\binom{m}{i}$ ways to choose $i$ distinct indices, there are $2^i$ possible assignments (specifications) of feature values\n",
    " \n",
    "Altogether, $\\sum\\limits_{i=0}^{i=m} \\binom{m}{i} \\cdot 2^i = 3^m$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complexity calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.372711Z",
     "start_time": "2019-05-01T16:13:44.346960Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assuming a feature set of size 23\n",
      "Assuming a segment inventory of size 96...\n",
      "Assuming each cell requires ≥ 2 bits of storage\n",
      "i = 0\n",
      "S_0:\n",
      "\t m=96 choose i=0 = 1.0\n",
      "\t 2^i = 1\n",
      "\t (m choose i) * 2^i = 1.0\n",
      "\t 1 rows = 1 partial feature vectors in S_0\n",
      "\t 23 cells/pfv * 2 bits/cell * 1 pfvs in S_0 ⟶ ≥ 5.75e-09 GB needed for S_0\n",
      "\n",
      "\n",
      "X_0:\n",
      "\t 1 rows=pfvs in S_0 = 1 rows=extensions in X_0\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 96 binary cells\n",
      "\t 96 cells/extension * 2 bits/cell * 1 extensions in X_0 ⟶ ≥ 2.4e-08 GB needed for X_0\n",
      "i = 1\n",
      "S_1:\n",
      "\t m=96 choose i=1 = 23.0\n",
      "\t 2^i = 2\n",
      "\t (m choose i) * 2^i = 46.0\n",
      "\t 46 rows = 46 partial feature vectors in S_1\n",
      "\t 23 cells/pfv * 2 bits/cell * 46 pfvs in S_1 ⟶ ≥ 2.645e-07 GB needed for S_1\n",
      "\n",
      "\n",
      "X_1:\n",
      "\t 46 rows=pfvs in S_1 = 46 rows=extensions in X_1\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 96 binary cells\n",
      "\t 96 cells/extension * 2 bits/cell * 46 extensions in X_1 ⟶ ≥ 1.104e-06 GB needed for X_1\n",
      "i = 2\n",
      "S_2:\n",
      "\t m=96 choose i=2 = 253.0\n",
      "\t 2^i = 4\n",
      "\t (m choose i) * 2^i = 1,012.0\n",
      "\t 1,012 rows = 1,012 partial feature vectors in S_2\n",
      "\t 23 cells/pfv * 2 bits/cell * 1,012 pfvs in S_2 ⟶ ≥ 5.819e-06 GB needed for S_2\n",
      "\n",
      "\n",
      "X_2:\n",
      "\t 1,012 rows=pfvs in S_2 = 1,012 rows=extensions in X_2\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 96 binary cells\n",
      "\t 96 cells/extension * 2 bits/cell * 1,012 extensions in X_2 ⟶ ≥ 2.4288e-05 GB needed for X_2\n",
      "i = 3\n",
      "S_3:\n",
      "\t m=96 choose i=3 = 1,771.0\n",
      "\t 2^i = 8\n",
      "\t (m choose i) * 2^i = 14,168.0\n",
      "\t 14,168 rows = 14,168 partial feature vectors in S_3\n",
      "\t 23 cells/pfv * 2 bits/cell * 14,168 pfvs in S_3 ⟶ ≥ 8.1466e-05 GB needed for S_3\n",
      "\n",
      "\n",
      "X_3:\n",
      "\t 14,168 rows=pfvs in S_3 = 14,168 rows=extensions in X_3\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 96 binary cells\n",
      "\t 96 cells/extension * 2 bits/cell * 14,168 extensions in X_3 ⟶ ≥ 0.000340032 GB needed for X_3\n",
      "i = 4\n",
      "S_4:\n",
      "\t m=96 choose i=4 = 8,855.0\n",
      "\t 2^i = 16\n",
      "\t (m choose i) * 2^i = 141,680.0\n",
      "\t 141,680 rows = 141,680 partial feature vectors in S_4\n",
      "\t 23 cells/pfv * 2 bits/cell * 141,680 pfvs in S_4 ⟶ ≥ 0.00081466 GB needed for S_4\n",
      "\n",
      "\n",
      "X_4:\n",
      "\t 141,680 rows=pfvs in S_4 = 141,680 rows=extensions in X_4\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 96 binary cells\n",
      "\t 96 cells/extension * 2 bits/cell * 141,680 extensions in X_4 ⟶ ≥ 0.00340032 GB needed for X_4\n",
      "i = 5\n",
      "S_5:\n",
      "\t m=96 choose i=5 = 33,649.0\n",
      "\t 2^i = 32\n",
      "\t (m choose i) * 2^i = 1,076,768.0\n",
      "\t 1,076,768 rows = 1,076,768 partial feature vectors in S_5\n",
      "\t 23 cells/pfv * 2 bits/cell * 1,076,768 pfvs in S_5 ⟶ ≥ 0.006191416 GB needed for S_5\n",
      "\n",
      "\n",
      "X_5:\n",
      "\t 1,076,768 rows=pfvs in S_5 = 1,076,768 rows=extensions in X_5\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 96 binary cells\n",
      "\t 96 cells/extension * 2 bits/cell * 1,076,768 extensions in X_5 ⟶ ≥ 0.025842432 GB needed for X_5\n",
      "i = 6\n",
      "S_6:\n",
      "\t m=96 choose i=6 = 100,947.0\n",
      "\t 2^i = 64\n",
      "\t (m choose i) * 2^i = 6,460,608.0\n",
      "\t 6,460,608 rows = 6,460,608 partial feature vectors in S_6\n",
      "\t 23 cells/pfv * 2 bits/cell * 6,460,608 pfvs in S_6 ⟶ ≥ 0.037148496 GB needed for S_6\n",
      "\n",
      "\n",
      "X_6:\n",
      "\t 6,460,608 rows=pfvs in S_6 = 6,460,608 rows=extensions in X_6\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 96 binary cells\n",
      "\t 96 cells/extension * 2 bits/cell * 6,460,608 extensions in X_6 ⟶ ≥ 0.155054592 GB needed for X_6\n",
      "i = 7\n",
      "S_7:\n",
      "\t m=96 choose i=7 = 245,157.0\n",
      "\t 2^i = 128\n",
      "\t (m choose i) * 2^i = 31,380,096.0\n",
      "\t 31,380,096 rows = 31,380,096 partial feature vectors in S_7\n",
      "\t 23 cells/pfv * 2 bits/cell * 31,380,096 pfvs in S_7 ⟶ ≥ 0.180435552 GB needed for S_7\n",
      "\n",
      "\n",
      "X_7:\n",
      "\t 31,380,096 rows=pfvs in S_7 = 31,380,096 rows=extensions in X_7\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 96 binary cells\n",
      "\t 96 cells/extension * 2 bits/cell * 31,380,096 extensions in X_7 ⟶ ≥ 0.753122304 GB needed for X_7\n",
      "i = 8\n",
      "S_8:\n",
      "\t m=96 choose i=8 = 490,314.0\n",
      "\t 2^i = 256\n",
      "\t (m choose i) * 2^i = 125,520,384.0\n",
      "\t 125,520,384 rows = 125,520,384 partial feature vectors in S_8\n",
      "\t 23 cells/pfv * 2 bits/cell * 125,520,384 pfvs in S_8 ⟶ ≥ 0.721742208 GB needed for S_8\n",
      "\n",
      "\n",
      "X_8:\n",
      "\t 125,520,384 rows=pfvs in S_8 = 125,520,384 rows=extensions in X_8\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 96 binary cells\n",
      "\t 96 cells/extension * 2 bits/cell * 125,520,384 extensions in X_8 ⟶ ≥ 3.012489216 GB needed for X_8\n",
      "i = 9\n",
      "S_9:\n",
      "\t m=96 choose i=9 = 817,190.0\n",
      "\t 2^i = 512\n",
      "\t (m choose i) * 2^i = 418,401,280.0\n",
      "\t 418,401,280 rows = 418,401,280 partial feature vectors in S_9\n",
      "\t 23 cells/pfv * 2 bits/cell * 418,401,280 pfvs in S_9 ⟶ ≥ 2.40580736 GB needed for S_9\n",
      "\n",
      "\n",
      "X_9:\n",
      "\t 418,401,280 rows=pfvs in S_9 = 418,401,280 rows=extensions in X_9\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 96 binary cells\n",
      "\t 96 cells/extension * 2 bits/cell * 418,401,280 extensions in X_9 ⟶ ≥ 10.04163072 GB needed for X_9\n",
      "i = 10\n",
      "S_10:\n",
      "\t m=96 choose i=10 = 1,144,066.0\n",
      "\t 2^i = 1,024\n",
      "\t (m choose i) * 2^i = 1,171,523,584.0\n",
      "\t 1,171,523,584 rows = 1,171,523,584 partial feature vectors in S_10\n",
      "\t 23 cells/pfv * 2 bits/cell * 1,171,523,584 pfvs in S_10 ⟶ ≥ 6.736260608 GB needed for S_10\n",
      "\n",
      "\n",
      "X_10:\n",
      "\t 1,171,523,584 rows=pfvs in S_10 = 1,171,523,584 rows=extensions in X_10\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 96 binary cells\n",
      "\t 96 cells/extension * 2 bits/cell * 1,171,523,584 extensions in X_10 ⟶ ≥ 28.116566016 GB needed for X_10\n",
      "i = 11\n",
      "S_11:\n",
      "\t m=96 choose i=11 = 1,352,078.0\n",
      "\t 2^i = 2,048\n",
      "\t (m choose i) * 2^i = 2,769,055,744.0\n",
      "\t 2,769,055,744 rows = 2,769,055,744 partial feature vectors in S_11\n",
      "\t 23 cells/pfv * 2 bits/cell * 2,769,055,744 pfvs in S_11 ⟶ ≥ 15.922070528 GB needed for S_11\n",
      "\n",
      "\n",
      "X_11:\n",
      "\t 2,769,055,744 rows=pfvs in S_11 = 2,769,055,744 rows=extensions in X_11\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 96 binary cells\n",
      "\t 96 cells/extension * 2 bits/cell * 2,769,055,744 extensions in X_11 ⟶ ≥ 66.457337856 GB needed for X_11\n",
      "i = 12\n",
      "S_12:\n",
      "\t m=96 choose i=12 = 1,352,078.0\n",
      "\t 2^i = 4,096\n",
      "\t (m choose i) * 2^i = 5,538,111,488.0\n",
      "\t 5,538,111,488 rows = 5,538,111,488 partial feature vectors in S_12\n",
      "\t 23 cells/pfv * 2 bits/cell * 5,538,111,488 pfvs in S_12 ⟶ ≥ 31.844141056 GB needed for S_12\n",
      "\n",
      "\n",
      "X_12:\n",
      "\t 5,538,111,488 rows=pfvs in S_12 = 5,538,111,488 rows=extensions in X_12\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 96 binary cells\n",
      "\t 96 cells/extension * 2 bits/cell * 5,538,111,488 extensions in X_12 ⟶ ≥ 132.914675712 GB needed for X_12\n",
      "i = 13\n",
      "S_13:\n",
      "\t m=96 choose i=13 = 1,144,066.0\n",
      "\t 2^i = 8,192\n",
      "\t (m choose i) * 2^i = 9,372,188,672.0\n",
      "\t 9,372,188,672 rows = 9,372,188,672 partial feature vectors in S_13\n",
      "\t 23 cells/pfv * 2 bits/cell * 9,372,188,672 pfvs in S_13 ⟶ ≥ 53.890084864 GB needed for S_13\n",
      "\n",
      "\n",
      "X_13:\n",
      "\t 9,372,188,672 rows=pfvs in S_13 = 9,372,188,672 rows=extensions in X_13\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 96 binary cells\n",
      "\t 96 cells/extension * 2 bits/cell * 9,372,188,672 extensions in X_13 ⟶ ≥ 224.932528128 GB needed for X_13\n",
      "i = 14\n",
      "S_14:\n",
      "\t m=96 choose i=14 = 817,190.0\n",
      "\t 2^i = 16,384\n",
      "\t (m choose i) * 2^i = 13,388,840,960.0\n",
      "\t 13,388,840,960 rows = 13,388,840,960 partial feature vectors in S_14\n",
      "\t 23 cells/pfv * 2 bits/cell * 13,388,840,960 pfvs in S_14 ⟶ ≥ 76.98583552 GB needed for S_14\n",
      "\n",
      "\n",
      "X_14:\n",
      "\t 13,388,840,960 rows=pfvs in S_14 = 13,388,840,960 rows=extensions in X_14\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 96 binary cells\n",
      "\t 96 cells/extension * 2 bits/cell * 13,388,840,960 extensions in X_14 ⟶ ≥ 321.33218304 GB needed for X_14\n",
      "i = 15\n",
      "S_15:\n",
      "\t m=96 choose i=15 = 490,314.0\n",
      "\t 2^i = 32,768\n",
      "\t (m choose i) * 2^i = 16,066,609,152.0\n",
      "\t 16,066,609,152 rows = 16,066,609,152 partial feature vectors in S_15\n",
      "\t 23 cells/pfv * 2 bits/cell * 16,066,609,152 pfvs in S_15 ⟶ ≥ 92.383002624 GB needed for S_15\n",
      "\n",
      "\n",
      "X_15:\n",
      "\t 16,066,609,152 rows=pfvs in S_15 = 16,066,609,152 rows=extensions in X_15\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 96 binary cells\n",
      "\t 96 cells/extension * 2 bits/cell * 16,066,609,152 extensions in X_15 ⟶ ≥ 385.598619648 GB needed for X_15\n",
      "i = 16\n",
      "S_16:\n",
      "\t m=96 choose i=16 = 245,157.0\n",
      "\t 2^i = 65,536\n",
      "\t (m choose i) * 2^i = 16,066,609,152.0\n",
      "\t 16,066,609,152 rows = 16,066,609,152 partial feature vectors in S_16\n",
      "\t 23 cells/pfv * 2 bits/cell * 16,066,609,152 pfvs in S_16 ⟶ ≥ 92.383002624 GB needed for S_16\n",
      "\n",
      "\n",
      "X_16:\n",
      "\t 16,066,609,152 rows=pfvs in S_16 = 16,066,609,152 rows=extensions in X_16\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 96 binary cells\n",
      "\t 96 cells/extension * 2 bits/cell * 16,066,609,152 extensions in X_16 ⟶ ≥ 385.598619648 GB needed for X_16\n",
      "i = 17\n",
      "S_17:\n",
      "\t m=96 choose i=17 = 100,947.0\n",
      "\t 2^i = 131,072\n",
      "\t (m choose i) * 2^i = 13,231,325,184.0\n",
      "\t 13,231,325,184 rows = 13,231,325,184 partial feature vectors in S_17\n",
      "\t 23 cells/pfv * 2 bits/cell * 13,231,325,184 pfvs in S_17 ⟶ ≥ 76.080119808 GB needed for S_17\n",
      "\n",
      "\n",
      "X_17:\n",
      "\t 13,231,325,184 rows=pfvs in S_17 = 13,231,325,184 rows=extensions in X_17\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 96 binary cells\n",
      "\t 96 cells/extension * 2 bits/cell * 13,231,325,184 extensions in X_17 ⟶ ≥ 317.551804416 GB needed for X_17\n",
      "i = 18\n",
      "S_18:\n",
      "\t m=96 choose i=18 = 33,649.0\n",
      "\t 2^i = 262,144\n",
      "\t (m choose i) * 2^i = 8,820,883,456.0\n",
      "\t 8,820,883,456 rows = 8,820,883,456 partial feature vectors in S_18\n",
      "\t 23 cells/pfv * 2 bits/cell * 8,820,883,456 pfvs in S_18 ⟶ ≥ 50.720079872 GB needed for S_18\n",
      "\n",
      "\n",
      "X_18:\n",
      "\t 8,820,883,456 rows=pfvs in S_18 = 8,820,883,456 rows=extensions in X_18\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 96 binary cells\n",
      "\t 96 cells/extension * 2 bits/cell * 8,820,883,456 extensions in X_18 ⟶ ≥ 211.701202944 GB needed for X_18\n",
      "i = 19\n",
      "S_19:\n",
      "\t m=96 choose i=19 = 8,855.0\n",
      "\t 2^i = 524,288\n",
      "\t (m choose i) * 2^i = 4,642,570,240.0\n",
      "\t 4,642,570,240 rows = 4,642,570,240 partial feature vectors in S_19\n",
      "\t 23 cells/pfv * 2 bits/cell * 4,642,570,240 pfvs in S_19 ⟶ ≥ 26.69477888 GB needed for S_19\n",
      "\n",
      "\n",
      "X_19:\n",
      "\t 4,642,570,240 rows=pfvs in S_19 = 4,642,570,240 rows=extensions in X_19\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 96 binary cells\n",
      "\t 96 cells/extension * 2 bits/cell * 4,642,570,240 extensions in X_19 ⟶ ≥ 111.42168576 GB needed for X_19\n",
      "i = 20\n",
      "S_20:\n",
      "\t m=96 choose i=20 = 1,771.0\n",
      "\t 2^i = 1,048,576\n",
      "\t (m choose i) * 2^i = 1,857,028,096.0\n",
      "\t 1,857,028,096 rows = 1,857,028,096 partial feature vectors in S_20\n",
      "\t 23 cells/pfv * 2 bits/cell * 1,857,028,096 pfvs in S_20 ⟶ ≥ 10.677911552 GB needed for S_20\n",
      "\n",
      "\n",
      "X_20:\n",
      "\t 1,857,028,096 rows=pfvs in S_20 = 1,857,028,096 rows=extensions in X_20\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 96 binary cells\n",
      "\t 96 cells/extension * 2 bits/cell * 1,857,028,096 extensions in X_20 ⟶ ≥ 44.568674304 GB needed for X_20\n",
      "i = 21\n",
      "S_21:\n",
      "\t m=96 choose i=21 = 253.0\n",
      "\t 2^i = 2,097,152\n",
      "\t (m choose i) * 2^i = 530,579,456.0\n",
      "\t 530,579,456 rows = 530,579,456 partial feature vectors in S_21\n",
      "\t 23 cells/pfv * 2 bits/cell * 530,579,456 pfvs in S_21 ⟶ ≥ 3.050831872 GB needed for S_21\n",
      "\n",
      "\n",
      "X_21:\n",
      "\t 530,579,456 rows=pfvs in S_21 = 530,579,456 rows=extensions in X_21\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 96 binary cells\n",
      "\t 96 cells/extension * 2 bits/cell * 530,579,456 extensions in X_21 ⟶ ≥ 12.733906944 GB needed for X_21\n",
      "i = 22\n",
      "S_22:\n",
      "\t m=96 choose i=22 = 23.0\n",
      "\t 2^i = 4,194,304\n",
      "\t (m choose i) * 2^i = 96,468,992.0\n",
      "\t 96,468,992 rows = 96,468,992 partial feature vectors in S_22\n",
      "\t 23 cells/pfv * 2 bits/cell * 96,468,992 pfvs in S_22 ⟶ ≥ 0.554696704 GB needed for S_22\n",
      "\n",
      "\n",
      "X_22:\n",
      "\t 96,468,992 rows=pfvs in S_22 = 96,468,992 rows=extensions in X_22\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 96 binary cells\n",
      "\t 96 cells/extension * 2 bits/cell * 96,468,992 extensions in X_22 ⟶ ≥ 2.315255808 GB needed for X_22\n",
      "i = 23\n",
      "S_23:\n",
      "\t m=96 choose i=23 = 1.0\n",
      "\t 2^i = 8,388,608\n",
      "\t (m choose i) * 2^i = 8,388,608.0\n",
      "\t 8,388,608 rows = 8,388,608 partial feature vectors in S_23\n",
      "\t 23 cells/pfv * 2 bits/cell * 8,388,608 pfvs in S_23 ⟶ ≥ 0.048234496 GB needed for S_23\n",
      "\n",
      "\n",
      "X_23:\n",
      "\t 8,388,608 rows=pfvs in S_23 = 8,388,608 rows=extensions in X_23\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 96 binary cells\n",
      "\t 96 cells/extension * 2 bits/cell * 8,388,608 extensions in X_23 ⟶ ≥ 0.201326592 GB needed for X_23\n",
      "\n",
      "\n",
      "Total number of S cells = 2,165,293,113,021\n",
      "Total number of X cells = 9,037,745,167,392\n",
      "Total number of cells = 11,203,038,280,413\n",
      "Min. GB for storing S = 541.32327825525\n",
      "Min. GB for storing X = 2,259.436291848\n",
      "Min. GB for storing S + X = 2,800.75957010325\n"
     ]
    }
   ],
   "source": [
    "# feature_set_size = num_features\n",
    "# feature_set_size = 20\n",
    "feature_set_size = 23 # = num features in bakovic_chart_riggle_hayes{.tsv,.json}\n",
    "\n",
    "# segment_inventory_size = len(objects)\n",
    "# segment_inventory_size = 40\n",
    "segment_inventory_size = 96 # = num symbols in bakovic_chart_riggle_hayes{.tsv,.json}\n",
    "# segment_inventory_size = 120\n",
    "\n",
    "bits_per_cell = 2\n",
    "# bits_per_cell = 4\n",
    "# bits_per_cell = 8\n",
    "\n",
    "print('Assuming a feature set of size {0}'.format(feature_set_size))\n",
    "print('Assuming a segment inventory of size {0}...'.format(segment_inventory_size))\n",
    "print('Assuming each cell requires ≥ {0} bits of storage'.format(bits_per_cell))\n",
    "\n",
    "S_cells = []\n",
    "X_cells = []\n",
    "for i in range(feature_set_size + 1):\n",
    "    print('i = {0}'.format(i))\n",
    "\n",
    "    print('S_{0}:'.format(i))\n",
    "    print('\\t m={0} choose i={1} = {2:,}'.format(segment_inventory_size, i, binom(feature_set_size, i)))\n",
    "    print('\\t 2^i = {0:,}'.format(2 ** i))\n",
    "    print('\\t (m choose i) * 2^i = {0:,}'.format(binom(feature_set_size, i) * (2 ** i)))\n",
    "    num_pfvs_in_Si = int(binom(feature_set_size, i) * (2 ** i))\n",
    "    # num_ints_in_Xi = num_pfvs_in_Si * segment_inventory_size\n",
    "    \n",
    "    print('\\t {0:,} rows = {0:,} partial feature vectors in S_{1}'.format(num_pfvs_in_Si, i))\n",
    "    cells_per_pfv = int(feature_set_size)\n",
    "    bits_per_pfv = cells_per_pfv * bits_per_cell\n",
    "    bits_for_Si = bits_per_pfv * num_pfvs_in_Si\n",
    "    GB_for_Si = bits_for_Si / 8e9\n",
    "    print('\\t {0} cells/pfv * {1} bits/cell * {2:,} pfvs in S_{3} ⟶ ≥ {4} GB needed for S_{3}'.format(cells_per_pfv, bits_per_cell, num_pfvs_in_Si, i, GB_for_Si))\n",
    "    cells_for_Si = int(num_pfvs_in_Si * cells_per_pfv)\n",
    "    S_cells.append(cells_for_Si)\n",
    "\n",
    "    print('\\n')\n",
    "\n",
    "    print('X_{0}:'.format(i))\n",
    "    print(\"\\t {0:,} rows=pfvs in S_{1} = {0:,} rows=extensions in X_{1}\".format(num_pfvs_in_Si, i))\n",
    "    print('\\t Each extension (as an index vector/naive indicator function) has l = {0} binary cells'.format(segment_inventory_size))\n",
    "    num_extensions_in_Xi = int(num_pfvs_in_Si)\n",
    "    cells_per_extension = int(segment_inventory_size)\n",
    "    bits_per_extension = cells_per_extension * bits_per_cell\n",
    "    bits_for_Xi = bits_per_extension * num_extensions_in_Xi\n",
    "    GB_for_Xi = bits_for_Xi / 8e9\n",
    "    print('\\t {0} cells/extension * {1} bits/cell * {2:,} extensions in X_{3} ⟶ ≥ {4} GB needed for X_{3}'.format(cells_per_extension, bits_per_cell, num_extensions_in_Xi, i, GB_for_Xi))\n",
    "    cells_for_Xi = int(num_extensions_in_Xi * cells_per_extension)\n",
    "    X_cells.append(cells_for_Xi)\n",
    "    # print(\"\\t {0:,} rows * {1:,} columns = {2:,} cells in S_{3}\".format(num_pfvs_in_Si, segment_inventory_size, num_ints_in_Xi, i))\n",
    "    \n",
    "    # num_cells_required = (binom(feature_set_size, i) * (2 ** i)) * segment_inventory_size\n",
    "    # print(\"\\t minimum of {0:,} GB required if S_{1} stored using {2} bits/int\".format(num_cells_required * bits_per_cell / 8e9, i, bits_per_cell))\n",
    "    # S_cells.append( num_cells_required )\n",
    "    \n",
    "    # print('\\t 2^{0} = {1:,}'.format(segment_inventory_size, 2 ** segment_inventory_size))\n",
    "    # print('\\t {0:,} rows in S_{1} * {2} objects = {3} cells in X_{1}'.format())\n",
    "    # num_X_cells_required = 2 ** segment_inventory_size\n",
    "    # print('\\t minimum of {0:,} GB required if X_{1} stored using {2} bits/int'.format(num_X_cells_required * bits_per_cell / 8e9, i, bits_per_cell))\n",
    "    # X_cells.append( num_X_cells_required )\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "num_S_cells = sum(S_cells)\n",
    "num_X_cells = sum(X_cells)\n",
    "total_number_of_cells = num_S_cells + num_X_cells\n",
    "\n",
    "print('Total number of S cells = {0:,}'.format(num_S_cells))\n",
    "print('Total number of X cells = {0:,}'.format(num_X_cells))\n",
    "print('Total number of cells = {0:,}'.format(total_number_of_cells))\n",
    "\n",
    "S_bits = num_S_cells * bits_per_cell\n",
    "X_bits = num_X_cells * bits_per_cell\n",
    "total_bits = S_bits + X_bits\n",
    "\n",
    "print('Min. GB for storing S = {0:,}'.format(S_bits / 8e9))\n",
    "print('Min. GB for storing X = {0:,}'.format(X_bits / 8e9))\n",
    "print('Min. GB for storing S + X = {0:,}'.format( (S_bits + X_bits) / 8e9 ))\n",
    "\n",
    "# print('Min. storage required, in GB, assuming each cell requires ≥ {1} bits = {0:,}'.format(n_GB_required, bits_per_cell))\n",
    "\n",
    "# total_number_of_cells_X = sum(X_cells)\n",
    "# print('Total number of X_i cells = {0:,}'.format(total_number_of_cells_X))\n",
    "# n_bits_required_X = total_number_of_cells_X * bits_per_cell\n",
    "# n_GB_required_X = n_bits_required_X / 8e9\n",
    "# print('Min. storage required, in GB, assuming each cell requires ≥ {1} bits = {0:,}'.format(n_GB_required_X, bits_per_cell))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.397101Z",
     "start_time": "2019-05-01T16:13:44.374648Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assuming a feature set of size 10\n",
      "Assuming a segment inventory of size 20...\n",
      "Assuming each cell requires ≥ 8 bits of storage\n",
      "i = 0\n",
      "S_0:\n",
      "\t m=20 choose i=0 = 1.0\n",
      "\t 2^i = 1\n",
      "\t (m choose i) * 2^i = 1.0\n",
      "\t 1 rows = 1 partial feature vectors in S_0\n",
      "\t 10 cells/pfv * 8 bits/cell * 1 pfvs in S_0 ⟶ ≥ 1e-08 GB needed for S_0\n",
      "\n",
      "\n",
      "X_0:\n",
      "\t 1 rows=pfvs in S_0 = 1 rows=extensions in X_0\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 20 binary cells\n",
      "\t 20 cells/extension * 8 bits/cell * 1 extensions in X_0 ⟶ ≥ 2e-08 GB needed for X_0\n",
      "i = 1\n",
      "S_1:\n",
      "\t m=20 choose i=1 = 10.0\n",
      "\t 2^i = 2\n",
      "\t (m choose i) * 2^i = 20.0\n",
      "\t 20 rows = 20 partial feature vectors in S_1\n",
      "\t 10 cells/pfv * 8 bits/cell * 20 pfvs in S_1 ⟶ ≥ 2e-07 GB needed for S_1\n",
      "\n",
      "\n",
      "X_1:\n",
      "\t 20 rows=pfvs in S_1 = 20 rows=extensions in X_1\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 20 binary cells\n",
      "\t 20 cells/extension * 8 bits/cell * 20 extensions in X_1 ⟶ ≥ 4e-07 GB needed for X_1\n",
      "i = 2\n",
      "S_2:\n",
      "\t m=20 choose i=2 = 45.0\n",
      "\t 2^i = 4\n",
      "\t (m choose i) * 2^i = 180.0\n",
      "\t 180 rows = 180 partial feature vectors in S_2\n",
      "\t 10 cells/pfv * 8 bits/cell * 180 pfvs in S_2 ⟶ ≥ 1.8e-06 GB needed for S_2\n",
      "\n",
      "\n",
      "X_2:\n",
      "\t 180 rows=pfvs in S_2 = 180 rows=extensions in X_2\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 20 binary cells\n",
      "\t 20 cells/extension * 8 bits/cell * 180 extensions in X_2 ⟶ ≥ 3.6e-06 GB needed for X_2\n",
      "i = 3\n",
      "S_3:\n",
      "\t m=20 choose i=3 = 120.0\n",
      "\t 2^i = 8\n",
      "\t (m choose i) * 2^i = 960.0\n",
      "\t 960 rows = 960 partial feature vectors in S_3\n",
      "\t 10 cells/pfv * 8 bits/cell * 960 pfvs in S_3 ⟶ ≥ 9.6e-06 GB needed for S_3\n",
      "\n",
      "\n",
      "X_3:\n",
      "\t 960 rows=pfvs in S_3 = 960 rows=extensions in X_3\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 20 binary cells\n",
      "\t 20 cells/extension * 8 bits/cell * 960 extensions in X_3 ⟶ ≥ 1.92e-05 GB needed for X_3\n",
      "i = 4\n",
      "S_4:\n",
      "\t m=20 choose i=4 = 210.0\n",
      "\t 2^i = 16\n",
      "\t (m choose i) * 2^i = 3,360.0\n",
      "\t 3,360 rows = 3,360 partial feature vectors in S_4\n",
      "\t 10 cells/pfv * 8 bits/cell * 3,360 pfvs in S_4 ⟶ ≥ 3.36e-05 GB needed for S_4\n",
      "\n",
      "\n",
      "X_4:\n",
      "\t 3,360 rows=pfvs in S_4 = 3,360 rows=extensions in X_4\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 20 binary cells\n",
      "\t 20 cells/extension * 8 bits/cell * 3,360 extensions in X_4 ⟶ ≥ 6.72e-05 GB needed for X_4\n",
      "i = 5\n",
      "S_5:\n",
      "\t m=20 choose i=5 = 252.0\n",
      "\t 2^i = 32\n",
      "\t (m choose i) * 2^i = 8,064.0\n",
      "\t 8,064 rows = 8,064 partial feature vectors in S_5\n",
      "\t 10 cells/pfv * 8 bits/cell * 8,064 pfvs in S_5 ⟶ ≥ 8.064e-05 GB needed for S_5\n",
      "\n",
      "\n",
      "X_5:\n",
      "\t 8,064 rows=pfvs in S_5 = 8,064 rows=extensions in X_5\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 20 binary cells\n",
      "\t 20 cells/extension * 8 bits/cell * 8,064 extensions in X_5 ⟶ ≥ 0.00016128 GB needed for X_5\n",
      "i = 6\n",
      "S_6:\n",
      "\t m=20 choose i=6 = 210.0\n",
      "\t 2^i = 64\n",
      "\t (m choose i) * 2^i = 13,440.0\n",
      "\t 13,440 rows = 13,440 partial feature vectors in S_6\n",
      "\t 10 cells/pfv * 8 bits/cell * 13,440 pfvs in S_6 ⟶ ≥ 0.0001344 GB needed for S_6\n",
      "\n",
      "\n",
      "X_6:\n",
      "\t 13,440 rows=pfvs in S_6 = 13,440 rows=extensions in X_6\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 20 binary cells\n",
      "\t 20 cells/extension * 8 bits/cell * 13,440 extensions in X_6 ⟶ ≥ 0.0002688 GB needed for X_6\n",
      "i = 7\n",
      "S_7:\n",
      "\t m=20 choose i=7 = 120.0\n",
      "\t 2^i = 128\n",
      "\t (m choose i) * 2^i = 15,360.0\n",
      "\t 15,360 rows = 15,360 partial feature vectors in S_7\n",
      "\t 10 cells/pfv * 8 bits/cell * 15,360 pfvs in S_7 ⟶ ≥ 0.0001536 GB needed for S_7\n",
      "\n",
      "\n",
      "X_7:\n",
      "\t 15,360 rows=pfvs in S_7 = 15,360 rows=extensions in X_7\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 20 binary cells\n",
      "\t 20 cells/extension * 8 bits/cell * 15,360 extensions in X_7 ⟶ ≥ 0.0003072 GB needed for X_7\n",
      "i = 8\n",
      "S_8:\n",
      "\t m=20 choose i=8 = 45.0\n",
      "\t 2^i = 256\n",
      "\t (m choose i) * 2^i = 11,520.0\n",
      "\t 11,520 rows = 11,520 partial feature vectors in S_8\n",
      "\t 10 cells/pfv * 8 bits/cell * 11,520 pfvs in S_8 ⟶ ≥ 0.0001152 GB needed for S_8\n",
      "\n",
      "\n",
      "X_8:\n",
      "\t 11,520 rows=pfvs in S_8 = 11,520 rows=extensions in X_8\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 20 binary cells\n",
      "\t 20 cells/extension * 8 bits/cell * 11,520 extensions in X_8 ⟶ ≥ 0.0002304 GB needed for X_8\n",
      "i = 9\n",
      "S_9:\n",
      "\t m=20 choose i=9 = 10.0\n",
      "\t 2^i = 512\n",
      "\t (m choose i) * 2^i = 5,120.0\n",
      "\t 5,120 rows = 5,120 partial feature vectors in S_9\n",
      "\t 10 cells/pfv * 8 bits/cell * 5,120 pfvs in S_9 ⟶ ≥ 5.12e-05 GB needed for S_9\n",
      "\n",
      "\n",
      "X_9:\n",
      "\t 5,120 rows=pfvs in S_9 = 5,120 rows=extensions in X_9\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 20 binary cells\n",
      "\t 20 cells/extension * 8 bits/cell * 5,120 extensions in X_9 ⟶ ≥ 0.0001024 GB needed for X_9\n",
      "i = 10\n",
      "S_10:\n",
      "\t m=20 choose i=10 = 1.0\n",
      "\t 2^i = 1,024\n",
      "\t (m choose i) * 2^i = 1,024.0\n",
      "\t 1,024 rows = 1,024 partial feature vectors in S_10\n",
      "\t 10 cells/pfv * 8 bits/cell * 1,024 pfvs in S_10 ⟶ ≥ 1.024e-05 GB needed for S_10\n",
      "\n",
      "\n",
      "X_10:\n",
      "\t 1,024 rows=pfvs in S_10 = 1,024 rows=extensions in X_10\n",
      "\t Each extension (as an index vector/naive indicator function) has l = 20 binary cells\n",
      "\t 20 cells/extension * 8 bits/cell * 1,024 extensions in X_10 ⟶ ≥ 2.048e-05 GB needed for X_10\n",
      "\n",
      "\n",
      "Total number of S cells = 590,490\n",
      "Total number of X cells = 1,180,980\n",
      "Total number of cells = 1,771,470\n",
      "Min. GB for storing S = 0.00059049\n",
      "Min. GB for storing X = 0.00118098\n",
      "Min. GB for storing S + X = 0.00177147\n"
     ]
    }
   ],
   "source": [
    "feature_set_size = num_features\n",
    "# feature_set_size = 20\n",
    "# feature_set_size = 23 # = num features in bakovic_chart_riggle_hayes{.tsv,.json}\n",
    "\n",
    "segment_inventory_size = len(objects)\n",
    "# segment_inventory_size = 40\n",
    "# segment_inventory_size = 96 # = num symbols in bakovic_chart_riggle_hayes{.tsv,.json}\n",
    "# segment_inventory_size = 120\n",
    "\n",
    "# bits_per_cell = 2\n",
    "# bits_per_cell = 4\n",
    "bits_per_cell = 8\n",
    "\n",
    "print('Assuming a feature set of size {0}'.format(feature_set_size))\n",
    "print('Assuming a segment inventory of size {0}...'.format(segment_inventory_size))\n",
    "print('Assuming each cell requires ≥ {0} bits of storage'.format(bits_per_cell))\n",
    "\n",
    "S_cells = []\n",
    "X_cells = []\n",
    "for i in range(feature_set_size + 1):\n",
    "    print('i = {0}'.format(i))\n",
    "\n",
    "    print('S_{0}:'.format(i))\n",
    "    print('\\t m={0} choose i={1} = {2:,}'.format(segment_inventory_size, i, binom(feature_set_size, i)))\n",
    "    print('\\t 2^i = {0:,}'.format(2 ** i))\n",
    "    print('\\t (m choose i) * 2^i = {0:,}'.format(binom(feature_set_size, i) * (2 ** i)))\n",
    "    num_pfvs_in_Si = int(binom(feature_set_size, i) * (2 ** i))\n",
    "    # num_ints_in_Xi = num_pfvs_in_Si * segment_inventory_size\n",
    "    \n",
    "    print('\\t {0:,} rows = {0:,} partial feature vectors in S_{1}'.format(num_pfvs_in_Si, i))\n",
    "    cells_per_pfv = int(feature_set_size)\n",
    "    bits_per_pfv = cells_per_pfv * bits_per_cell\n",
    "    bits_for_Si = bits_per_pfv * num_pfvs_in_Si\n",
    "    GB_for_Si = bits_for_Si / 8e9\n",
    "    print('\\t {0} cells/pfv * {1} bits/cell * {2:,} pfvs in S_{3} ⟶ ≥ {4} GB needed for S_{3}'.format(cells_per_pfv, bits_per_cell, num_pfvs_in_Si, i, GB_for_Si))\n",
    "    cells_for_Si = int(num_pfvs_in_Si * cells_per_pfv)\n",
    "    S_cells.append(cells_for_Si)\n",
    "\n",
    "    print('\\n')\n",
    "\n",
    "    print('X_{0}:'.format(i))\n",
    "    print(\"\\t {0:,} rows=pfvs in S_{1} = {0:,} rows=extensions in X_{1}\".format(num_pfvs_in_Si, i))\n",
    "    print('\\t Each extension (as an index vector/naive indicator function) has l = {0} binary cells'.format(segment_inventory_size))\n",
    "    num_extensions_in_Xi = int(num_pfvs_in_Si)\n",
    "    cells_per_extension = int(segment_inventory_size)\n",
    "    bits_per_extension = cells_per_extension * bits_per_cell\n",
    "    bits_for_Xi = bits_per_extension * num_extensions_in_Xi\n",
    "    GB_for_Xi = bits_for_Xi / 8e9\n",
    "    print('\\t {0} cells/extension * {1} bits/cell * {2:,} extensions in X_{3} ⟶ ≥ {4} GB needed for X_{3}'.format(cells_per_extension, bits_per_cell, num_extensions_in_Xi, i, GB_for_Xi))\n",
    "    cells_for_Xi = int(num_extensions_in_Xi * cells_per_extension)\n",
    "    X_cells.append(cells_for_Xi)\n",
    "    # print(\"\\t {0:,} rows * {1:,} columns = {2:,} cells in S_{3}\".format(num_pfvs_in_Si, segment_inventory_size, num_ints_in_Xi, i))\n",
    "    \n",
    "    # num_cells_required = (binom(feature_set_size, i) * (2 ** i)) * segment_inventory_size\n",
    "    # print(\"\\t minimum of {0:,} GB required if S_{1} stored using {2} bits/int\".format(num_cells_required * bits_per_cell / 8e9, i, bits_per_cell))\n",
    "    # S_cells.append( num_cells_required )\n",
    "    \n",
    "    # print('\\t 2^{0} = {1:,}'.format(segment_inventory_size, 2 ** segment_inventory_size))\n",
    "    # print('\\t {0:,} rows in S_{1} * {2} objects = {3} cells in X_{1}'.format())\n",
    "    # num_X_cells_required = 2 ** segment_inventory_size\n",
    "    # print('\\t minimum of {0:,} GB required if X_{1} stored using {2} bits/int'.format(num_X_cells_required * bits_per_cell / 8e9, i, bits_per_cell))\n",
    "    # X_cells.append( num_X_cells_required )\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "num_S_cells = sum(S_cells)\n",
    "num_X_cells = sum(X_cells)\n",
    "total_number_of_cells = num_S_cells + num_X_cells\n",
    "\n",
    "print('Total number of S cells = {0:,}'.format(num_S_cells))\n",
    "print('Total number of X cells = {0:,}'.format(num_X_cells))\n",
    "print('Total number of cells = {0:,}'.format(total_number_of_cells))\n",
    "\n",
    "S_bits = num_S_cells * bits_per_cell\n",
    "X_bits = num_X_cells * bits_per_cell\n",
    "total_bits = S_bits + X_bits\n",
    "\n",
    "print('Min. GB for storing S = {0:,}'.format(S_bits / 8e9))\n",
    "print('Min. GB for storing X = {0:,}'.format(X_bits / 8e9))\n",
    "print('Min. GB for storing S + X = {0:,}'.format( (S_bits + X_bits) / 8e9 ))\n",
    "\n",
    "# print('Min. storage required, in GB, assuming each cell requires ≥ {1} bits = {0:,}'.format(n_GB_required, bits_per_cell))\n",
    "\n",
    "# total_number_of_cells_X = sum(X_cells)\n",
    "# print('Total number of X_i cells = {0:,}'.format(total_number_of_cells_X))\n",
    "# n_bits_required_X = total_number_of_cells_X * bits_per_cell\n",
    "# n_GB_required_X = n_bits_required_X / 8e9\n",
    "# print('Min. storage required, in GB, assuming each cell requires ≥ {1} bits = {0:,}'.format(n_GB_required_X, bits_per_cell))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.408868Z",
     "start_time": "2019-05-01T16:13:44.403424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 0\n",
      "\t m choose i = 1.0\n",
      "\t 2^i = 1\n",
      "\t (m choose i) * 2^i = 1.0\n",
      "i = 1\n",
      "\t m choose i = 10.0\n",
      "\t 2^i = 2\n",
      "\t (m choose i) * 2^i = 20.0\n",
      "i = 2\n",
      "\t m choose i = 45.0\n",
      "\t 2^i = 4\n",
      "\t (m choose i) * 2^i = 180.0\n",
      "i = 3\n",
      "\t m choose i = 120.0\n",
      "\t 2^i = 8\n",
      "\t (m choose i) * 2^i = 960.0\n",
      "i = 4\n",
      "\t m choose i = 210.0\n",
      "\t 2^i = 16\n",
      "\t (m choose i) * 2^i = 3360.0\n",
      "i = 5\n",
      "\t m choose i = 252.0\n",
      "\t 2^i = 32\n",
      "\t (m choose i) * 2^i = 8064.0\n",
      "i = 6\n",
      "\t m choose i = 210.0\n",
      "\t 2^i = 64\n",
      "\t (m choose i) * 2^i = 13440.0\n",
      "i = 7\n",
      "\t m choose i = 120.0\n",
      "\t 2^i = 128\n",
      "\t (m choose i) * 2^i = 15360.0\n",
      "i = 8\n",
      "\t m choose i = 45.0\n",
      "\t 2^i = 256\n",
      "\t (m choose i) * 2^i = 11520.0\n",
      "i = 9\n",
      "\t m choose i = 10.0\n",
      "\t 2^i = 512\n",
      "\t (m choose i) * 2^i = 5120.0\n",
      "i = 10\n",
      "\t m choose i = 1.0\n",
      "\t 2^i = 1024\n",
      "\t (m choose i) * 2^i = 1024.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_features + 1):\n",
    "    print('i = {0}'.format(i))\n",
    "    print('\\t m choose i = {0}'.format(binom(num_features, i)))\n",
    "    print('\\t 2^i = {0}'.format(2 ** i))\n",
    "    print('\\t (m choose i) * 2^i = {0}'.format(binom(num_features, i) * (2 ** i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing $S_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.426717Z",
     "start_time": "2019-05-01T16:13:44.410771Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int8),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int8),\n",
       " array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0], dtype=int8),\n",
       " array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0], dtype=int8),\n",
       " array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0], dtype=int8),\n",
       " array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int8),\n",
       " array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0], dtype=int8),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0], dtype=int8),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0], dtype=int8),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=int8),\n",
       " array([-1,  0,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int8),\n",
       " array([ 0, -1,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int8),\n",
       " array([ 0,  0, -1,  0,  0,  0,  0,  0,  0,  0], dtype=int8),\n",
       " array([ 0,  0,  0, -1,  0,  0,  0,  0,  0,  0], dtype=int8),\n",
       " array([ 0,  0,  0,  0, -1,  0,  0,  0,  0,  0], dtype=int8),\n",
       " array([ 0,  0,  0,  0,  0, -1,  0,  0,  0,  0], dtype=int8),\n",
       " array([ 0,  0,  0,  0,  0,  0, -1,  0,  0,  0], dtype=int8),\n",
       " array([ 0,  0,  0,  0,  0,  0,  0, -1,  0,  0], dtype=int8),\n",
       " array([ 0,  0,  0,  0,  0,  0,  0,  0, -1,  0], dtype=int8),\n",
       " array([ 0,  0,  0,  0,  0,  0,  0,  0,  0, -1], dtype=int8)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basis_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.441276Z",
     "start_time": "2019-05-01T16:13:44.428477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int8)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S0 = np.zeros((1,num_features), dtype=myint)\n",
    "S0\n",
    "S0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.457158Z",
     "start_time": "2019-05-01T16:13:44.443554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  1,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  1,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  1,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  1,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  1,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  1,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  1,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  1],\n",
       "       [-1,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, -1,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0, -1,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, -1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, -1,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, -1,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0, -1,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, -1,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, -1,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, -1]], dtype=int8)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(20, 10)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S1 = np.array(basis_vectors, dtype=myint)\n",
    "S1\n",
    "S1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.462225Z",
     "start_time": "2019-05-01T16:13:44.458919Z"
    }
   },
   "outputs": [],
   "source": [
    "def grand_union(pfvs):\n",
    "    return reduce(union, pfvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.473146Z",
     "start_time": "2019-05-01T16:13:44.463984Z"
    }
   },
   "outputs": [],
   "source": [
    "def indexChoicesToComponentOptions(index_choices):\n",
    "    indices = list(index_choices)\n",
    "    one_hots = one_hot_stack(indices)\n",
    "    component_options = tuple([(v, -1 * v) for v in one_hots])\n",
    "    return component_options\n",
    "\n",
    "def componentOptionsToChoices(component_options):\n",
    "    choice_combinations = tuple(product(*component_options))\n",
    "#     return tuple(starmap(union,\n",
    "#                          choice_combinations))\n",
    "    return tuple(map(grand_union,\n",
    "                     choice_combinations))\n",
    "\n",
    "def make_Si_naive(i):\n",
    "    index_choices = combinations(range(num_features), i)\n",
    "    componentOptions = (indexChoicesToComponentOptions(c) for c in index_choices)\n",
    "    componentChoices = (componentOptionsToChoices(o) for o in componentOptions)\n",
    "    choices_flattened = reduce(lambda a,b: a + b, componentChoices)\n",
    "    return np.array(choices_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.496183Z",
     "start_time": "2019-05-01T16:13:44.474960Z"
    }
   },
   "outputs": [],
   "source": [
    "S2_naive = make_Si_naive(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.505176Z",
     "start_time": "2019-05-01T16:13:44.497417Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  0, ...,  0,  0,  0],\n",
       "       [ 1, -1,  0, ...,  0,  0,  0],\n",
       "       [-1,  1,  0, ...,  0,  0,  0],\n",
       "       ..., \n",
       "       [ 0,  0,  0, ...,  0,  1, -1],\n",
       "       [ 0,  0,  0, ...,  0, -1,  1],\n",
       "       [ 0,  0,  0, ...,  0, -1, -1]], dtype=int8)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(180, 10)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S2_naive\n",
    "S2_naive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.511590Z",
     "start_time": "2019-05-01T16:13:44.507021Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2 ** 2) * binom(5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.617962Z",
     "start_time": "2019-05-01T16:13:44.513268Z"
    }
   },
   "outputs": [],
   "source": [
    "S3_naive = make_Si_naive(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:13:44.626377Z",
     "start_time": "2019-05-01T16:13:44.619412Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 10)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  1, ...,  0,  0,  0],\n",
       "       [ 1,  1, -1, ...,  0,  0,  0],\n",
       "       [ 1, -1,  1, ...,  0,  0,  0],\n",
       "       ..., \n",
       "       [ 0,  0,  0, ..., -1,  1, -1],\n",
       "       [ 0,  0,  0, ..., -1, -1,  1],\n",
       "       [ 0,  0,  0, ..., -1, -1, -1]], dtype=int8)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S3_naive.shape\n",
    "S3_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:14:02.483166Z",
     "start_time": "2019-05-01T16:13:44.628137Z"
    }
   },
   "outputs": [],
   "source": [
    "Ss_naive = [S0, S1]\n",
    "for i in range(2, num_features+1):\n",
    "    Ss_naive.append(make_Si_naive(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:14:02.500643Z",
     "start_time": "2019-05-01T16:14:02.484648Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(20, 10)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(180, 10)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(960, 10)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(3360, 10)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(8064, 10)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(13440, 10)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(15360, 10)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(11520, 10)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(5120, 10)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1024, 10)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features\n",
    "2 * num_features\n",
    "\n",
    "for Si in Ss_naive:\n",
    "    Si.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:14:02.554065Z",
     "start_time": "2019-05-01T16:14:02.501852Z"
    }
   },
   "outputs": [],
   "source": [
    "#TODO/optimization: this could/should be parallelized\n",
    "def make_Si(i, Sj):\n",
    "    assert i > 1\n",
    "    # NB j = i-1\n",
    "#     print('i = {0}'.format(i))\n",
    "#     print('\\t|S1 x Sj| = {0}'.format(len(tuple(product(S1, Sj)))))\n",
    "    Si_ = np.array([union(u,v) for u,v in filter(lambda pair: agree_(*pair) and not np.array_equal(pair[0], pair[1]), \n",
    "                                                 product(S1, Sj))], \n",
    "                   dtype=myint)\n",
    "#     print('\\t|Si_| = {0}'.format(Si_.shape))\n",
    "    Si__ = set(np2t(Si_)) - set(np2t(Sj))\n",
    "#     print('\\t|Si__| = {0}'.format(len(Si__)))\n",
    "    Si = np.array(tuple(Si__), dtype=myint)\n",
    "    return Si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:15:39.869628Z",
     "start_time": "2019-05-01T16:14:02.555181Z"
    }
   },
   "outputs": [],
   "source": [
    "Ss = [S0, S1]\n",
    "for i in range(2, num_features+1):\n",
    "    Ss.append(make_Si(i, Ss[i-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:15:39.885752Z",
     "start_time": "2019-05-01T16:15:39.871256Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(20, 10)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(180, 10)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(960, 10)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(3360, 10)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(8064, 10)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(13440, 10)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(15360, 10)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(11520, 10)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(5120, 10)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1024, 10)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features\n",
    "2 * num_features\n",
    "\n",
    "for Si in Ss:\n",
    "    Si.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:15:40.280999Z",
     "start_time": "2019-05-01T16:15:39.886848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 0\n",
      "set()\n",
      "set()\n",
      "\n",
      "\n",
      "i = 1\n",
      "set()\n",
      "set()\n",
      "\n",
      "\n",
      "i = 2\n",
      "set()\n",
      "set()\n",
      "\n",
      "\n",
      "i = 3\n",
      "set()\n",
      "set()\n",
      "\n",
      "\n",
      "i = 4\n",
      "set()\n",
      "set()\n",
      "\n",
      "\n",
      "i = 5\n",
      "set()\n",
      "set()\n",
      "\n",
      "\n",
      "i = 6\n",
      "set()\n",
      "set()\n",
      "\n",
      "\n",
      "i = 7\n",
      "set()\n",
      "set()\n",
      "\n",
      "\n",
      "i = 8\n",
      "set()\n",
      "set()\n",
      "\n",
      "\n",
      "i = 9\n",
      "set()\n",
      "set()\n",
      "\n",
      "\n",
      "i = 10\n",
      "set()\n",
      "set()\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_features+1):\n",
    "    print('i = {0}'.format(i))\n",
    "    Si = set(np2t(Ss[i]))\n",
    "    Si_naive = set(np2t(Ss_naive[i]))\n",
    "    unique_to_Si = Si - Si_naive\n",
    "    unique_to_Si_naive = Si_naive - Si\n",
    "    print(unique_to_Si)\n",
    "    print(unique_to_Si_naive)\n",
    "    assert Si == Si_naive\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing $\\overline{S}_i$ given $S_{i-1}$ or $\\overline{S}_{i-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:15:40.287829Z",
     "start_time": "2019-05-01T16:15:40.282696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=int8)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extension_naive(random_partial_fv)\n",
    "extension_naive(random_partial_fv).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:15:40.295656Z",
     "start_time": "2019-05-01T16:15:40.289369Z"
    }
   },
   "outputs": [],
   "source": [
    "def distinct(u, v):\n",
    "    return not np.array_equal(u, v)\n",
    "\n",
    "def empty_extension(u):\n",
    "    return np.array_equal(extension_naive(u), np.zeros((len(objects),), dtype=myint))\n",
    "\n",
    "def keep(pair):\n",
    "    u = pair[0]\n",
    "    v = pair[1]\n",
    "    consistent = agree_(*pair)\n",
    "    different = distinct(u, v)\n",
    "    non_empty = (not empty_extension(u)) and (not empty_extension(v))\n",
    "    return consistent and different and non_empty\n",
    "\n",
    "#TODO/optimization: this could/should be parallelized\n",
    "def make_Si_bar(i, Sj):\n",
    "    assert i > 1\n",
    "    # NB j = i-1\n",
    "#     print('i = {0}'.format(i))\n",
    "#     print('\\t|S1 x Sj| = {0}'.format(len(tuple(product(S1, Sj)))))\n",
    "    Si_bar_ = np.array([union(u,v) for u,v in filter(keep, product(S1, Sj))],\n",
    "                       dtype=myint)\n",
    "#     print('\\t|Si_bar_| = {0}'.format(Si_bar_.shape))\n",
    "    Si_bar__ = set(np2t(Si_bar_)) - set(np2t(Sj))\n",
    "#     print('\\t|Si_bar__| = {0}'.format(len(Si_bar__)))\n",
    "    Si_bar = np.array(tuple(Si_bar__), dtype=myint)\n",
    "    return Si_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the savings (with respect to the current randomly generated set of objects and number of features)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:15:41.226686Z",
     "start_time": "2019-05-01T16:15:40.296973Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 10)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(180, 10)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S2_bar = make_Si_bar(2, S1)\n",
    "S2_bar.shape\n",
    "Ss[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:15:48.557321Z",
     "start_time": "2019-05-01T16:15:41.228028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 10)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(960, 10)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S3_bar = make_Si_bar(3, Ss[2])\n",
    "S3_bar.shape\n",
    "Ss[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:16:24.770707Z",
     "start_time": "2019-05-01T16:15:48.558736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3358, 10)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(3360, 10)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S4_bar = make_Si_bar(4, Ss[3])\n",
    "S4_bar.shape\n",
    "Ss[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:18:27.760293Z",
     "start_time": "2019-05-01T16:16:24.777142Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7854, 10)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(8064, 10)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S5_bar = make_Si_bar(5, Ss[4])\n",
    "S5_bar.shape\n",
    "Ss[5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:23:24.702668Z",
     "start_time": "2019-05-01T16:18:27.761945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11755, 10)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(13440, 10)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S6_bar = make_Si_bar(6, Ss[5])\n",
    "S6_bar.shape\n",
    "Ss[6].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:31:38.280392Z",
     "start_time": "2019-05-01T16:23:24.703780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10686, 10)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(15360, 10)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S7_bar = make_Si_bar(7, Ss[6])\n",
    "S7_bar.shape\n",
    "Ss[7].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposing $S_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:31:38.286946Z",
     "start_time": "2019-05-01T16:31:38.281586Z"
    }
   },
   "outputs": [],
   "source": [
    "def b_factors_(partial_feature_vectors):\n",
    "    big_shape = partial_feature_vectors.shape\n",
    "    num_vectors = big_shape[0]\n",
    "    \n",
    "    a_vector = partial_feature_vectors[0]\n",
    "    num_specified_features = np.sum(np.abs(a_vector))\n",
    "    \n",
    "    my_shape = (num_vectors, num_specified_features)\n",
    "    my_non_zeros = np.reshape(np.nonzero(partial_feature_vectors)[1], my_shape)\n",
    "#     print(my_non_zeros.shape)\n",
    "#     my_non_zeros = np.transpose(my_non_zeros, (0, 2, 1))\n",
    "#     return my_non_zeros\n",
    "    my_one_hot_stack = one_hot_stack(  my_non_zeros  )#.transpose((0,2,1))\n",
    "    return my_one_hot_stack * np.sign(partial_feature_vectors).reshape((num_vectors, 1, num_features))\n",
    "\n",
    "def decompose_(partial_feature_vectors):\n",
    "    Bs = b_factors_(partial_feature_vectors)\n",
    "    bs = Bs[:,0,:]\n",
    "    vs = partial_feature_vectors - bs\n",
    "    assert all([wffv(v) for v in vs])\n",
    "    return bs, vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:31:38.319370Z",
     "start_time": "2019-05-01T16:31:38.288060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 2, 10)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_factors_(S2_naive).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:31:38.326203Z",
     "start_time": "2019-05-01T16:31:38.320219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int8)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int8)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S2_naive[2]\n",
    "np.sign(S2_naive[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:31:38.344153Z",
     "start_time": "2019-05-01T16:31:38.327086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  1,  0,  0,  0,  0,  0,  0,  0,  0]], dtype=int8)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "       [[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]], dtype=int8)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_factors_(S2_naive)[2]\n",
    "one_hot_stack( b_factors_(S2_naive)[2] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:31:38.348313Z",
     "start_time": "2019-05-01T16:31:38.345288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0,  0, ...,  0,  0,  0],\n",
       "       [ 1,  0,  0, ...,  0,  0,  0],\n",
       "       [-1,  0,  0, ...,  0,  0,  0],\n",
       "       ..., \n",
       "       [ 0,  0,  0, ...,  0,  1,  0],\n",
       "       [ 0,  0,  0, ...,  0, -1,  0],\n",
       "       [ 0,  0,  0, ...,  0, -1,  0]], dtype=int8)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_factors_(S2_naive)[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:31:38.355513Z",
     "start_time": "2019-05-01T16:31:38.349208Z"
    }
   },
   "outputs": [],
   "source": [
    "B2, V2 = decompose_(S2_naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:31:38.359447Z",
     "start_time": "2019-05-01T16:31:38.356408Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0,  0, ...,  0,  0,  0],\n",
       "       [ 1,  0,  0, ...,  0,  0,  0],\n",
       "       [-1,  0,  0, ...,  0,  0,  0],\n",
       "       ..., \n",
       "       [ 0,  0,  0, ...,  0,  1,  0],\n",
       "       [ 0,  0,  0, ...,  0, -1,  0],\n",
       "       [ 0,  0,  0, ...,  0, -1,  0]], dtype=int8)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:31:38.365704Z",
     "start_time": "2019-05-01T16:31:38.360281Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  0,  0,  0,  0,  0,  0,  0,  0], dtype=int8)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[-1,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  1,  0,  0,  0,  0,  0,  0,  0,  0]], dtype=int8)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S2_naive[2]\n",
    "b_factors_(S2_naive)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:31:38.371494Z",
     "start_time": "2019-05-01T16:31:38.366715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  0, ...,  0,  0,  0],\n",
       "       [ 0, -1,  0, ...,  0,  0,  0],\n",
       "       [ 0,  1,  0, ...,  0,  0,  0],\n",
       "       ..., \n",
       "       [ 0,  0,  0, ...,  0,  0, -1],\n",
       "       [ 0,  0,  0, ...,  0,  0,  1],\n",
       "       [ 0,  0,  0, ...,  0,  0, -1]], dtype=int8)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:31:38.377224Z",
     "start_time": "2019-05-01T16:31:38.372359Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  0, ...,  0,  0,  0],\n",
       "       [ 1, -1,  0, ...,  0,  0,  0],\n",
       "       [-1,  1,  0, ...,  0,  0,  0],\n",
       "       ..., \n",
       "       [ 0,  0,  0, ...,  0,  1, -1],\n",
       "       [ 0,  0,  0, ...,  0, -1,  1],\n",
       "       [ 0,  0,  0, ...,  0, -1, -1]], dtype=int8)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S2_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:31:38.382655Z",
     "start_time": "2019-05-01T16:31:38.378042Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(B2 + V2, S2_naive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating $X_i = ⟦S_i⟧$: $S_i = B \\cup V \\iff ⟦S_i⟧ = ⟦B⟧ \\cap ⟦V⟧$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **Dimensions:** If $S_i$ is a matrix of dimensions $(\\binom{m}{i} \\cdot 2^i, m)$, then $⟦S_i⟧ = X_i$ is a matrix of size $(\\binom{m}{i} \\cdot 2^i, l)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **Construction:** Just as $S_i$ can be decomposed into the row-wise (well, element-wise) sum of two matrices $B + V = B \\cup V$ s.t. all rows of $B$ come from $S_1$ and all rows of $V$ come from $S_{i-1}$, we can construct $X_i = ⟦S_i⟧$ as the row-wise intersection $⟦B⟧ \\cap ⟦V⟧$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:31:38.390960Z",
     "start_time": "2019-05-01T16:31:38.383489Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1, -1,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [-1,  1,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [-1, -1,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1,  0,  1,  0,  0,  0,  0,  0,  0,  0]], dtype=int8)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [-1,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [-1,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 1,  0,  0,  0,  0,  0,  0,  0,  0,  0]], dtype=int8)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, -1,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  1,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, -1,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  1,  0,  0,  0,  0,  0,  0,  0]], dtype=int8)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S2_naive[:5]\n",
    "B2[:5]\n",
    "V2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:31:38.396965Z",
     "start_time": "2019-05-01T16:31:38.391827Z"
    }
   },
   "outputs": [],
   "source": [
    "#TODO/optimization: this could/should be parallelized\n",
    "def extension_naive_(Vs):#, asIndexVectors=True):\n",
    "    '''\n",
    "    The extension of a stack of partial feature vectors Vs is \n",
    "    a stack of index vectors indicating the corresponding \n",
    "    vectors (= fully specified feature vectors) that 'agree' \n",
    "    with each partial feature vector in Vs.\n",
    "    '''\n",
    "    matches = tuple([[o for o in objects if agree(v,o).all()] for v in Vs])\n",
    "##     matches = np.array([[1.0 if np.linalg.norm(agree(v,o), 1) == num_features else 0.0 for o in objects]\n",
    "#                         for v in Vs])\n",
    "#     if asIndexVector:\n",
    "#         return makeExtensionVector([getIndex(o) for o in matches])\n",
    "#     return matches\n",
    "    extension_vectors = np.array([makeExtensionVector([getIndex(o) for o in matches_v])\n",
    "                                  for matches_v in matches])\n",
    "#     assert np.array_equal(extension_vectors, np.array([extension_naive(v) for v in Vs]))\n",
    "    return extension_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:31:38.939252Z",
     "start_time": "2019-05-01T16:31:38.397850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 20)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int8)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int8)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_naive = extension_naive_(S2_naive)\n",
    "X2_naive.shape\n",
    "X2_naive[:5]\n",
    "\n",
    "X2_naive_alt = intersection(extension_naive_(B2), \n",
    "                            extension_naive_(V2))\n",
    "X2_naive_alt[:5]\n",
    "\n",
    "np.array_equal(X2_naive,\n",
    "               X2_naive_alt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:31:38.944858Z",
     "start_time": "2019-05-01T16:31:38.940515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_naive.nbytes\n",
    "X2_naive_alt.nbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressing arrays and matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparse representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:31:55.023351Z",
     "start_time": "2019-05-01T16:31:51.962862Z"
    }
   },
   "outputs": [],
   "source": [
    "import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:39:46.049180Z",
     "start_time": "2019-05-01T16:39:46.044887Z"
    }
   },
   "outputs": [],
   "source": [
    "def density(a):\n",
    "    num_cells = reduce(lambda x,y: x * y, a.shape)\n",
    "    d = len(np.nonzero(a)[0]) / num_cells\n",
    "    return d\n",
    "\n",
    "def sparsity(a):\n",
    "    return 1 - density(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:39:48.823432Z",
     "start_time": "2019-05-01T16:39:46.969043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, -1,  1, -1,  0,  0,  0,  0,  0,  1])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_partial_fv\n",
    "sparsity(random_partial_fv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:39:54.542479Z",
     "start_time": "2019-05-01T16:39:54.534952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "15300"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparsity(X2_naive)\n",
    "\n",
    "X2_naive.nbytes\n",
    "\n",
    "X2_naive_sparse = sparse.COO(X2_naive)\n",
    "X2_naive_sparse.nbytes #????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:40:51.406348Z",
     "start_time": "2019-05-01T16:40:51.388934Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30000000000000004"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "153600"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1827840"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.30000000000000004"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "106860"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparsity(Ss[7])\n",
    "Ss[7].nbytes\n",
    "\n",
    "S7_sparse = sparse.COO(Ss[7])\n",
    "S7_sparse.nbytes\n",
    "\n",
    "sparsity(S7_bar)\n",
    "S7_bar.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:43:33.673128Z",
     "start_time": "2019-05-01T16:43:28.569044Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96875"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "161280"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "85680"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X5 = extension_naive_(Ss[5])\n",
    "sparsity(X5)\n",
    "X5.nbytes\n",
    "\n",
    "X5_sparse = sparse.COO(X5)\n",
    "X5_sparse.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:43:28.567344Z",
     "start_time": "2019-05-01T16:43:18.335827Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9921875"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "307200"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "40800"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X7 = extension_naive_(Ss[7])\n",
    "sparsity(X7)\n",
    "X7.nbytes\n",
    "\n",
    "X7_sparse = sparse.COO(X7)\n",
    "X7_sparse.nbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `bitarray`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:31:39.023047Z",
     "start_time": "2019-05-01T16:31:38.949840Z"
    }
   },
   "outputs": [],
   "source": [
    "from bitarray import bitarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:31:39.027207Z",
     "start_time": "2019-05-01T16:31:39.024622Z"
    }
   },
   "outputs": [],
   "source": [
    "codebook = {-1:bitarray('00'),\n",
    "            0:bitarray('01'),\n",
    "            1:bitarray('10')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:31:39.034818Z",
     "start_time": "2019-05-01T16:31:39.028289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bitarray('000110')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = bitarray()\n",
    "r.encode(codebook, [-1,0,1])\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:31:39.041159Z",
     "start_time": "2019-05-01T16:31:39.035930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, 0, 1]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.decode(codebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:31:39.048179Z",
     "start_time": "2019-05-01T16:31:39.042248Z"
    }
   },
   "outputs": [],
   "source": [
    "def indexArrayToBA(ia):\n",
    "    return bitarray(list(ia))\n",
    "\n",
    "def baToIndexArray(ba):\n",
    "    return np.array(list(map(int, ba.tolist())), dtype=myint)\n",
    "\n",
    "def indexMatrixToBAs(im):\n",
    "    return list(map(indexArrayToBA, im))\n",
    "\n",
    "def basToIndexMatrix(bas):\n",
    "    return np.array(list(map(baToIndexArray, bas)), dtype=myint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:31:39.055349Z",
     "start_time": "2019-05-01T16:31:39.049402Z"
    }
   },
   "outputs": [],
   "source": [
    "def pfvToBA(pfv):\n",
    "    ba = bitarray()\n",
    "    ba.encode(codebook, list(pfv))\n",
    "    return ba\n",
    "\n",
    "def baToPFV(ba):\n",
    "    return np.array(ba.decode(codebook), dtype=myint)\n",
    "\n",
    "def pfvsToBAs(pfvs):\n",
    "    return list(map(pfvToBA, pfvs))\n",
    "\n",
    "def basToPFVs(bas):\n",
    "    return np.array(list(map(baToPFV, bas)), dtype=myint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:31:39.062845Z",
     "start_time": "2019-05-01T16:31:39.056513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, -1,  1, -1,  0,  0,  0,  0,  0,  1])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "bitarray('01001000010101010110')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_partial_fv\n",
    "rpfv_b = pfvToBA(random_partial_fv)\n",
    "rpfv_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:31:39.067420Z",
     "start_time": "2019-05-01T16:31:39.063920Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, -1,  1, -1,  0,  0,  0,  0,  0,  1], dtype=int8)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baToPFV(rpfv_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
